[tool.poetry]
name = "fmbench"
version = "1.0.48"
description ="Benchmark performance of **any Foundation Model (FM)** deployed on **any AWS Generative AI service**, be it **Amazon SageMaker**, **Amazon Bedrock**, **Amazon EKS**, or **Amazon EC2**. The FMs could be deployed on these platforms either directly through `FMbench`, or, if they are already deployed then also they could be benchmarked through the **Bring your own endpoint** mode supported by `FMBench`."
authors = ["Amit Arora <aroraai@amazon.com>", "Madhur prashant <Madhurpt@amazon.com>"]
readme = "README.md"
license = "MIT"
repository = "https://github.com/aws-samples/foundation-model-benchmarking-tool"
keywords = ["benchmarking", "sagemaker", "bedrock", "bring your own endpoint", "generative-ai", "foundation-models"]

[tool.poetry.dependencies]
python = "^3.11"
requests = "^2.32.2"
ipywidgets = "8.1.1"
transformers = "4.41.2"
pandas = "2.1.4"
datasets = "2.16.1"
seaborn = "0.13.1"
tomark = "0.1.4"
jupyter = "^1.0.0"
boto3 = "^1.34.109"
papermill = "^2.5.0"
pyyaml = "*"
sagemaker = "2.223.0"
litellm = "1.40.0"
plotly = "5.22.0"
kaleido = "0.2.1"
jinja2 = "3.1.4"
tqdm = "4.66.4"
pydantic = "2.7.4"

[tool.poetry.dev-dependencies]

[[tool.poetry.packages]]
include = "fmbench"
from = "src"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
fmbench = 'fmbench.main:main'
