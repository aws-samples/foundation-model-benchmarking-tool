{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on all deployed endpoints: Various combinations of payloads, concurrency levels, model configurations\n",
    "---------------------\n",
    "*This notebook works best with the conda_python3 kernel on a ml.t3.medium machine*.\n",
    "\n",
    "#### This step of our solution design includes running inferences on all deployed model endpoints (with different configurations, concurrency levels and payload sizes). This notebook runs inferences in a manner that is calls endpoints concurrently and asychronously to generate responses and record metrics. Here are some of the key components:\n",
    "\n",
    "- **Accessing the deployed endpoints**, creating a predictor object for these endpoints to call them during inference time.\n",
    "\n",
    "- **Functions to define metrics**: This notebook sets stage for metrics to be recorded during the time of invocation of all these models for benchmarking purposes.\n",
    "\n",
    "- **Running Actual Inferences**: Once the metrics are defined, we set a blocker function that is responsible for creating inference on a single payload called get_inference. We then run a series of asynchronous functions that can be viewed in the code (link above), to create asychronous inferefences on the deployed models. The way we send requests are by creating combinations: this means creating combinations of payloads of different sizes that can be viewed in the config.yml file, with different concurrency levels (in this case we first go through all patches of payloads with a concurrency level of 1, then 2, and then 4). You can set this to your desired value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all of the necessary libraries below to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if interactive mode is set to no -> pickup fmbench from Python installation path\n",
    "# if interactive mode is set to yes -> pickup fmbench from the current path (one level above this notebook)\n",
    "# if interactive mode is not defined -> pickup fmbench from the current path (one level above this notebook)\n",
    "# the premise is that if run non-interactively then it can only be run through main.py which will set interactive mode to no\n",
    "import os\n",
    "import sys\n",
    "if os.environ.get(\"INTERACTIVE_MODE_SET\", \"yes\") == \"yes\":\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /opt/homebrew/share/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/madhurpt/Library/Application Support/sagemaker/config.yaml\n",
      "config file current -> configs/config-claude-models.yml, None\n",
      "Loaded config: {'general': {'name': 'fmbench-claude', 'model_name': 'claude'}, 'aws': {'region': 'us-east-1', 'sagemaker_execution_role': 'arn:aws:iam::121797993273:user/ab3', 'bucket': 'sagemaker-fmbench-write-121797993273'}, 'dir_paths': {'data_prefix': 'data', 'prompts_prefix': 'prompts', 'all_prompts_file': 'all_prompts.csv', 'metrics_dir': 'metrics', 'models_dir': 'models', 'metadata_dir': 'metadata'}, 's3_read_data': {'read_bucket': 'sagemaker-fmbench-read-121797993273', 'scripts_prefix': 'scripts', 'script_files': ['hf_token.txt'], 'source_data_prefix': 'source_data', 'tokenizer_prefix': 'tokenizer', 'prompt_template_dir': 'prompt_template', 'prompt_template_file': 'prompt_template.txt'}, 'run_steps': {'0_setup.ipynb': True, '1_generate_data.ipynb': True, '2_deploy_model.ipynb': False, '3_run_inference.ipynb': True, '4_model_metric_analysis.ipynb': True, '5_cleanup.ipynb': True}, 'datasets': {'prompt_template_keys': ['input', 'context'], 'filters': [{'language': 'en', 'min_length_in_tokens': 1, 'max_length_in_tokens': 500, 'payload_file': 'payload_en_1-500.jsonl'}, {'language': 'en', 'min_length_in_tokens': 500, 'max_length_in_tokens': 1000, 'payload_file': 'payload_en_500-1000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 1000, 'max_length_in_tokens': 2000, 'payload_file': 'payload_en_1000-2000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 2000, 'max_length_in_tokens': 3000, 'payload_file': 'payload_en_2000-3000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 3000, 'max_length_in_tokens': 4000, 'payload_file': 'payload_en_3000-4000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 305, 'max_length_in_tokens': 3997, 'payload_file': 'payload_en_305-3997.jsonl'}]}, 'metrics': {'dataset_of_interest': 'en_3000-4000', 'weights': {'price_per_tx_wt': 0.65, 'latenct_wt': 0.35}}, 'pricing': {'ml.m5.xlarge': 0.23, 'ml.g5.xlarge': 1.006, 'ml.g5.2xlarge': 1.212, 'ml.g5.12xlarge': 7.09, 'ml.g5.24xlarge': 10.18, 'ml.g5.48xlarge': 20.36, 'ml.inf2.24xlarge': 7.79, 'ml.inf2.48xlarge': 15.58, 'ml.p4d.24xlarge': 37.688, 'ml.p3.2xlarge': 3.825, 'Claudev3-Haiku-ODT': [{'input-per-1k-tokens': 0.00025}, {'output-per-1k-tokens': 0.00125}], 'Claudev3-Sonnet-ODT': [{'input-per-1k-tokens': 0.003}, {'output-per-1k-tokens': 0.015}], 'ClaudeV2-ODT': [{'input-per-1k-tokens': 0.0008}, {'output-per-1k-tokens': 0.0024}], 'ClaudeV2:1-ODT': [{'input-per-1k-tokens': 0.0008}, {'output-per-1k-tokens': 0.0024}], 'ClaudeInstant-ODT': [{'input-per-1k-tokens': 0.0008}, {'output-per-1k-tokens': 0.0024}], 'titan-emb-text-ODT': [{'input-per-1k-tokens': 0.0001}, {'output-per-1k-tokens': 0}], 'titan-text-lite-ODT': [{'input-per-1k-tokens': 0.0003}, {'output-per-1k-tokens': 0.0004}], 'titan-text-express-ODT': [{'input-per-1k-tokens': 0.0008}, {'output-per-1k-tokens': 0.0016}], 'Mistral-ODT': [{'input-per-1k-tokens': 0.00015}, {'output-per-1k-tokens': 0.0002}], 'Mixtral-ODT': [{'input-per-1k-tokens': 0.00045}, {'output-per-1k-tokens': 0.0007}], 'Llama13b-ODT': [{'input-per-1k-tokens': 0.00075}, {'output-per-1k-tokens': 0.001}], 'Llama70b-ODT': [{'input-per-1k-tokens': 0.00195}, {'output-per-1k-tokens': 0.00195}], 'AI21mid-ODT': [{'input-per-1k-tokens': 0.0125}, {'output-per-1k-tokens': 0.0125}], 'AI21ultra-ODT': [{'input-per-1k-tokens': 0.0188}, {'output-per-1k-tokens': 0.0188}], 'CohereCommand-ODT': [{'input-per-1k-tokens': 0.0015}, {'output-per-1k-tokens': 0.002}], 'CohereCommLight-ODT': [{'input-per-1k-tokens': 0.0003}, {'output-per-1k-tokens': 0.0006}]}, 'inference_parameters': {'ContentType': 'application/json', 'Accept': 'application/json'}, 'experiments': [{'name': 'haiku-bedrock-trial', 'model_id': 'anthropic.claude-3-haiku-20240307-v1:0', 'model_version': '*', 'model_name': 'haiku', 'ep_name': 'anthropic.claude-3-haiku-20240307-v1:0', 'instance_type': 'Claudev3-Haiku-ODT', 'image_uri': None, 'deploy': False, 'instance_count': 1, 'deployment_script': None, 'inference_script': 'bedrock_predictor.py', 'payload_files': ['payload_en_3000-4000.jsonl'], 'concurrency_levels': [1], 'env': None}, {'name': 'claude-3-sonnet', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0', 'model_version': '*', 'model_name': 'claude-3-sonnet', 'ep_name': 'anthropic.claude-3-sonnet-20240229-v1:0', 'instance_type': 'Claudev3-Sonnet-ODT', 'image_uri': None, 'deploy': False, 'instance_count': 1, 'deployment_script': None, 'inference_script': 'bedrock_predictor.py', 'payload_files': ['payload_en_3000-4000.jsonl'], 'concurrency_levels': [1], 'env': None}], 'report': {'per_inference_request_file': 'per_inference_request_results.csv', 'all_metrics_file': 'all_metrics.csv', 'txn_count_for_showing_cost': 100000, 'v_shift_w_single_instance': 0.025, 'v_shift_w_gt_one_instance': 0.025}}\n",
      "CustomTokenizer, based on HF transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files found in S3 Bucket: 'sagemaker-fmbench-read-121797993273' with Prefix: 'tokenizer'\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "import copy\n",
    "import boto3\n",
    "import asyncio\n",
    "import logging\n",
    "import botocore\n",
    "import itertools\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "from fmbench.utils import *\n",
    "from fmbench.globals import * \n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from transformers import AutoTokenizer\n",
    "from sagemaker.predictor import Predictor\n",
    "import importlib.resources as pkg_resources\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from fmbench.scripts.bedrock_predictor import BedrockPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pygmentize globals.py to view and use any of the globally initialized variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Config.yml file that contains information that is used across this benchmarking environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:{\n",
      "  \"general\": {\n",
      "    \"name\": \"fmbench-claude\",\n",
      "    \"model_name\": \"claude\"\n",
      "  },\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role\": \"arn:aws:iam::121797993273:user/ab3\",\n",
      "    \"bucket\": \"sagemaker-fmbench-write-121797993273\"\n",
      "  },\n",
      "  \"dir_paths\": {\n",
      "    \"data_prefix\": \"data\",\n",
      "    \"prompts_prefix\": \"prompts\",\n",
      "    \"all_prompts_file\": \"all_prompts.csv\",\n",
      "    \"metrics_dir\": \"metrics\",\n",
      "    \"models_dir\": \"models\",\n",
      "    \"metadata_dir\": \"metadata\"\n",
      "  },\n",
      "  \"s3_read_data\": {\n",
      "    \"read_bucket\": \"sagemaker-fmbench-read-121797993273\",\n",
      "    \"scripts_prefix\": \"scripts\",\n",
      "    \"script_files\": [\n",
      "      \"hf_token.txt\"\n",
      "    ],\n",
      "    \"source_data_prefix\": \"source_data\",\n",
      "    \"tokenizer_prefix\": \"tokenizer\",\n",
      "    \"prompt_template_dir\": \"prompt_template\",\n",
      "    \"prompt_template_file\": \"prompt_template.txt\"\n",
      "  },\n",
      "  \"run_steps\": {\n",
      "    \"0_setup.ipynb\": true,\n",
      "    \"1_generate_data.ipynb\": true,\n",
      "    \"2_deploy_model.ipynb\": false,\n",
      "    \"3_run_inference.ipynb\": true,\n",
      "    \"4_model_metric_analysis.ipynb\": true,\n",
      "    \"5_cleanup.ipynb\": true\n",
      "  },\n",
      "  \"datasets\": {\n",
      "    \"prompt_template_keys\": [\n",
      "      \"input\",\n",
      "      \"context\"\n",
      "    ],\n",
      "    \"filters\": [\n",
      "      {\n",
      "        \"language\": \"en\",\n",
      "        \"min_length_in_tokens\": 1,\n",
      "        \"max_length_in_tokens\": 500,\n",
      "        \"payload_file\": \"payload_en_1-500.jsonl\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"en\",\n",
      "        \"min_length_in_tokens\": 500,\n",
      "        \"max_length_in_tokens\": 1000,\n",
      "        \"payload_file\": \"payload_en_500-1000.jsonl\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"en\",\n",
      "        \"min_length_in_tokens\": 1000,\n",
      "        \"max_length_in_tokens\": 2000,\n",
      "        \"payload_file\": \"payload_en_1000-2000.jsonl\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"en\",\n",
      "        \"min_length_in_tokens\": 2000,\n",
      "        \"max_length_in_tokens\": 3000,\n",
      "        \"payload_file\": \"payload_en_2000-3000.jsonl\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"en\",\n",
      "        \"min_length_in_tokens\": 3000,\n",
      "        \"max_length_in_tokens\": 4000,\n",
      "        \"payload_file\": \"payload_en_3000-4000.jsonl\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"en\",\n",
      "        \"min_length_in_tokens\": 305,\n",
      "        \"max_length_in_tokens\": 3997,\n",
      "        \"payload_file\": \"payload_en_305-3997.jsonl\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"dataset_of_interest\": \"en_3000-4000\",\n",
      "    \"weights\": {\n",
      "      \"price_per_tx_wt\": 0.65,\n",
      "      \"latenct_wt\": 0.35\n",
      "    }\n",
      "  },\n",
      "  \"pricing\": {\n",
      "    \"ml.m5.xlarge\": 0.23,\n",
      "    \"ml.g5.xlarge\": 1.006,\n",
      "    \"ml.g5.2xlarge\": 1.212,\n",
      "    \"ml.g5.12xlarge\": 7.09,\n",
      "    \"ml.g5.24xlarge\": 10.18,\n",
      "    \"ml.g5.48xlarge\": 20.36,\n",
      "    \"ml.inf2.24xlarge\": 7.79,\n",
      "    \"ml.inf2.48xlarge\": 15.58,\n",
      "    \"ml.p4d.24xlarge\": 37.688,\n",
      "    \"ml.p3.2xlarge\": 3.825,\n",
      "    \"Claudev3-Haiku-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.00025\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.00125\n",
      "      }\n",
      "    ],\n",
      "    \"Claudev3-Sonnet-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.003\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.015\n",
      "      }\n",
      "    ],\n",
      "    \"ClaudeV2-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0008\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0024\n",
      "      }\n",
      "    ],\n",
      "    \"ClaudeV2:1-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0008\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0024\n",
      "      }\n",
      "    ],\n",
      "    \"ClaudeInstant-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0008\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0024\n",
      "      }\n",
      "    ],\n",
      "    \"titan-emb-text-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0001\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0\n",
      "      }\n",
      "    ],\n",
      "    \"titan-text-lite-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0003\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0004\n",
      "      }\n",
      "    ],\n",
      "    \"titan-text-express-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0008\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0016\n",
      "      }\n",
      "    ],\n",
      "    \"Mistral-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.00015\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0002\n",
      "      }\n",
      "    ],\n",
      "    \"Mixtral-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.00045\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0007\n",
      "      }\n",
      "    ],\n",
      "    \"Llama13b-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.00075\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.001\n",
      "      }\n",
      "    ],\n",
      "    \"Llama70b-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.00195\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.00195\n",
      "      }\n",
      "    ],\n",
      "    \"AI21mid-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0125\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0125\n",
      "      }\n",
      "    ],\n",
      "    \"AI21ultra-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0188\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0188\n",
      "      }\n",
      "    ],\n",
      "    \"CohereCommand-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0015\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.002\n",
      "      }\n",
      "    ],\n",
      "    \"CohereCommLight-ODT\": [\n",
      "      {\n",
      "        \"input-per-1k-tokens\": 0.0003\n",
      "      },\n",
      "      {\n",
      "        \"output-per-1k-tokens\": 0.0006\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"inference_parameters\": {\n",
      "    \"ContentType\": \"application/json\",\n",
      "    \"Accept\": \"application/json\"\n",
      "  },\n",
      "  \"experiments\": [\n",
      "    {\n",
      "      \"name\": \"haiku-bedrock-trial\",\n",
      "      \"model_id\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "      \"model_version\": \"*\",\n",
      "      \"model_name\": \"haiku\",\n",
      "      \"ep_name\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "      \"instance_type\": \"Claudev3-Haiku-ODT\",\n",
      "      \"image_uri\": null,\n",
      "      \"deploy\": false,\n",
      "      \"instance_count\": 1,\n",
      "      \"deployment_script\": null,\n",
      "      \"inference_script\": \"bedrock_predictor.py\",\n",
      "      \"payload_files\": [\n",
      "        \"payload_en_3000-4000.jsonl\"\n",
      "      ],\n",
      "      \"concurrency_levels\": [\n",
      "        1\n",
      "      ],\n",
      "      \"env\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"claude-3-sonnet\",\n",
      "      \"model_id\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
      "      \"model_version\": \"*\",\n",
      "      \"model_name\": \"claude-3-sonnet\",\n",
      "      \"ep_name\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
      "      \"instance_type\": \"Claudev3-Sonnet-ODT\",\n",
      "      \"image_uri\": null,\n",
      "      \"deploy\": false,\n",
      "      \"instance_count\": 1,\n",
      "      \"deployment_script\": null,\n",
      "      \"inference_script\": \"bedrock_predictor.py\",\n",
      "      \"payload_files\": [\n",
      "        \"payload_en_3000-4000.jsonl\"\n",
      "      ],\n",
      "      \"concurrency_levels\": [\n",
      "        1\n",
      "      ],\n",
      "      \"env\": null\n",
      "    }\n",
      "  ],\n",
      "  \"report\": {\n",
      "    \"per_inference_request_file\": \"per_inference_request_results.csv\",\n",
      "    \"all_metrics_file\": \"all_metrics.csv\",\n",
      "    \"txn_count_for_showing_cost\": 100000,\n",
      "    \"v_shift_w_single_instance\": 0.025,\n",
      "    \"v_shift_w_gt_one_instance\": 0.025\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = load_config(CONFIG_FILE)\n",
    "logger.info(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## getting access to the s3 bucket where endpoints.json for different models resides\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the deployed model endpoints from the endpoints.json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Key fmbench-claude-ab3/data/models/endpoints.json not found in bucket sagemaker-fmbench-write-121797993273. Using an empty list for endpoints for bedrock models.\n"
     ]
    }
   ],
   "source": [
    "## Refer to the file path for the endpoint\n",
    "## getting the endpoint as an s3 object from the deployed path\n",
    "try:\n",
    "    endpoint_info_list = json.loads(get_s3_object(config['aws']['bucket'], ENDPOINT_LIST_PATH))\n",
    "    logger.info(f\"found information for {len(endpoint_info_list)} endpoints in bucket={config['aws']['bucket']}, key={ENDPOINT_LIST_PATH}\")\n",
    "    logger.info(json.dumps(endpoint_info_list, indent=2))\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "        logger.warning(f\"Key {ENDPOINT_LIST_PATH} not found in bucket {config['aws']['bucket']}. Using an empty list for endpoints for bedrock models.\")\n",
    "        endpoint_info_list = []\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:there are 0 deployed endpoint(s), endpoint_name_list->[]\n"
     ]
    }
   ],
   "source": [
    "# List down the endpoint names that have been deployed\n",
    "endpoint_name_list = [e['endpoint']['EndpointName'] for e in endpoint_info_list]\n",
    "logger.info(f\"there are {len(endpoint_name_list)} deployed endpoint(s), endpoint_name_list->{endpoint_name_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions to define and calculate metrics during the time of invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_sum(l: List) -> Union[int, float]:\n",
    "    return sum(filter(None, l))\n",
    "\n",
    "def safe_div(n: Union[int, float], d: Union[int, float]) -> Optional[Union[int, float]]:\n",
    "    return n/d if d else None\n",
    "\n",
    "## Represents the function to calculate all of the metrics at the time of inference\n",
    "def calculate_metrics(responses, chunk, elapsed_async, experiment_name, concurrency, payload_file) -> Dict:\n",
    "    \n",
    "    ## calculate errors based on the completion status of the inference prompt\n",
    "    errors = [r for r in responses if r['completion'] is None]\n",
    "    \n",
    "    ## Calculate the difference as the successes \n",
    "    successes = len(chunk) - len(errors)\n",
    "    \n",
    "    ## Count all of the prompts token count during inference\n",
    "    all_prompts_token_count = safe_sum([r['prompt_tokens'] for r in responses])\n",
    "    prompt_token_throughput = round(all_prompts_token_count / elapsed_async, 2)\n",
    "    prompt_token_count_mean = safe_div(all_prompts_token_count, successes)\n",
    "    all_completions_token_count = safe_sum([r['completion_tokens'] for r in responses])\n",
    "    completion_token_throughput = round(all_completions_token_count / elapsed_async, 2)\n",
    "    completion_token_count_mean = safe_div(all_completions_token_count, successes)\n",
    "    transactions_per_second = round(successes / elapsed_async, 2)\n",
    "    transactions_per_minute = int(transactions_per_second * 60)\n",
    "    \n",
    "    ## calculate the latency mean utilizing the safe_sum function defined above\n",
    "    latency_mean = safe_div(safe_sum([r['latency'] for r in responses]), successes)\n",
    "    \n",
    "    ## Function returns all these values at the time of the invocations\n",
    "    return {\n",
    "        'experiment_name': experiment_name,\n",
    "        'concurrency': concurrency,\n",
    "        'payload_file': payload_file,\n",
    "        'errors': errors,\n",
    "        'successes': successes,\n",
    "        'error_rate': len(errors)/len(chunk),\n",
    "        'all_prompts_token_count': all_prompts_token_count,\n",
    "        'prompt_token_count_mean': prompt_token_count_mean,\n",
    "        'prompt_token_throughput': prompt_token_throughput,\n",
    "        'all_completions_token_count': all_completions_token_count,\n",
    "        'completion_token_count_mean': completion_token_count_mean,\n",
    "        'completion_token_throughput': completion_token_throughput,\n",
    "        'transactions': len(chunk),\n",
    "        'transactions_per_second': transactions_per_second,\n",
    "        'transactions_per_minute': transactions_per_minute,\n",
    "        'latency_mean': latency_mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a blocker function and a series of asynchronous concurrent model prompt invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_metrics(endpoint_name=None,\n",
    "                    prompt=None,\n",
    "                    inference_params=None,\n",
    "                    completion=None,\n",
    "                    prompt_tokens=None,\n",
    "                    completion_tokens=None,\n",
    "                    latency=None) -> Dict:\n",
    "    return dict(endpoint_name=endpoint_name,                \n",
    "                prompt=prompt,\n",
    "                **inference_params,\n",
    "                completion=completion,\n",
    "                prompt_tokens=prompt_tokens,\n",
    "                completion_tokens=completion_tokens,\n",
    "                latency=latency)\n",
    "\n",
    "def get_inference(predictor, payload) -> Dict:\n",
    "    \n",
    "    latency = 0\n",
    "\n",
    "    ## initializing completion tokens\n",
    "    completion_tokens = None\n",
    "    prompt_tokens = None\n",
    "\n",
    "    try:\n",
    "        # get inference      \n",
    "        resp = predictor.get_prediction(payload) \n",
    "        logger.info(f\"response={resp}\")\n",
    "        response_json = resp['response_json']\n",
    "        logger.info(f\"response_json={response_json}\")\n",
    "        latency = resp['latency']\n",
    "        logger.info(f\"latency={latency}\")\n",
    "        prompt_tokens = resp['prompt_tokens']\n",
    "        logger.info(f\"prompt_tokens={prompt_tokens}\")\n",
    "        completion_tokens = resp['completion_tokens']\n",
    "        logger.info(f\"completion_tokens={completion_tokens}\")\n",
    "\n",
    "        # Assign the generated_text value to completion\n",
    "        completion = response_json.get(\"generated_text\", \"\")\n",
    "\n",
    "        # Set metrics and logging for both cases\n",
    "        response = set_metrics(predictor.endpoint_name,\n",
    "                               payload['inputs'],\n",
    "                               payload['parameters'],\n",
    "                               completion,\n",
    "                               prompt_tokens, \n",
    "                               completion_tokens,\n",
    "                               latency)\n",
    "        \n",
    "        # logger.info(f\"get_inference, done, endpoint={predictor.endpoint_name}, response={json.dumps(response, indent=2)}, latency={latency:.2f}\")\n",
    "        logger.info(f\"get_inference, done, endpoint={predictor.endpoint_name}, prompt_tokens = {prompt_tokens}, completion_tokens={completion_tokens}, latency={latency:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error occurred with {predictor.endpoint_name}, exception={str(e)}\")\n",
    "        response = set_metrics(predictor.endpoint_name,\n",
    "                               payload['inputs'],\n",
    "                               payload['parameters'],\n",
    "                               None,\n",
    "                               prompt_tokens,\n",
    "                               None,\n",
    "                               None)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a series of asynchronous functions to invoke and run inferences concurrently and asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Represents a function to start invoking models in separate thread asynchronously for the blocker function\n",
    "async def async_get_inference(predictor, payload: Dict) -> Dict:\n",
    "    return await asyncio.to_thread(get_inference, predictor, payload)\n",
    "\n",
    "## Gathers all of the tasks and sets of the concurrent calling of the asychronous invocations\n",
    "async def async_get_all_inferences(predictor, payload_list: List) -> List:\n",
    "    return await asyncio.gather(*[async_get_inference(predictor, payload) for payload in payload_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This function runs the asynchronous function series above together for different experiments and concurrency levels.\n",
    "async def run_inferences(predictor: sagemaker.base_predictor.Predictor, chunk: List, experiment: Dict, concurrency: int, payload_file: str) -> Tuple[List, Dict]:\n",
    "    logger.info(f\"processing chunk with concurrency={concurrency}\")\n",
    "    s = time.perf_counter()\n",
    "    responses = await async_get_all_inferences(predictor, chunk)\n",
    "    elapsed_async = time.perf_counter() - s\n",
    "\n",
    "    # Add more metadata about this experiment\n",
    "    for r in responses:\n",
    "        r['experiment_name'] = experiment['name']\n",
    "        r['concurrency'] = concurrency\n",
    "\n",
    "    metrics = calculate_metrics(responses, chunk, elapsed_async, experiment['name'], concurrency, payload_file)\n",
    "    return responses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to create the predictors from the experiment we are iterating over\n",
    "def create_predictor_for_experiment(experiment: Dict, config: Dict, endpoint_info_list: List) -> Optional[sagemaker.base_predictor.Predictor]:\n",
    "\n",
    "    ## Iterate through the endpoint information to fetch the endpoint name\n",
    "    ep_info = [e for e in endpoint_info_list if e['experiment_name'] == experiment['name']]\n",
    "    logger.info(f\"endpoint info found is: {ep_info}\")\n",
    "\n",
    "    if ep_info != []:\n",
    "        ep_name = ep_info[0]['endpoint']['EndpointName']\n",
    "        logger.info(f\"experiment name={experiment['name']}, ep_name={ep_name}\")\n",
    "    \n",
    "    elif ep_info == []:\n",
    "        ep_name = experiment['ep_name']\n",
    "        logger.info(f\"experiment name={experiment['name']}, custom bring your own ep_name={ep_name}\")\n",
    "\n",
    "    else:\n",
    "        logger.error(f\"endpoint for experiment={experiment['name']} not found, skipping\")\n",
    "        return None\n",
    "\n",
    "    # create predictor objects\n",
    "    # Proceed with deployment as before\n",
    "    # Assuming fmbench is a valid Python package and scripts is a subdirectory within it\n",
    "    scripts_dir = Path(pkg_resources.files('fmbench'), 'scripts')\n",
    "    logger.info(f\"Using fmbench.scripts directory: {scripts_dir}\")\n",
    "\n",
    "    # Ensure the scripts directory exists\n",
    "    scripts_dir.mkdir(parents=True, exist_ok=True)\n",
    "    module_name = Path(experiment['inference_script']).stem\n",
    "    logger.info(f\"script provided for inference from this model is --> {module_name}\")\n",
    "    script_path = scripts_dir / f\"{module_name}.py\"\n",
    "    logger.info(f\"script path is --> {script_path}\")\n",
    "\n",
    "    # Check and proceed with local script\n",
    "    if not script_path.exists():\n",
    "        logger.error(f\"script {script_path} not found.\")\n",
    "        return None\n",
    "\n",
    "    logger.info(f\"Deploying using local code: {script_path}\")\n",
    "\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(script_path))\n",
    "    inference_module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = inference_module\n",
    "    spec.loader.exec_module(inference_module)\n",
    "    # create a predictor from each endpoint in experiments\n",
    "    return inference_module.create_predictor(ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Here, we will process combinations of concurrency levels, the payload files and then loop through the \n",
    "## different combinations to make payloads splitted in terms of the concurrency metric and how we can run \n",
    "## it and make inference\n",
    "\n",
    "def create_payload_dict(jline: str, experiment: Dict) -> Dict:\n",
    "    payload: Dict = json.loads(jline)\n",
    "    return payload\n",
    "    \n",
    "    \n",
    "def create_combinations(experiment: Dict) -> List[Tuple]:\n",
    "    combinations_data = []\n",
    "\n",
    "    # Repeat for each concurrency level\n",
    "    combinations = list(itertools.product(experiment['concurrency_levels'], experiment['payload_files']))\n",
    "    logger.info(f\"there are {len(combinations)} combinations of {combinations} to run\")\n",
    "\n",
    "    for concurrency, payload_file in combinations:\n",
    "        # Construct the full S3 file path\n",
    "        s3_file_path = os.path.join(PROMPTS_DIR, payload_file)\n",
    "        logger.info(f\"s3 path where the payload files are being read from -> {s3_file_path}\")\n",
    "\n",
    "        # Read the payload file from S3\n",
    "        try:\n",
    "            response = s3_client.get_object(Bucket=config['aws']['bucket'], Key=s3_file_path)\n",
    "            payload_file_content = response['Body'].read().decode('utf-8')\n",
    "\n",
    "            # Create a payload list by processing each line\n",
    "            payload_list = [create_payload_dict(jline, experiment) for jline in payload_file_content.splitlines()]\n",
    "            logger.info(f\"read from s3://{config['aws']['bucket']}/{s3_file_path}, contains {len(payload_list)} lines\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file from S3: {e}\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"creating combinations for concurrency={concurrency}, payload_file={payload_file}, payload_list length={len(payload_list)}\")\n",
    "        \n",
    "        n = concurrency\n",
    "        \n",
    "        if len(payload_list) < n:\n",
    "            elements_to_add = n - len(payload_list)\n",
    "            element_to_replicate = payload_list[0]\n",
    "            # payload_list = payload_list.extend([element_to_replicate]*elements_to_add)\n",
    "            payload_list.extend([element_to_replicate]*elements_to_add)\n",
    "            \n",
    "        # Split the original list into sublists which contain the number of requests we want to send concurrently        \n",
    "        payload_list_splitted = [payload_list[i * n:(i + 1) * n] for i in range((len(payload_list) + n - 1) // n )]  \n",
    "        \n",
    "        for p in payload_list_splitted:\n",
    "            if len(p) < n:\n",
    "                elements_to_add = n - len(p)\n",
    "                element_to_replicate = p[0]\n",
    "                # p = p.extend([element_to_replicate]*elements_to_add)\n",
    "                p.extend([element_to_replicate]*elements_to_add)\n",
    "            \n",
    "\n",
    "        # Only keep lists that have at least concurrency number of elements\n",
    "        len_before = len(payload_list_splitted)\n",
    "        payload_list_splitted = [p for p in payload_list_splitted if len(p) == concurrency]\n",
    "        logger.info(f\"after only retaining chunks of length {concurrency}, we have {len(payload_list_splitted)} chunks, previously we had {len_before} chunks\")\n",
    "        combinations_data.append((concurrency, payload_file, payload_list_splitted))\n",
    "    logger.info(f\"there are {len(combinations)} for {experiment}\")\n",
    "    return combinations_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Current time recorded while running this experiment is 2024-03-22 17:10:54.801401+00:00..... deployed models are going to start inferences...\n",
      "INFO:__main__:endpoint info found is: []\n",
      "INFO:__main__:experiment name=haiku-bedrock-trial, custom bring your own ep_name=anthropic.claude-3-haiku-20240307-v1:0\n",
      "INFO:__main__:Using fmbench.scripts directory: /Users/madhurpt/Desktop/foundation-model-benchmarking-tool-5/src/fmbench/scripts\n",
      "INFO:__main__:script provided for inference from this model is --> bedrock_predictor\n",
      "INFO:__main__:script path is --> /Users/madhurpt/Desktop/foundation-model-benchmarking-tool-5/src/fmbench/scripts/bedrock_predictor.py\n",
      "INFO:__main__:Deploying using local code: /Users/madhurpt/Desktop/foundation-model-benchmarking-tool-5/src/fmbench/scripts/bedrock_predictor.py\n",
      "INFO:bedrock_predictor:__init__ self._predictor=<botocore.client.BedrockRuntime object at 0x17de5c110>\n",
      "INFO:__main__:there are 1 combinations of [(1, 'payload_en_3000-4000.jsonl')] to run\n",
      "INFO:__main__:s3 path where the payload files are being read from -> fmbench-claude-ab3/data/prompts/payload_en_3000-4000.jsonl\n",
      "INFO:__main__:read from s3://sagemaker-fmbench-write-121797993273/fmbench-claude-ab3/data/prompts/payload_en_3000-4000.jsonl, contains 57 lines\n",
      "INFO:__main__:creating combinations for concurrency=1, payload_file=payload_en_3000-4000.jsonl, payload_list length=57\n",
      "INFO:__main__:after only retaining chunks of length 1, we have 57 chunks, previously we had 57 chunks\n",
      "INFO:__main__:there are 1 for {'name': 'haiku-bedrock-trial', 'model_id': 'anthropic.claude-3-haiku-20240307-v1:0', 'model_version': '*', 'model_name': 'haiku', 'ep_name': 'anthropic.claude-3-haiku-20240307-v1:0', 'instance_type': 'Claudev3-Haiku-ODT', 'image_uri': None, 'deploy': False, 'instance_count': 1, 'deployment_script': None, 'inference_script': 'bedrock_predictor.py', 'payload_files': ['payload_en_3000-4000.jsonl'], 'concurrency_levels': [1], 'env': None}\n",
      "INFO:__main__:e_idx=1/2, chunk_index=1/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3000\n",
      "INFO:bedrock_predictor:Claude completion tokens: 80\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01EbWZkfq8PnT8aUGG1esHTt', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Indradhanura Chhai came out earlier than The Death of Black King. Passage 3 states that Indradhanura Chhai is a 1993 Indian Oriya film, while Passage 7 states that The Death of Black King is a 1971 Czechoslovak film. Therefore, Indradhanura Chhai was released later than The Death of Black King.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2923, 'output_tokens': 101}, 'generated_text': 'Based on the information provided in the passages, Indradhanura Chhai came out earlier than The Death of Black King. Passage 3 states that Indradhanura Chhai is a 1993 Indian Oriya film, while Passage 7 states that The Death of Black King is a 1971 Czechoslovak film. Therefore, Indradhanura Chhai was released later than The Death of Black King.'}, 'latency': 1.8779802909994032, 'prompt_tokens': 3000, 'completion_tokens': 80}\n",
      "INFO:__main__:response_json={'id': 'msg_01EbWZkfq8PnT8aUGG1esHTt', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Indradhanura Chhai came out earlier than The Death of Black King. Passage 3 states that Indradhanura Chhai is a 1993 Indian Oriya film, while Passage 7 states that The Death of Black King is a 1971 Czechoslovak film. Therefore, Indradhanura Chhai was released later than The Death of Black King.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2923, 'output_tokens': 101}, 'generated_text': 'Based on the information provided in the passages, Indradhanura Chhai came out earlier than The Death of Black King. Passage 3 states that Indradhanura Chhai is a 1993 Indian Oriya film, while Passage 7 states that The Death of Black King is a 1971 Czechoslovak film. Therefore, Indradhanura Chhai was released later than The Death of Black King.'}\n",
      "INFO:__main__:latency=1.8779802909994032\n",
      "INFO:__main__:prompt_tokens=3000\n",
      "INFO:__main__:completion_tokens=80\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3000, completion_tokens=80, latency=1.8780\n",
      "INFO:__main__:e_idx=1/2, chunk_index=2/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3896\n",
      "INFO:bedrock_predictor:Claude completion tokens: 63\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01A21jfwN1yQaB9RhCDy3RkK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Unfortunately, there is no information provided in the given passages about the ages or birth dates of Peter Rosegger and Ruel Redinger, so I do not have enough information to determine who is younger between the two. The passages do not contain any details that would allow me to make a comparison of their ages.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3765, 'output_tokens': 69}, 'generated_text': 'Unfortunately, there is no information provided in the given passages about the ages or birth dates of Peter Rosegger and Ruel Redinger, so I do not have enough information to determine who is younger between the two. The passages do not contain any details that would allow me to make a comparison of their ages.'}, 'latency': 2.190343791997293, 'prompt_tokens': 3896, 'completion_tokens': 63}\n",
      "INFO:__main__:response_json={'id': 'msg_01A21jfwN1yQaB9RhCDy3RkK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Unfortunately, there is no information provided in the given passages about the ages or birth dates of Peter Rosegger and Ruel Redinger, so I do not have enough information to determine who is younger between the two. The passages do not contain any details that would allow me to make a comparison of their ages.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3765, 'output_tokens': 69}, 'generated_text': 'Unfortunately, there is no information provided in the given passages about the ages or birth dates of Peter Rosegger and Ruel Redinger, so I do not have enough information to determine who is younger between the two. The passages do not contain any details that would allow me to make a comparison of their ages.'}\n",
      "INFO:__main__:latency=2.190343791997293\n",
      "INFO:__main__:prompt_tokens=3896\n",
      "INFO:__main__:completion_tokens=63\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3896, completion_tokens=63, latency=2.1903\n",
      "INFO:__main__:e_idx=1/2, chunk_index=3/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3789\n",
      "INFO:bedrock_predictor:Claude completion tokens: 54\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01EpnywzCBwWTTj3hh6gtDVU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Erich Haenisch died first. The passage states that Erich Haenisch died on 21 December 1966, while William Pooley died on 5 August 1629. Therefore, Erich Haenisch died later than William Pooley.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3533, 'output_tokens': 72}, 'generated_text': 'Based on the information provided, Erich Haenisch died first. The passage states that Erich Haenisch died on 21 December 1966, while William Pooley died on 5 August 1629. Therefore, Erich Haenisch died later than William Pooley.'}, 'latency': 1.5150667499983683, 'prompt_tokens': 3789, 'completion_tokens': 54}\n",
      "INFO:__main__:response_json={'id': 'msg_01EpnywzCBwWTTj3hh6gtDVU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Erich Haenisch died first. The passage states that Erich Haenisch died on 21 December 1966, while William Pooley died on 5 August 1629. Therefore, Erich Haenisch died later than William Pooley.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3533, 'output_tokens': 72}, 'generated_text': 'Based on the information provided, Erich Haenisch died first. The passage states that Erich Haenisch died on 21 December 1966, while William Pooley died on 5 August 1629. Therefore, Erich Haenisch died later than William Pooley.'}\n",
      "INFO:__main__:latency=1.5150667499983683\n",
      "INFO:__main__:prompt_tokens=3789\n",
      "INFO:__main__:completion_tokens=54\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3789, completion_tokens=54, latency=1.5151\n",
      "INFO:__main__:e_idx=1/2, chunk_index=4/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3450\n",
      "INFO:bedrock_predictor:Claude completion tokens: 33\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01WmTzKk3Gus5drQshUJqShB', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the information provided, Thomas E. Noell's father, John William Noell, died in Washington, D.C. on March 14, 1863.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3249, 'output_tokens': 41}, 'generated_text': \"According to the information provided, Thomas E. Noell's father, John William Noell, died in Washington, D.C. on March 14, 1863.\"}, 'latency': 1.3629426670086104, 'prompt_tokens': 3450, 'completion_tokens': 33}\n",
      "INFO:__main__:response_json={'id': 'msg_01WmTzKk3Gus5drQshUJqShB', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the information provided, Thomas E. Noell's father, John William Noell, died in Washington, D.C. on March 14, 1863.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3249, 'output_tokens': 41}, 'generated_text': \"According to the information provided, Thomas E. Noell's father, John William Noell, died in Washington, D.C. on March 14, 1863.\"}\n",
      "INFO:__main__:latency=1.3629426670086104\n",
      "INFO:__main__:prompt_tokens=3450\n",
      "INFO:__main__:completion_tokens=33\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3450, completion_tokens=33, latency=1.3629\n",
      "INFO:__main__:e_idx=1/2, chunk_index=5/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3482\n",
      "INFO:bedrock_predictor:Claude completion tokens: 50\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01RgkJNnEK8HAx1xTDYQgnQ2', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a Chinese and German former international table tennis player, while Johann Christian Gustav Lucae was a German anatomist.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3345, 'output_tokens': 55}, 'generated_text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a Chinese and German former international table tennis player, while Johann Christian Gustav Lucae was a German anatomist.'}, 'latency': 1.171558834001189, 'prompt_tokens': 3482, 'completion_tokens': 50}\n",
      "INFO:__main__:response_json={'id': 'msg_01RgkJNnEK8HAx1xTDYQgnQ2', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a Chinese and German former international table tennis player, while Johann Christian Gustav Lucae was a German anatomist.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3345, 'output_tokens': 55}, 'generated_text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a Chinese and German former international table tennis player, while Johann Christian Gustav Lucae was a German anatomist.'}\n",
      "INFO:__main__:latency=1.171558834001189\n",
      "INFO:__main__:prompt_tokens=3482\n",
      "INFO:__main__:completion_tokens=50\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3482, completion_tokens=50, latency=1.1716\n",
      "INFO:__main__:e_idx=1/2, chunk_index=6/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3144\n",
      "INFO:bedrock_predictor:Claude completion tokens: 88\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01CuBoTr5bdXEDDT1KCp2iTK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the director of the film Nallavan Vazhvan was P. Neelakantan. The passage states that P. Neelakantan was a Tamil film director who was active for nearly four decades, but it does not provide the date of his death. Therefore, I do not have enough information to confidently state the date of death of the director of Nallavan Vazhvan.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2990, 'output_tokens': 97}, 'generated_text': 'According to the information provided, the director of the film Nallavan Vazhvan was P. Neelakantan. The passage states that P. Neelakantan was a Tamil film director who was active for nearly four decades, but it does not provide the date of his death. Therefore, I do not have enough information to confidently state the date of death of the director of Nallavan Vazhvan.'}, 'latency': 1.7817927500000224, 'prompt_tokens': 3144, 'completion_tokens': 88}\n",
      "INFO:__main__:response_json={'id': 'msg_01CuBoTr5bdXEDDT1KCp2iTK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the director of the film Nallavan Vazhvan was P. Neelakantan. The passage states that P. Neelakantan was a Tamil film director who was active for nearly four decades, but it does not provide the date of his death. Therefore, I do not have enough information to confidently state the date of death of the director of Nallavan Vazhvan.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2990, 'output_tokens': 97}, 'generated_text': 'According to the information provided, the director of the film Nallavan Vazhvan was P. Neelakantan. The passage states that P. Neelakantan was a Tamil film director who was active for nearly four decades, but it does not provide the date of his death. Therefore, I do not have enough information to confidently state the date of death of the director of Nallavan Vazhvan.'}\n",
      "INFO:__main__:latency=1.7817927500000224\n",
      "INFO:__main__:prompt_tokens=3144\n",
      "INFO:__main__:completion_tokens=88\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3144, completion_tokens=88, latency=1.7818\n",
      "INFO:__main__:e_idx=1/2, chunk_index=7/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3639\n",
      "INFO:bedrock_predictor:Claude completion tokens: 141\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01RZPFJGebkuSJY7PHrW8wpy', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, it appears that Duilio Coletti, the director of the film Folgore Division, died earlier than Lesley Selander, the director of the film Sandflow.\\n\\nThe passage on Duilio Coletti states that he was an Italian film director and screenwriter who directed 29 films between 1934 and 1977 and died in 1999. In contrast, the passage on Lesley Selander indicates that he was an American film director of Westerns and adventure movies whose career spanned from 1936 to 1968, and he died in 1979.\\n\\nTherefore, the director who died first was Duilio Coletti, the director of the film Folgore Division.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 172}, 'generated_text': 'Based on the information provided in the passages, it appears that Duilio Coletti, the director of the film Folgore Division, died earlier than Lesley Selander, the director of the film Sandflow.\\n\\nThe passage on Duilio Coletti states that he was an Italian film director and screenwriter who directed 29 films between 1934 and 1977 and died in 1999. In contrast, the passage on Lesley Selander indicates that he was an American film director of Westerns and adventure movies whose career spanned from 1936 to 1968, and he died in 1979.\\n\\nTherefore, the director who died first was Duilio Coletti, the director of the film Folgore Division.'}, 'latency': 3.345127041990054, 'prompt_tokens': 3639, 'completion_tokens': 141}\n",
      "INFO:__main__:response_json={'id': 'msg_01RZPFJGebkuSJY7PHrW8wpy', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, it appears that Duilio Coletti, the director of the film Folgore Division, died earlier than Lesley Selander, the director of the film Sandflow.\\n\\nThe passage on Duilio Coletti states that he was an Italian film director and screenwriter who directed 29 films between 1934 and 1977 and died in 1999. In contrast, the passage on Lesley Selander indicates that he was an American film director of Westerns and adventure movies whose career spanned from 1936 to 1968, and he died in 1979.\\n\\nTherefore, the director who died first was Duilio Coletti, the director of the film Folgore Division.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 172}, 'generated_text': 'Based on the information provided in the passages, it appears that Duilio Coletti, the director of the film Folgore Division, died earlier than Lesley Selander, the director of the film Sandflow.\\n\\nThe passage on Duilio Coletti states that he was an Italian film director and screenwriter who directed 29 films between 1934 and 1977 and died in 1999. In contrast, the passage on Lesley Selander indicates that he was an American film director of Westerns and adventure movies whose career spanned from 1936 to 1968, and he died in 1979.\\n\\nTherefore, the director who died first was Duilio Coletti, the director of the film Folgore Division.'}\n",
      "INFO:__main__:latency=3.345127041990054\n",
      "INFO:__main__:prompt_tokens=3639\n",
      "INFO:__main__:completion_tokens=141\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3639, completion_tokens=141, latency=3.3451\n",
      "INFO:__main__:e_idx=1/2, chunk_index=8/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3014\n",
      "INFO:bedrock_predictor:Claude completion tokens: 54\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01Hk7Sg9R9QnZP6j5ioCAcDv', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Canada. The passage states that Edmonton/Twin Island Airpark is located in Alberta, Canada, and Mayerthorpe Airport is located in Alberta, Canada as well.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2816, 'output_tokens': 59}, 'generated_text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Canada. The passage states that Edmonton/Twin Island Airpark is located in Alberta, Canada, and Mayerthorpe Airport is located in Alberta, Canada as well.'}, 'latency': 1.333495499988203, 'prompt_tokens': 3014, 'completion_tokens': 54}\n",
      "INFO:__main__:response_json={'id': 'msg_01Hk7Sg9R9QnZP6j5ioCAcDv', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Canada. The passage states that Edmonton/Twin Island Airpark is located in Alberta, Canada, and Mayerthorpe Airport is located in Alberta, Canada as well.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2816, 'output_tokens': 59}, 'generated_text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Canada. The passage states that Edmonton/Twin Island Airpark is located in Alberta, Canada, and Mayerthorpe Airport is located in Alberta, Canada as well.'}\n",
      "INFO:__main__:latency=1.333495499988203\n",
      "INFO:__main__:prompt_tokens=3014\n",
      "INFO:__main__:completion_tokens=54\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3014, completion_tokens=54, latency=1.3335\n",
      "INFO:__main__:e_idx=1/2, chunk_index=9/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3891\n",
      "INFO:bedrock_predictor:Claude completion tokens: 61\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_019PgP4WzZngx4WiFjgsTFHQ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, the album Blow in the Wind by Me First and the Gimme Gimmes was released in 2001, while the album Full Length LP by Guttermouth was released in 1991. Therefore, Blow in the Wind was released more recently than Full Length LP.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3662, 'output_tokens': 68}, 'generated_text': 'Based on the information provided, the album Blow in the Wind by Me First and the Gimme Gimmes was released in 2001, while the album Full Length LP by Guttermouth was released in 1991. Therefore, Blow in the Wind was released more recently than Full Length LP.'}, 'latency': 1.7533139590086648, 'prompt_tokens': 3891, 'completion_tokens': 61}\n",
      "INFO:__main__:response_json={'id': 'msg_019PgP4WzZngx4WiFjgsTFHQ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, the album Blow in the Wind by Me First and the Gimme Gimmes was released in 2001, while the album Full Length LP by Guttermouth was released in 1991. Therefore, Blow in the Wind was released more recently than Full Length LP.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3662, 'output_tokens': 68}, 'generated_text': 'Based on the information provided, the album Blow in the Wind by Me First and the Gimme Gimmes was released in 2001, while the album Full Length LP by Guttermouth was released in 1991. Therefore, Blow in the Wind was released more recently than Full Length LP.'}\n",
      "INFO:__main__:latency=1.7533139590086648\n",
      "INFO:__main__:prompt_tokens=3891\n",
      "INFO:__main__:completion_tokens=61\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3891, completion_tokens=61, latency=1.7533\n",
      "INFO:__main__:e_idx=1/2, chunk_index=10/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3575\n",
      "INFO:bedrock_predictor:Claude completion tokens: 55\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_014B8nAXN9aqovYYmsJhDvSP', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Kakwa River is located in Alberta, Canada, while Bighead River is located in Grey County, Ontario, Canada. Therefore, Kakwa River and Bighead River are located in the same country, which is Canada.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3419, 'output_tokens': 60}, 'generated_text': 'Based on the information provided in the passages, Kakwa River is located in Alberta, Canada, while Bighead River is located in Grey County, Ontario, Canada. Therefore, Kakwa River and Bighead River are located in the same country, which is Canada.'}, 'latency': 1.3156347909971373, 'prompt_tokens': 3575, 'completion_tokens': 55}\n",
      "INFO:__main__:response_json={'id': 'msg_014B8nAXN9aqovYYmsJhDvSP', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Kakwa River is located in Alberta, Canada, while Bighead River is located in Grey County, Ontario, Canada. Therefore, Kakwa River and Bighead River are located in the same country, which is Canada.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3419, 'output_tokens': 60}, 'generated_text': 'Based on the information provided in the passages, Kakwa River is located in Alberta, Canada, while Bighead River is located in Grey County, Ontario, Canada. Therefore, Kakwa River and Bighead River are located in the same country, which is Canada.'}\n",
      "INFO:__main__:latency=1.3156347909971373\n",
      "INFO:__main__:prompt_tokens=3575\n",
      "INFO:__main__:completion_tokens=55\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3575, completion_tokens=55, latency=1.3156\n",
      "INFO:__main__:e_idx=1/2, chunk_index=11/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3419\n",
      "INFO:bedrock_predictor:Claude completion tokens: 64\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_014zxW6nDatP2DGyA19MBhNz', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, I do not have enough information to determine who is younger between Vrindavan Lal Verma and Kerem nan. The passages do not provide any details about the ages or birth dates of these two individuals, so I cannot make a comparison to determine who is younger.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 71}, 'generated_text': 'Based on the information provided in the passages, I do not have enough information to determine who is younger between Vrindavan Lal Verma and Kerem nan. The passages do not provide any details about the ages or birth dates of these two individuals, so I cannot make a comparison to determine who is younger.'}, 'latency': 1.7053979580086889, 'prompt_tokens': 3419, 'completion_tokens': 64}\n",
      "INFO:__main__:response_json={'id': 'msg_014zxW6nDatP2DGyA19MBhNz', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, I do not have enough information to determine who is younger between Vrindavan Lal Verma and Kerem nan. The passages do not provide any details about the ages or birth dates of these two individuals, so I cannot make a comparison to determine who is younger.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 71}, 'generated_text': 'Based on the information provided in the passages, I do not have enough information to determine who is younger between Vrindavan Lal Verma and Kerem nan. The passages do not provide any details about the ages or birth dates of these two individuals, so I cannot make a comparison to determine who is younger.'}\n",
      "INFO:__main__:latency=1.7053979580086889\n",
      "INFO:__main__:prompt_tokens=3419\n",
      "INFO:__main__:completion_tokens=64\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3419, completion_tokens=64, latency=1.7054\n",
      "INFO:__main__:e_idx=1/2, chunk_index=12/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3458\n",
      "INFO:bedrock_predictor:Claude completion tokens: 39\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_019opqELKG9Bfdy5o1P1vmj1', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, William Jolliffe, 4th Baron Hylton's father, Hylton Jolliffe, 3rd Baron Hylton, died on 26 May 1945.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3289, 'output_tokens': 53}, 'generated_text': \"According to the passage, William Jolliffe, 4th Baron Hylton's father, Hylton Jolliffe, 3rd Baron Hylton, died on 26 May 1945.\"}, 'latency': 1.579533124997397, 'prompt_tokens': 3458, 'completion_tokens': 39}\n",
      "INFO:__main__:response_json={'id': 'msg_019opqELKG9Bfdy5o1P1vmj1', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, William Jolliffe, 4th Baron Hylton's father, Hylton Jolliffe, 3rd Baron Hylton, died on 26 May 1945.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3289, 'output_tokens': 53}, 'generated_text': \"According to the passage, William Jolliffe, 4th Baron Hylton's father, Hylton Jolliffe, 3rd Baron Hylton, died on 26 May 1945.\"}\n",
      "INFO:__main__:latency=1.579533124997397\n",
      "INFO:__main__:prompt_tokens=3458\n",
      "INFO:__main__:completion_tokens=39\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3458, completion_tokens=39, latency=1.5795\n",
      "INFO:__main__:e_idx=1/2, chunk_index=13/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3508\n",
      "INFO:bedrock_predictor:Claude completion tokens: 40\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01Hnk7XLJk7V1vzWe9yzn8hJ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the director of the film \"Sources of Life\" is Oskar Roehler. The passages do not mention anything about Oskar Roehler\\'s father.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3385, 'output_tokens': 45}, 'generated_text': 'According to the information provided, the director of the film \"Sources of Life\" is Oskar Roehler. The passages do not mention anything about Oskar Roehler\\'s father.'}, 'latency': 1.3232489160000114, 'prompt_tokens': 3508, 'completion_tokens': 40}\n",
      "INFO:__main__:response_json={'id': 'msg_01Hnk7XLJk7V1vzWe9yzn8hJ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the director of the film \"Sources of Life\" is Oskar Roehler. The passages do not mention anything about Oskar Roehler\\'s father.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3385, 'output_tokens': 45}, 'generated_text': 'According to the information provided, the director of the film \"Sources of Life\" is Oskar Roehler. The passages do not mention anything about Oskar Roehler\\'s father.'}\n",
      "INFO:__main__:latency=1.3232489160000114\n",
      "INFO:__main__:prompt_tokens=3508\n",
      "INFO:__main__:completion_tokens=40\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3508, completion_tokens=40, latency=1.3232\n",
      "INFO:__main__:e_idx=1/2, chunk_index=14/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3436\n",
      "INFO:bedrock_predictor:Claude completion tokens: 61\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01MsuWDTjsuu9zQpZ1ZR33EJ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the information provided in the passages, Where Are You? I'm Here was released in 1993, while Patnam Vachina Pativrathalu was released in 1982. Therefore, Patnam Vachina Pativrathalu came out earlier than Where Are You? I'm Here.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3427, 'output_tokens': 74}, 'generated_text': \"Based on the information provided in the passages, Where Are You? I'm Here was released in 1993, while Patnam Vachina Pativrathalu was released in 1982. Therefore, Patnam Vachina Pativrathalu came out earlier than Where Are You? I'm Here.\"}, 'latency': 1.501563833997352, 'prompt_tokens': 3436, 'completion_tokens': 61}\n",
      "INFO:__main__:response_json={'id': 'msg_01MsuWDTjsuu9zQpZ1ZR33EJ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the information provided in the passages, Where Are You? I'm Here was released in 1993, while Patnam Vachina Pativrathalu was released in 1982. Therefore, Patnam Vachina Pativrathalu came out earlier than Where Are You? I'm Here.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3427, 'output_tokens': 74}, 'generated_text': \"Based on the information provided in the passages, Where Are You? I'm Here was released in 1993, while Patnam Vachina Pativrathalu was released in 1982. Therefore, Patnam Vachina Pativrathalu came out earlier than Where Are You? I'm Here.\"}\n",
      "INFO:__main__:latency=1.501563833997352\n",
      "INFO:__main__:prompt_tokens=3436\n",
      "INFO:__main__:completion_tokens=61\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3436, completion_tokens=61, latency=1.5016\n",
      "INFO:__main__:e_idx=1/2, chunk_index=15/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3249\n",
      "INFO:bedrock_predictor:Claude completion tokens: 27\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01LfCNHoEJZnGwcySZNam1Yi', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, Charles James Irwin Grant, 6th Baron de Longueuil's paternal grandfather was Captain David Alexander Grant.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3065, 'output_tokens': 35}, 'generated_text': \"According to the passage, Charles James Irwin Grant, 6th Baron de Longueuil's paternal grandfather was Captain David Alexander Grant.\"}, 'latency': 1.1842429590033134, 'prompt_tokens': 3249, 'completion_tokens': 27}\n",
      "INFO:__main__:response_json={'id': 'msg_01LfCNHoEJZnGwcySZNam1Yi', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, Charles James Irwin Grant, 6th Baron de Longueuil's paternal grandfather was Captain David Alexander Grant.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3065, 'output_tokens': 35}, 'generated_text': \"According to the passage, Charles James Irwin Grant, 6th Baron de Longueuil's paternal grandfather was Captain David Alexander Grant.\"}\n",
      "INFO:__main__:latency=1.1842429590033134\n",
      "INFO:__main__:prompt_tokens=3249\n",
      "INFO:__main__:completion_tokens=27\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3249, completion_tokens=27, latency=1.1842\n",
      "INFO:__main__:e_idx=1/2, chunk_index=16/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3087\n",
      "INFO:bedrock_predictor:Claude completion tokens: 56\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01H53jqHovq3dMNNsSRxdRP3', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Helen Clifton was born earlier than Steve Barancik. The passage about Helen Clifton states that she was born on May 4, 1948, while the passage about Steve Barancik does not mention his date of birth.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2593, 'output_tokens': 64}, 'generated_text': 'Based on the information provided in the passages, Helen Clifton was born earlier than Steve Barancik. The passage about Helen Clifton states that she was born on May 4, 1948, while the passage about Steve Barancik does not mention his date of birth.'}, 'latency': 1.2926026250061113, 'prompt_tokens': 3087, 'completion_tokens': 56}\n",
      "INFO:__main__:response_json={'id': 'msg_01H53jqHovq3dMNNsSRxdRP3', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Helen Clifton was born earlier than Steve Barancik. The passage about Helen Clifton states that she was born on May 4, 1948, while the passage about Steve Barancik does not mention his date of birth.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2593, 'output_tokens': 64}, 'generated_text': 'Based on the information provided in the passages, Helen Clifton was born earlier than Steve Barancik. The passage about Helen Clifton states that she was born on May 4, 1948, while the passage about Steve Barancik does not mention his date of birth.'}\n",
      "INFO:__main__:latency=1.2926026250061113\n",
      "INFO:__main__:prompt_tokens=3087\n",
      "INFO:__main__:completion_tokens=56\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3087, completion_tokens=56, latency=1.2926\n",
      "INFO:__main__:e_idx=1/2, chunk_index=17/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3680\n",
      "INFO:bedrock_predictor:Claude completion tokens: 45\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01DUtWmSGmeR1DQB5rzB2sQU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the information provided, Leka, Crown Prince Of Albania's mother, Susan, Crown Princess of Albania, died on 17 July 2004 in Tirana, Albania. She died of lung cancer.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3479, 'output_tokens': 50}, 'generated_text': \"According to the information provided, Leka, Crown Prince Of Albania's mother, Susan, Crown Princess of Albania, died on 17 July 2004 in Tirana, Albania. She died of lung cancer.\"}, 'latency': 1.9018017079943093, 'prompt_tokens': 3680, 'completion_tokens': 45}\n",
      "INFO:__main__:response_json={'id': 'msg_01DUtWmSGmeR1DQB5rzB2sQU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the information provided, Leka, Crown Prince Of Albania's mother, Susan, Crown Princess of Albania, died on 17 July 2004 in Tirana, Albania. She died of lung cancer.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3479, 'output_tokens': 50}, 'generated_text': \"According to the information provided, Leka, Crown Prince Of Albania's mother, Susan, Crown Princess of Albania, died on 17 July 2004 in Tirana, Albania. She died of lung cancer.\"}\n",
      "INFO:__main__:latency=1.9018017079943093\n",
      "INFO:__main__:prompt_tokens=3680\n",
      "INFO:__main__:completion_tokens=45\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3680, completion_tokens=45, latency=1.9018\n",
      "INFO:__main__:e_idx=1/2, chunk_index=18/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3950\n",
      "INFO:bedrock_predictor:Claude completion tokens: 67\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01YMLKrG7nieYZ4Y7LM1tEbm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Band-e-Amir Dragons is named after the Band-e Amir National Park in Afghanistan. The passage states that the Band-e-Amir Dragons team represents the provinces around the Band-e Amir lakes in central Afghanistan, and that the team is named after the Band-e Amir National Park.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3621, 'output_tokens': 73}, 'generated_text': 'Band-e-Amir Dragons is named after the Band-e Amir National Park in Afghanistan. The passage states that the Band-e-Amir Dragons team represents the provinces around the Band-e Amir lakes in central Afghanistan, and that the team is named after the Band-e Amir National Park.'}, 'latency': 1.965698790998431, 'prompt_tokens': 3950, 'completion_tokens': 67}\n",
      "INFO:__main__:response_json={'id': 'msg_01YMLKrG7nieYZ4Y7LM1tEbm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Band-e-Amir Dragons is named after the Band-e Amir National Park in Afghanistan. The passage states that the Band-e-Amir Dragons team represents the provinces around the Band-e Amir lakes in central Afghanistan, and that the team is named after the Band-e Amir National Park.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3621, 'output_tokens': 73}, 'generated_text': 'Band-e-Amir Dragons is named after the Band-e Amir National Park in Afghanistan. The passage states that the Band-e-Amir Dragons team represents the provinces around the Band-e Amir lakes in central Afghanistan, and that the team is named after the Band-e Amir National Park.'}\n",
      "INFO:__main__:latency=1.965698790998431\n",
      "INFO:__main__:prompt_tokens=3950\n",
      "INFO:__main__:completion_tokens=67\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3950, completion_tokens=67, latency=1.9657\n",
      "INFO:__main__:e_idx=1/2, chunk_index=19/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3463\n",
      "INFO:bedrock_predictor:Claude completion tokens: 59\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_011eQm3pBuapQZh3SEes575W', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passage, the radio station that serves the Lakes Region of New Hampshire, which comprises all of Belknap County among other areas, is not explicitly stated. The passages do not provide the call letters of a radio station that serves the entire Lakes Region as described.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3284, 'output_tokens': 63}, 'generated_text': 'Based on the information provided in the passage, the radio station that serves the Lakes Region of New Hampshire, which comprises all of Belknap County among other areas, is not explicitly stated. The passages do not provide the call letters of a radio station that serves the entire Lakes Region as described.'}, 'latency': 1.5897330830048304, 'prompt_tokens': 3463, 'completion_tokens': 59}\n",
      "INFO:__main__:response_json={'id': 'msg_011eQm3pBuapQZh3SEes575W', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passage, the radio station that serves the Lakes Region of New Hampshire, which comprises all of Belknap County among other areas, is not explicitly stated. The passages do not provide the call letters of a radio station that serves the entire Lakes Region as described.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3284, 'output_tokens': 63}, 'generated_text': 'Based on the information provided in the passage, the radio station that serves the Lakes Region of New Hampshire, which comprises all of Belknap County among other areas, is not explicitly stated. The passages do not provide the call letters of a radio station that serves the entire Lakes Region as described.'}\n",
      "INFO:__main__:latency=1.5897330830048304\n",
      "INFO:__main__:prompt_tokens=3463\n",
      "INFO:__main__:completion_tokens=59\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3463, completion_tokens=59, latency=1.5897\n",
      "INFO:__main__:e_idx=1/2, chunk_index=20/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3996\n",
      "INFO:bedrock_predictor:Claude completion tokens: 81\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_0155pMGBzaup1dBF1jHhSRu3', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the village of Shienga is located in the East Mamprusi district of the Northern Region of Ghana. The passage states that the capital town of the East Mamprusi Municipal Assembly (which was originally known as the East Mamprusi District) is Gambaga. So the capital of the district that includes the village of Shienga is Gambaga.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3684, 'output_tokens': 88}, 'generated_text': 'According to the information provided, the village of Shienga is located in the East Mamprusi district of the Northern Region of Ghana. The passage states that the capital town of the East Mamprusi Municipal Assembly (which was originally known as the East Mamprusi District) is Gambaga. So the capital of the district that includes the village of Shienga is Gambaga.'}, 'latency': 2.603216916002566, 'prompt_tokens': 3996, 'completion_tokens': 81}\n",
      "INFO:__main__:response_json={'id': 'msg_0155pMGBzaup1dBF1jHhSRu3', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the village of Shienga is located in the East Mamprusi district of the Northern Region of Ghana. The passage states that the capital town of the East Mamprusi Municipal Assembly (which was originally known as the East Mamprusi District) is Gambaga. So the capital of the district that includes the village of Shienga is Gambaga.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3684, 'output_tokens': 88}, 'generated_text': 'According to the information provided, the village of Shienga is located in the East Mamprusi district of the Northern Region of Ghana. The passage states that the capital town of the East Mamprusi Municipal Assembly (which was originally known as the East Mamprusi District) is Gambaga. So the capital of the district that includes the village of Shienga is Gambaga.'}\n",
      "INFO:__main__:latency=2.603216916002566\n",
      "INFO:__main__:prompt_tokens=3996\n",
      "INFO:__main__:completion_tokens=81\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3996, completion_tokens=81, latency=2.6032\n",
      "INFO:__main__:e_idx=1/2, chunk_index=21/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3050\n",
      "INFO:bedrock_predictor:Claude completion tokens: 123\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_0171URpYCsQoQgK1DoFU1RLm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the information provided in the passages, Tim Cluess has led the Iona Gaels men's basketball team for a longer period of time than Steve Prohm has led the Murray State Racers and Iowa State Cyclones. The passages indicate that Tim Cluess was the head coach of Iona from the 2010-11 season through at least the 2016-17 season, spanning 7 seasons. In contrast, the passages only mention Steve Prohm as the head coach of Murray State in the 2012-13 season and the head coach of Iowa State starting in the 2015-16 season, a shorter overall tenure.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2903, 'output_tokens': 152}, 'generated_text': \"Based on the information provided in the passages, Tim Cluess has led the Iona Gaels men's basketball team for a longer period of time than Steve Prohm has led the Murray State Racers and Iowa State Cyclones. The passages indicate that Tim Cluess was the head coach of Iona from the 2010-11 season through at least the 2016-17 season, spanning 7 seasons. In contrast, the passages only mention Steve Prohm as the head coach of Murray State in the 2012-13 season and the head coach of Iowa State starting in the 2015-16 season, a shorter overall tenure.\"}, 'latency': 2.472797417009133, 'prompt_tokens': 3050, 'completion_tokens': 123}\n",
      "INFO:__main__:response_json={'id': 'msg_0171URpYCsQoQgK1DoFU1RLm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the information provided in the passages, Tim Cluess has led the Iona Gaels men's basketball team for a longer period of time than Steve Prohm has led the Murray State Racers and Iowa State Cyclones. The passages indicate that Tim Cluess was the head coach of Iona from the 2010-11 season through at least the 2016-17 season, spanning 7 seasons. In contrast, the passages only mention Steve Prohm as the head coach of Murray State in the 2012-13 season and the head coach of Iowa State starting in the 2015-16 season, a shorter overall tenure.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2903, 'output_tokens': 152}, 'generated_text': \"Based on the information provided in the passages, Tim Cluess has led the Iona Gaels men's basketball team for a longer period of time than Steve Prohm has led the Murray State Racers and Iowa State Cyclones. The passages indicate that Tim Cluess was the head coach of Iona from the 2010-11 season through at least the 2016-17 season, spanning 7 seasons. In contrast, the passages only mention Steve Prohm as the head coach of Murray State in the 2012-13 season and the head coach of Iowa State starting in the 2015-16 season, a shorter overall tenure.\"}\n",
      "INFO:__main__:latency=2.472797417009133\n",
      "INFO:__main__:prompt_tokens=3050\n",
      "INFO:__main__:completion_tokens=123\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3050, completion_tokens=123, latency=2.4728\n",
      "INFO:__main__:e_idx=1/2, chunk_index=22/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3737\n",
      "INFO:bedrock_predictor:Claude completion tokens: 39\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01KA2Jsg3788JmVoBJoU4VRL', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, Jim Rasenberger has contributed to the Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3488, 'output_tokens': 44}, 'generated_text': 'According to the information provided, Jim Rasenberger has contributed to the Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}, 'latency': 1.2344536659948062, 'prompt_tokens': 3737, 'completion_tokens': 39}\n",
      "INFO:__main__:response_json={'id': 'msg_01KA2Jsg3788JmVoBJoU4VRL', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, Jim Rasenberger has contributed to the Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3488, 'output_tokens': 44}, 'generated_text': 'According to the information provided, Jim Rasenberger has contributed to the Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}\n",
      "INFO:__main__:latency=1.2344536659948062\n",
      "INFO:__main__:prompt_tokens=3737\n",
      "INFO:__main__:completion_tokens=39\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3737, completion_tokens=39, latency=1.2345\n",
      "INFO:__main__:e_idx=1/2, chunk_index=23/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3410\n",
      "INFO:bedrock_predictor:Claude completion tokens: 80\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_018ZPKibhCTK4goKQMBGepsE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided:\\n\\nCassiope is a genus of 9-12 small shrubby species in the family Ericaceae. \\n\\nDeutzia is a genus of about 60 species of flowering plants in the family Hydrangeaceae.\\n\\nTherefore, the genus Deutzia has more species (around 60) compared to the genus Cassiope (9-12 species).'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3314, 'output_tokens': 93}, 'generated_text': 'According to the information provided:\\n\\nCassiope is a genus of 9-12 small shrubby species in the family Ericaceae. \\n\\nDeutzia is a genus of about 60 species of flowering plants in the family Hydrangeaceae.\\n\\nTherefore, the genus Deutzia has more species (around 60) compared to the genus Cassiope (9-12 species).'}, 'latency': 1.7188978339981986, 'prompt_tokens': 3410, 'completion_tokens': 80}\n",
      "INFO:__main__:response_json={'id': 'msg_018ZPKibhCTK4goKQMBGepsE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided:\\n\\nCassiope is a genus of 9-12 small shrubby species in the family Ericaceae. \\n\\nDeutzia is a genus of about 60 species of flowering plants in the family Hydrangeaceae.\\n\\nTherefore, the genus Deutzia has more species (around 60) compared to the genus Cassiope (9-12 species).'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3314, 'output_tokens': 93}, 'generated_text': 'According to the information provided:\\n\\nCassiope is a genus of 9-12 small shrubby species in the family Ericaceae. \\n\\nDeutzia is a genus of about 60 species of flowering plants in the family Hydrangeaceae.\\n\\nTherefore, the genus Deutzia has more species (around 60) compared to the genus Cassiope (9-12 species).'}\n",
      "INFO:__main__:latency=1.7188978339981986\n",
      "INFO:__main__:prompt_tokens=3410\n",
      "INFO:__main__:completion_tokens=80\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3410, completion_tokens=80, latency=1.7189\n",
      "INFO:__main__:e_idx=1/2, chunk_index=24/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3979\n",
      "INFO:bedrock_predictor:Claude completion tokens: 55\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01EwiLZXB4tAReVNe15w58T2', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Peter Curtis and Scott Draper are both former professional tennis players.\\n\\nThe passages state that Peter Curtis was a \"former British professional tennis player\" and that Scott Draper is an \"Australian former tennis player and golfer\".'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3720, 'output_tokens': 59}, 'generated_text': 'Based on the information provided in the passages, Peter Curtis and Scott Draper are both former professional tennis players.\\n\\nThe passages state that Peter Curtis was a \"former British professional tennis player\" and that Scott Draper is an \"Australian former tennis player and golfer\".'}, 'latency': 1.723530999996001, 'prompt_tokens': 3979, 'completion_tokens': 55}\n",
      "INFO:__main__:response_json={'id': 'msg_01EwiLZXB4tAReVNe15w58T2', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Peter Curtis and Scott Draper are both former professional tennis players.\\n\\nThe passages state that Peter Curtis was a \"former British professional tennis player\" and that Scott Draper is an \"Australian former tennis player and golfer\".'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3720, 'output_tokens': 59}, 'generated_text': 'Based on the information provided in the passages, Peter Curtis and Scott Draper are both former professional tennis players.\\n\\nThe passages state that Peter Curtis was a \"former British professional tennis player\" and that Scott Draper is an \"Australian former tennis player and golfer\".'}\n",
      "INFO:__main__:latency=1.723530999996001\n",
      "INFO:__main__:prompt_tokens=3979\n",
      "INFO:__main__:completion_tokens=55\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3979, completion_tokens=55, latency=1.7235\n",
      "INFO:__main__:e_idx=1/2, chunk_index=25/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3171\n",
      "INFO:bedrock_predictor:Claude completion tokens: 59\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01TBLjLSV8VkM7WyZ8wPQmtN', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided in Passage 8, Jacob Minah is a decathlete from Germany. He set his personal best of 8099 points in the decathlon event on 13 August 2007 at the 2007 Summer Universiade in Bangkok, Thailand, where he earned the gold medal.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2922, 'output_tokens': 73}, 'generated_text': 'According to the information provided in Passage 8, Jacob Minah is a decathlete from Germany. He set his personal best of 8099 points in the decathlon event on 13 August 2007 at the 2007 Summer Universiade in Bangkok, Thailand, where he earned the gold medal.'}, 'latency': 1.4272227920009755, 'prompt_tokens': 3171, 'completion_tokens': 59}\n",
      "INFO:__main__:response_json={'id': 'msg_01TBLjLSV8VkM7WyZ8wPQmtN', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided in Passage 8, Jacob Minah is a decathlete from Germany. He set his personal best of 8099 points in the decathlon event on 13 August 2007 at the 2007 Summer Universiade in Bangkok, Thailand, where he earned the gold medal.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2922, 'output_tokens': 73}, 'generated_text': 'According to the information provided in Passage 8, Jacob Minah is a decathlete from Germany. He set his personal best of 8099 points in the decathlon event on 13 August 2007 at the 2007 Summer Universiade in Bangkok, Thailand, where he earned the gold medal.'}\n",
      "INFO:__main__:latency=1.4272227920009755\n",
      "INFO:__main__:prompt_tokens=3171\n",
      "INFO:__main__:completion_tokens=59\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3171, completion_tokens=59, latency=1.4272\n",
      "INFO:__main__:e_idx=1/2, chunk_index=26/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3655\n",
      "INFO:bedrock_predictor:Claude completion tokens: 78\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_0166857Sb4LJ3CknpJnmB176', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Euptelea and Muehlenbeckia are both genera. According to the information provided:\\n\\nEuptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. \\n\\nMuehlenbeckia is a genus of flowering plants in the family Polygonaceae. It has 24 recognized species as of March 2019.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3505, 'output_tokens': 90}, 'generated_text': 'Yes, Euptelea and Muehlenbeckia are both genera. According to the information provided:\\n\\nEuptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. \\n\\nMuehlenbeckia is a genus of flowering plants in the family Polygonaceae. It has 24 recognized species as of March 2019.'}, 'latency': 2.070308209003997, 'prompt_tokens': 3655, 'completion_tokens': 78}\n",
      "INFO:__main__:response_json={'id': 'msg_0166857Sb4LJ3CknpJnmB176', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Euptelea and Muehlenbeckia are both genera. According to the information provided:\\n\\nEuptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. \\n\\nMuehlenbeckia is a genus of flowering plants in the family Polygonaceae. It has 24 recognized species as of March 2019.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3505, 'output_tokens': 90}, 'generated_text': 'Yes, Euptelea and Muehlenbeckia are both genera. According to the information provided:\\n\\nEuptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. \\n\\nMuehlenbeckia is a genus of flowering plants in the family Polygonaceae. It has 24 recognized species as of March 2019.'}\n",
      "INFO:__main__:latency=2.070308209003997\n",
      "INFO:__main__:prompt_tokens=3655\n",
      "INFO:__main__:completion_tokens=78\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3655, completion_tokens=78, latency=2.0703\n",
      "INFO:__main__:e_idx=1/2, chunk_index=27/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3662\n",
      "INFO:bedrock_predictor:Claude completion tokens: 39\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_016FwMGVSAoL4RF1d2ir6PRm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, Bennett Hill Farm is located in the town of New Scotland, New York. The passage states that the population of New Scotland was 8,648 at the 2010 census.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3372, 'output_tokens': 47}, 'generated_text': 'According to the information provided, Bennett Hill Farm is located in the town of New Scotland, New York. The passage states that the population of New Scotland was 8,648 at the 2010 census.'}, 'latency': 1.5991464999970049, 'prompt_tokens': 3662, 'completion_tokens': 39}\n",
      "INFO:__main__:response_json={'id': 'msg_016FwMGVSAoL4RF1d2ir6PRm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, Bennett Hill Farm is located in the town of New Scotland, New York. The passage states that the population of New Scotland was 8,648 at the 2010 census.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3372, 'output_tokens': 47}, 'generated_text': 'According to the information provided, Bennett Hill Farm is located in the town of New Scotland, New York. The passage states that the population of New Scotland was 8,648 at the 2010 census.'}\n",
      "INFO:__main__:latency=1.5991464999970049\n",
      "INFO:__main__:prompt_tokens=3662\n",
      "INFO:__main__:completion_tokens=39\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3662, completion_tokens=39, latency=1.5991\n",
      "INFO:__main__:e_idx=1/2, chunk_index=28/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3098\n",
      "INFO:bedrock_predictor:Claude completion tokens: 45\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_014yoagi9VaJiTWEJYPCZYZF', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Sergio Casal and Manuel Orantes were both professional tennis players. The passages provided information about their tennis careers, including their Grand Slam doubles titles, Davis Cup participation, and other notable achievements in the sport of tennis.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2980, 'output_tokens': 50}, 'generated_text': 'Sergio Casal and Manuel Orantes were both professional tennis players. The passages provided information about their tennis careers, including their Grand Slam doubles titles, Davis Cup participation, and other notable achievements in the sport of tennis.'}, 'latency': 1.431425250004395, 'prompt_tokens': 3098, 'completion_tokens': 45}\n",
      "INFO:__main__:response_json={'id': 'msg_014yoagi9VaJiTWEJYPCZYZF', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Sergio Casal and Manuel Orantes were both professional tennis players. The passages provided information about their tennis careers, including their Grand Slam doubles titles, Davis Cup participation, and other notable achievements in the sport of tennis.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2980, 'output_tokens': 50}, 'generated_text': 'Sergio Casal and Manuel Orantes were both professional tennis players. The passages provided information about their tennis careers, including their Grand Slam doubles titles, Davis Cup participation, and other notable achievements in the sport of tennis.'}\n",
      "INFO:__main__:latency=1.431425250004395\n",
      "INFO:__main__:prompt_tokens=3098\n",
      "INFO:__main__:completion_tokens=45\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3098, completion_tokens=45, latency=1.4314\n",
      "INFO:__main__:e_idx=1/2, chunk_index=29/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3704\n",
      "INFO:bedrock_predictor:Claude completion tokens: 95\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_015i3XXkimeVk4AMa8qMmoV8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Baghdad ER was released first. The passage on Baghdad ER states that it was \"released by HBO on May 21, 2006,\" while the passage on The Ten-Year Lunch states that it \"premiered on the PBS series American Masters on September 28, 1987.\" Therefore, Baghdad ER was released earlier, in 2006, compared to The Ten-Year Lunch which was released in 1987.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3484, 'output_tokens': 102}, 'generated_text': 'Based on the information provided in the passages, Baghdad ER was released first. The passage on Baghdad ER states that it was \"released by HBO on May 21, 2006,\" while the passage on The Ten-Year Lunch states that it \"premiered on the PBS series American Masters on September 28, 1987.\" Therefore, Baghdad ER was released earlier, in 2006, compared to The Ten-Year Lunch which was released in 1987.'}, 'latency': 2.1796069589909166, 'prompt_tokens': 3704, 'completion_tokens': 95}\n",
      "INFO:__main__:response_json={'id': 'msg_015i3XXkimeVk4AMa8qMmoV8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, Baghdad ER was released first. The passage on Baghdad ER states that it was \"released by HBO on May 21, 2006,\" while the passage on The Ten-Year Lunch states that it \"premiered on the PBS series American Masters on September 28, 1987.\" Therefore, Baghdad ER was released earlier, in 2006, compared to The Ten-Year Lunch which was released in 1987.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3484, 'output_tokens': 102}, 'generated_text': 'Based on the information provided in the passages, Baghdad ER was released first. The passage on Baghdad ER states that it was \"released by HBO on May 21, 2006,\" while the passage on The Ten-Year Lunch states that it \"premiered on the PBS series American Masters on September 28, 1987.\" Therefore, Baghdad ER was released earlier, in 2006, compared to The Ten-Year Lunch which was released in 1987.'}\n",
      "INFO:__main__:latency=2.1796069589909166\n",
      "INFO:__main__:prompt_tokens=3704\n",
      "INFO:__main__:completion_tokens=95\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3704, completion_tokens=95, latency=2.1796\n",
      "INFO:__main__:e_idx=1/2, chunk_index=30/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3400\n",
      "INFO:bedrock_predictor:Claude completion tokens: 82\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01VBP6YSCYyxB7YFQ45vcthY', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, I do not know the total number of women who competed at the 2002 Asian Games the year Lee Young-Sun achieved her personal best throw of 58.87 metres. The passages provide some details about the 2002 Asian Games, such as the total number of athletes (459) and the participating nations (39), but do not specify the breakdown between male and female athletes.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3121, 'output_tokens': 93}, 'generated_text': 'Based on the information provided in the passages, I do not know the total number of women who competed at the 2002 Asian Games the year Lee Young-Sun achieved her personal best throw of 58.87 metres. The passages provide some details about the 2002 Asian Games, such as the total number of athletes (459) and the participating nations (39), but do not specify the breakdown between male and female athletes.'}, 'latency': 1.6915534169966122, 'prompt_tokens': 3400, 'completion_tokens': 82}\n",
      "INFO:__main__:response_json={'id': 'msg_01VBP6YSCYyxB7YFQ45vcthY', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passages, I do not know the total number of women who competed at the 2002 Asian Games the year Lee Young-Sun achieved her personal best throw of 58.87 metres. The passages provide some details about the 2002 Asian Games, such as the total number of athletes (459) and the participating nations (39), but do not specify the breakdown between male and female athletes.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3121, 'output_tokens': 93}, 'generated_text': 'Based on the information provided in the passages, I do not know the total number of women who competed at the 2002 Asian Games the year Lee Young-Sun achieved her personal best throw of 58.87 metres. The passages provide some details about the 2002 Asian Games, such as the total number of athletes (459) and the participating nations (39), but do not specify the breakdown between male and female athletes.'}\n",
      "INFO:__main__:latency=1.6915534169966122\n",
      "INFO:__main__:prompt_tokens=3400\n",
      "INFO:__main__:completion_tokens=82\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3400, completion_tokens=82, latency=1.6916\n",
      "INFO:__main__:e_idx=1/2, chunk_index=31/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3098\n",
      "INFO:bedrock_predictor:Claude completion tokens: 17\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_019fsPq9c9BQKk3SG7DfHMR8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2836, 'output_tokens': 24}, 'generated_text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}, 'latency': 0.96832600000198, 'prompt_tokens': 3098, 'completion_tokens': 17}\n",
      "INFO:__main__:response_json={'id': 'msg_019fsPq9c9BQKk3SG7DfHMR8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2836, 'output_tokens': 24}, 'generated_text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}\n",
      "INFO:__main__:latency=0.96832600000198\n",
      "INFO:__main__:prompt_tokens=3098\n",
      "INFO:__main__:completion_tokens=17\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3098, completion_tokens=17, latency=0.9683\n",
      "INFO:__main__:e_idx=1/2, chunk_index=32/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3909\n",
      "INFO:bedrock_predictor:Claude completion tokens: 38\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01PRXJNjiHc3QZpGxh4Pe53x', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A saluki is a type of dog. The passage discusses salukis, which are considered to be one of the oldest dog breeds in existence. Salukis are a beautiful breed of dog.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3669, 'output_tokens': 44}, 'generated_text': 'A saluki is a type of dog. The passage discusses salukis, which are considered to be one of the oldest dog breeds in existence. Salukis are a beautiful breed of dog.'}, 'latency': 1.439266041998053, 'prompt_tokens': 3909, 'completion_tokens': 38}\n",
      "INFO:__main__:response_json={'id': 'msg_01PRXJNjiHc3QZpGxh4Pe53x', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A saluki is a type of dog. The passage discusses salukis, which are considered to be one of the oldest dog breeds in existence. Salukis are a beautiful breed of dog.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3669, 'output_tokens': 44}, 'generated_text': 'A saluki is a type of dog. The passage discusses salukis, which are considered to be one of the oldest dog breeds in existence. Salukis are a beautiful breed of dog.'}\n",
      "INFO:__main__:latency=1.439266041998053\n",
      "INFO:__main__:prompt_tokens=3909\n",
      "INFO:__main__:completion_tokens=38\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3909, completion_tokens=38, latency=1.4393\n",
      "INFO:__main__:e_idx=1/2, chunk_index=33/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3971\n",
      "INFO:bedrock_predictor:Claude completion tokens: 67\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01V9ijJCqB89uuuL8Cz1i4im', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The Naismith Award is presented in the sport of basketball. The passage states that the Naismith Legacy Award is presented to \"players, coaches and other individuals or organizations from the game of basketball\" to honor their role in furthering the values of \"Honor, Respect and Integrity, both on and off the court.\"'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3757, 'output_tokens': 72}, 'generated_text': 'The Naismith Award is presented in the sport of basketball. The passage states that the Naismith Legacy Award is presented to \"players, coaches and other individuals or organizations from the game of basketball\" to honor their role in furthering the values of \"Honor, Respect and Integrity, both on and off the court.\"'}, 'latency': 2.380026792001445, 'prompt_tokens': 3971, 'completion_tokens': 67}\n",
      "INFO:__main__:response_json={'id': 'msg_01V9ijJCqB89uuuL8Cz1i4im', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The Naismith Award is presented in the sport of basketball. The passage states that the Naismith Legacy Award is presented to \"players, coaches and other individuals or organizations from the game of basketball\" to honor their role in furthering the values of \"Honor, Respect and Integrity, both on and off the court.\"'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3757, 'output_tokens': 72}, 'generated_text': 'The Naismith Award is presented in the sport of basketball. The passage states that the Naismith Legacy Award is presented to \"players, coaches and other individuals or organizations from the game of basketball\" to honor their role in furthering the values of \"Honor, Respect and Integrity, both on and off the court.\"'}\n",
      "INFO:__main__:latency=2.380026792001445\n",
      "INFO:__main__:prompt_tokens=3971\n",
      "INFO:__main__:completion_tokens=67\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3971, completion_tokens=67, latency=2.3800\n",
      "INFO:__main__:e_idx=1/2, chunk_index=34/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3132\n",
      "INFO:bedrock_predictor:Claude completion tokens: 28\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_018qosBP4x66hqb7Q8LcSKKq', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the information provided in the passage, the event that took place at Lord's Cricket Ground during the London 2012 Olympics was archery.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2930, 'output_tokens': 34}, 'generated_text': \"Based on the information provided in the passage, the event that took place at Lord's Cricket Ground during the London 2012 Olympics was archery.\"}, 'latency': 1.103548375001992, 'prompt_tokens': 3132, 'completion_tokens': 28}\n",
      "INFO:__main__:response_json={'id': 'msg_018qosBP4x66hqb7Q8LcSKKq', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the information provided in the passage, the event that took place at Lord's Cricket Ground during the London 2012 Olympics was archery.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2930, 'output_tokens': 34}, 'generated_text': \"Based on the information provided in the passage, the event that took place at Lord's Cricket Ground during the London 2012 Olympics was archery.\"}\n",
      "INFO:__main__:latency=1.103548375001992\n",
      "INFO:__main__:prompt_tokens=3132\n",
      "INFO:__main__:completion_tokens=28\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3132, completion_tokens=28, latency=1.1035\n",
      "INFO:__main__:e_idx=1/2, chunk_index=35/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3135\n",
      "INFO:bedrock_predictor:Claude completion tokens: 21\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01KbK3RjD2aZ8LPdNUQPYoir', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"The names of Donald Duck's three nephews are Huey, Dewey, and Louie.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2914, 'output_tokens': 26}, 'generated_text': \"The names of Donald Duck's three nephews are Huey, Dewey, and Louie.\"}, 'latency': 0.9229415419977158, 'prompt_tokens': 3135, 'completion_tokens': 21}\n",
      "INFO:__main__:response_json={'id': 'msg_01KbK3RjD2aZ8LPdNUQPYoir', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"The names of Donald Duck's three nephews are Huey, Dewey, and Louie.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2914, 'output_tokens': 26}, 'generated_text': \"The names of Donald Duck's three nephews are Huey, Dewey, and Louie.\"}\n",
      "INFO:__main__:latency=0.9229415419977158\n",
      "INFO:__main__:prompt_tokens=3135\n",
      "INFO:__main__:completion_tokens=21\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3135, completion_tokens=21, latency=0.9229\n",
      "INFO:__main__:e_idx=1/2, chunk_index=36/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3030\n",
      "INFO:bedrock_predictor:Claude completion tokens: 69\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_013FWWqdLXXtmE4tkeqdtinQ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Muhammad Ali (formerly known as Cassius Clay) was the boxer who was stripped of his heavyweight boxing titles when he refused to be inducted into the U.S. Army in April 1967. The passage states that the boxing authorities in America stripped Ali of his world heavyweight title and suspended his boxing license after he refused to be inducted.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2896, 'output_tokens': 72}, 'generated_text': 'Muhammad Ali (formerly known as Cassius Clay) was the boxer who was stripped of his heavyweight boxing titles when he refused to be inducted into the U.S. Army in April 1967. The passage states that the boxing authorities in America stripped Ali of his world heavyweight title and suspended his boxing license after he refused to be inducted.'}, 'latency': 1.5692496249976102, 'prompt_tokens': 3030, 'completion_tokens': 69}\n",
      "INFO:__main__:response_json={'id': 'msg_013FWWqdLXXtmE4tkeqdtinQ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Muhammad Ali (formerly known as Cassius Clay) was the boxer who was stripped of his heavyweight boxing titles when he refused to be inducted into the U.S. Army in April 1967. The passage states that the boxing authorities in America stripped Ali of his world heavyweight title and suspended his boxing license after he refused to be inducted.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2896, 'output_tokens': 72}, 'generated_text': 'Muhammad Ali (formerly known as Cassius Clay) was the boxer who was stripped of his heavyweight boxing titles when he refused to be inducted into the U.S. Army in April 1967. The passage states that the boxing authorities in America stripped Ali of his world heavyweight title and suspended his boxing license after he refused to be inducted.'}\n",
      "INFO:__main__:latency=1.5692496249976102\n",
      "INFO:__main__:prompt_tokens=3030\n",
      "INFO:__main__:completion_tokens=69\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3030, completion_tokens=69, latency=1.5692\n",
      "INFO:__main__:e_idx=1/2, chunk_index=37/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3848\n",
      "INFO:bedrock_predictor:Claude completion tokens: 28\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01HydbV5UNPYoNw7AzvYkX9N', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Aldo Moro, a former Italian Prime Minister, was kidnapped by the Red Brigade in 1978 and killed after 55 days in captivity.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3606, 'output_tokens': 39}, 'generated_text': 'Aldo Moro, a former Italian Prime Minister, was kidnapped by the Red Brigade in 1978 and killed after 55 days in captivity.'}, 'latency': 1.2798516250040848, 'prompt_tokens': 3848, 'completion_tokens': 28}\n",
      "INFO:__main__:response_json={'id': 'msg_01HydbV5UNPYoNw7AzvYkX9N', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Aldo Moro, a former Italian Prime Minister, was kidnapped by the Red Brigade in 1978 and killed after 55 days in captivity.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3606, 'output_tokens': 39}, 'generated_text': 'Aldo Moro, a former Italian Prime Minister, was kidnapped by the Red Brigade in 1978 and killed after 55 days in captivity.'}\n",
      "INFO:__main__:latency=1.2798516250040848\n",
      "INFO:__main__:prompt_tokens=3848\n",
      "INFO:__main__:completion_tokens=28\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3848, completion_tokens=28, latency=1.2799\n",
      "INFO:__main__:e_idx=1/2, chunk_index=38/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3208\n",
      "INFO:bedrock_predictor:Claude completion tokens: 28\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01JfxMPv3pzfmAgZ39NdkvvC', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Cary Grant\\n\\nCary Grant was the stage name used by the British-born American film actor Archibald Alec Leach.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2972, 'output_tokens': 36}, 'generated_text': 'Cary Grant\\n\\nCary Grant was the stage name used by the British-born American film actor Archibald Alec Leach.'}, 'latency': 1.097735167000792, 'prompt_tokens': 3208, 'completion_tokens': 28}\n",
      "INFO:__main__:response_json={'id': 'msg_01JfxMPv3pzfmAgZ39NdkvvC', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Cary Grant\\n\\nCary Grant was the stage name used by the British-born American film actor Archibald Alec Leach.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2972, 'output_tokens': 36}, 'generated_text': 'Cary Grant\\n\\nCary Grant was the stage name used by the British-born American film actor Archibald Alec Leach.'}\n",
      "INFO:__main__:latency=1.097735167000792\n",
      "INFO:__main__:prompt_tokens=3208\n",
      "INFO:__main__:completion_tokens=28\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3208, completion_tokens=28, latency=1.0977\n",
      "INFO:__main__:e_idx=1/2, chunk_index=39/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3475\n",
      "INFO:bedrock_predictor:Claude completion tokens: 62\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_015S3eMgiDMvHAfuj3vySFoh', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Unfortunately, the passage provided does not contain information about Blondie's last UK #1 hit of the 1980s. The passage is about the top 10 Blondie songs, but does not specifically mention their last UK #1 hit of that decade. I do not have enough information to answer this question.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3242, 'output_tokens': 73}, 'generated_text': \"Unfortunately, the passage provided does not contain information about Blondie's last UK #1 hit of the 1980s. The passage is about the top 10 Blondie songs, but does not specifically mention their last UK #1 hit of that decade. I do not have enough information to answer this question.\"}, 'latency': 1.390088874992216, 'prompt_tokens': 3475, 'completion_tokens': 62}\n",
      "INFO:__main__:response_json={'id': 'msg_015S3eMgiDMvHAfuj3vySFoh', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Unfortunately, the passage provided does not contain information about Blondie's last UK #1 hit of the 1980s. The passage is about the top 10 Blondie songs, but does not specifically mention their last UK #1 hit of that decade. I do not have enough information to answer this question.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3242, 'output_tokens': 73}, 'generated_text': \"Unfortunately, the passage provided does not contain information about Blondie's last UK #1 hit of the 1980s. The passage is about the top 10 Blondie songs, but does not specifically mention their last UK #1 hit of that decade. I do not have enough information to answer this question.\"}\n",
      "INFO:__main__:latency=1.390088874992216\n",
      "INFO:__main__:prompt_tokens=3475\n",
      "INFO:__main__:completion_tokens=62\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3475, completion_tokens=62, latency=1.3901\n",
      "INFO:__main__:e_idx=1/2, chunk_index=40/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3681\n",
      "INFO:bedrock_predictor:Claude completion tokens: 69\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01XK1Gyqkp5FXdFNVnqYUh1x', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A traditional hoy boat is powered by sails. The passage states that hoys were sloop-rigged, meaning they had a single mast with a mainsail and a jib sail, and that they used the wind to propel themselves, particularly in navigating the estuaries and coastal waters where they were commonly used.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3517, 'output_tokens': 73}, 'generated_text': 'A traditional hoy boat is powered by sails. The passage states that hoys were sloop-rigged, meaning they had a single mast with a mainsail and a jib sail, and that they used the wind to propel themselves, particularly in navigating the estuaries and coastal waters where they were commonly used.'}, 'latency': 2.1549686249927618, 'prompt_tokens': 3681, 'completion_tokens': 69}\n",
      "INFO:__main__:response_json={'id': 'msg_01XK1Gyqkp5FXdFNVnqYUh1x', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A traditional hoy boat is powered by sails. The passage states that hoys were sloop-rigged, meaning they had a single mast with a mainsail and a jib sail, and that they used the wind to propel themselves, particularly in navigating the estuaries and coastal waters where they were commonly used.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3517, 'output_tokens': 73}, 'generated_text': 'A traditional hoy boat is powered by sails. The passage states that hoys were sloop-rigged, meaning they had a single mast with a mainsail and a jib sail, and that they used the wind to propel themselves, particularly in navigating the estuaries and coastal waters where they were commonly used.'}\n",
      "INFO:__main__:latency=2.1549686249927618\n",
      "INFO:__main__:prompt_tokens=3681\n",
      "INFO:__main__:completion_tokens=69\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3681, completion_tokens=69, latency=2.1550\n",
      "INFO:__main__:e_idx=1/2, chunk_index=41/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3581\n",
      "INFO:bedrock_predictor:Claude completion tokens: 106\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01FmYDdkSCZ89YQMQXvHScNU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, Matthew Webb was the first recorded person to swim the English Channel without the use of artificial aids for sport purpose. After his record-setting Channel swim in 1875, Webb's final stunt was to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls, a feat that many observers considered suicidal. While Webb may have successfully survived the first part of the swim, the passage states that he died in the section of the river located near the entrance to the whirlpool.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3334, 'output_tokens': 118}, 'generated_text': \"According to the passage, Matthew Webb was the first recorded person to swim the English Channel without the use of artificial aids for sport purpose. After his record-setting Channel swim in 1875, Webb's final stunt was to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls, a feat that many observers considered suicidal. While Webb may have successfully survived the first part of the swim, the passage states that he died in the section of the river located near the entrance to the whirlpool.\"}, 'latency': 1.7017690840002615, 'prompt_tokens': 3581, 'completion_tokens': 106}\n",
      "INFO:__main__:response_json={'id': 'msg_01FmYDdkSCZ89YQMQXvHScNU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, Matthew Webb was the first recorded person to swim the English Channel without the use of artificial aids for sport purpose. After his record-setting Channel swim in 1875, Webb's final stunt was to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls, a feat that many observers considered suicidal. While Webb may have successfully survived the first part of the swim, the passage states that he died in the section of the river located near the entrance to the whirlpool.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3334, 'output_tokens': 118}, 'generated_text': \"According to the passage, Matthew Webb was the first recorded person to swim the English Channel without the use of artificial aids for sport purpose. After his record-setting Channel swim in 1875, Webb's final stunt was to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls, a feat that many observers considered suicidal. While Webb may have successfully survived the first part of the swim, the passage states that he died in the section of the river located near the entrance to the whirlpool.\"}\n",
      "INFO:__main__:latency=1.7017690840002615\n",
      "INFO:__main__:prompt_tokens=3581\n",
      "INFO:__main__:completion_tokens=106\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3581, completion_tokens=106, latency=1.7018\n",
      "INFO:__main__:e_idx=1/2, chunk_index=42/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3302\n",
      "INFO:bedrock_predictor:Claude completion tokens: 27\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01XvNoQnDufezaRLjvHQaiWU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The passage states that Alexander Graham Bell and his team first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3042, 'output_tokens': 32}, 'generated_text': 'The passage states that Alexander Graham Bell and his team first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}, 'latency': 1.15408579200448, 'prompt_tokens': 3302, 'completion_tokens': 27}\n",
      "INFO:__main__:response_json={'id': 'msg_01XvNoQnDufezaRLjvHQaiWU', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The passage states that Alexander Graham Bell and his team first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3042, 'output_tokens': 32}, 'generated_text': 'The passage states that Alexander Graham Bell and his team first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}\n",
      "INFO:__main__:latency=1.15408579200448\n",
      "INFO:__main__:prompt_tokens=3302\n",
      "INFO:__main__:completion_tokens=27\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3302, completion_tokens=27, latency=1.1541\n",
      "INFO:__main__:e_idx=1/2, chunk_index=43/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3614\n",
      "INFO:bedrock_predictor:Claude completion tokens: 50\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01GtschHKVbDftqWmjY9zPwS', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the city known as the \"Pearl of the Danube\" is Budapest. The passage mentions that the Danube Waltz river cruise explores \"the range of architectural wonders in Budapest and Bratislava\".'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3365, 'output_tokens': 54}, 'generated_text': 'According to the information provided, the city known as the \"Pearl of the Danube\" is Budapest. The passage mentions that the Danube Waltz river cruise explores \"the range of architectural wonders in Budapest and Bratislava\".'}, 'latency': 1.437327916995855, 'prompt_tokens': 3614, 'completion_tokens': 50}\n",
      "INFO:__main__:response_json={'id': 'msg_01GtschHKVbDftqWmjY9zPwS', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the information provided, the city known as the \"Pearl of the Danube\" is Budapest. The passage mentions that the Danube Waltz river cruise explores \"the range of architectural wonders in Budapest and Bratislava\".'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3365, 'output_tokens': 54}, 'generated_text': 'According to the information provided, the city known as the \"Pearl of the Danube\" is Budapest. The passage mentions that the Danube Waltz river cruise explores \"the range of architectural wonders in Budapest and Bratislava\".'}\n",
      "INFO:__main__:latency=1.437327916995855\n",
      "INFO:__main__:prompt_tokens=3614\n",
      "INFO:__main__:completion_tokens=50\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3614, completion_tokens=50, latency=1.4373\n",
      "INFO:__main__:e_idx=1/2, chunk_index=44/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3537\n",
      "INFO:bedrock_predictor:Claude completion tokens: 34\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01YLvnoD6w8i1b5TpszDbspX', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3321, 'output_tokens': 42}, 'generated_text': 'According to the passage, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}, 'latency': 1.0884941669937689, 'prompt_tokens': 3537, 'completion_tokens': 34}\n",
      "INFO:__main__:response_json={'id': 'msg_01YLvnoD6w8i1b5TpszDbspX', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3321, 'output_tokens': 42}, 'generated_text': 'According to the passage, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}\n",
      "INFO:__main__:latency=1.0884941669937689\n",
      "INFO:__main__:prompt_tokens=3537\n",
      "INFO:__main__:completion_tokens=34\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3537, completion_tokens=34, latency=1.0885\n",
      "INFO:__main__:e_idx=1/2, chunk_index=45/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3165\n",
      "INFO:bedrock_predictor:Claude completion tokens: 62\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01KVULJDmXCDzRYeucXG1r4G', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Gary Busey played the role of Buddy Holly in the 1978 film The Buddy Holly Story. The passage states that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\"'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2963, 'output_tokens': 72}, 'generated_text': 'Gary Busey played the role of Buddy Holly in the 1978 film The Buddy Holly Story. The passage states that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\"'}, 'latency': 1.3326556669926504, 'prompt_tokens': 3165, 'completion_tokens': 62}\n",
      "INFO:__main__:response_json={'id': 'msg_01KVULJDmXCDzRYeucXG1r4G', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Gary Busey played the role of Buddy Holly in the 1978 film The Buddy Holly Story. The passage states that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\"'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2963, 'output_tokens': 72}, 'generated_text': 'Gary Busey played the role of Buddy Holly in the 1978 film The Buddy Holly Story. The passage states that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\"'}\n",
      "INFO:__main__:latency=1.3326556669926504\n",
      "INFO:__main__:prompt_tokens=3165\n",
      "INFO:__main__:completion_tokens=62\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3165, completion_tokens=62, latency=1.3327\n",
      "INFO:__main__:e_idx=1/2, chunk_index=46/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3476\n",
      "INFO:bedrock_predictor:Claude completion tokens: 24\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_019xuZ1ZtzijYvb5FgK1Lc2N', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the passage, the character of Miss Pugh on the Tony Hancock radio show was played by Hattie Jacques.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3244, 'output_tokens': 31}, 'generated_text': 'Based on the passage, the character of Miss Pugh on the Tony Hancock radio show was played by Hattie Jacques.'}, 'latency': 1.35375500000373, 'prompt_tokens': 3476, 'completion_tokens': 24}\n",
      "INFO:__main__:response_json={'id': 'msg_019xuZ1ZtzijYvb5FgK1Lc2N', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the passage, the character of Miss Pugh on the Tony Hancock radio show was played by Hattie Jacques.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3244, 'output_tokens': 31}, 'generated_text': 'Based on the passage, the character of Miss Pugh on the Tony Hancock radio show was played by Hattie Jacques.'}\n",
      "INFO:__main__:latency=1.35375500000373\n",
      "INFO:__main__:prompt_tokens=3476\n",
      "INFO:__main__:completion_tokens=24\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3476, completion_tokens=24, latency=1.3538\n",
      "INFO:__main__:e_idx=1/2, chunk_index=47/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3235\n",
      "INFO:bedrock_predictor:Claude completion tokens: 31\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01VvBT6uwqEckfqsXeMDSsJo', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Nadine Coyle was born in Derry, Northern Ireland and was a member of the all-girl pop group Girls Aloud from the UK.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2994, 'output_tokens': 37}, 'generated_text': 'Nadine Coyle was born in Derry, Northern Ireland and was a member of the all-girl pop group Girls Aloud from the UK.'}, 'latency': 1.337912957998924, 'prompt_tokens': 3235, 'completion_tokens': 31}\n",
      "INFO:__main__:response_json={'id': 'msg_01VvBT6uwqEckfqsXeMDSsJo', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Nadine Coyle was born in Derry, Northern Ireland and was a member of the all-girl pop group Girls Aloud from the UK.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2994, 'output_tokens': 37}, 'generated_text': 'Nadine Coyle was born in Derry, Northern Ireland and was a member of the all-girl pop group Girls Aloud from the UK.'}\n",
      "INFO:__main__:latency=1.337912957998924\n",
      "INFO:__main__:prompt_tokens=3235\n",
      "INFO:__main__:completion_tokens=31\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3235, completion_tokens=31, latency=1.3379\n",
      "INFO:__main__:e_idx=1/2, chunk_index=48/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3363\n",
      "INFO:bedrock_predictor:Claude completion tokens: 21\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01D3YgYjLg9yRC9GM9W7HfDS', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The Uffizi and the Bargello are among the museums of art in Florence, Italy.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3218, 'output_tokens': 24}, 'generated_text': 'The Uffizi and the Bargello are among the museums of art in Florence, Italy.'}, 'latency': 1.0839249999989988, 'prompt_tokens': 3363, 'completion_tokens': 21}\n",
      "INFO:__main__:response_json={'id': 'msg_01D3YgYjLg9yRC9GM9W7HfDS', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The Uffizi and the Bargello are among the museums of art in Florence, Italy.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3218, 'output_tokens': 24}, 'generated_text': 'The Uffizi and the Bargello are among the museums of art in Florence, Italy.'}\n",
      "INFO:__main__:latency=1.0839249999989988\n",
      "INFO:__main__:prompt_tokens=3363\n",
      "INFO:__main__:completion_tokens=21\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3363, completion_tokens=21, latency=1.0839\n",
      "INFO:__main__:e_idx=1/2, chunk_index=49/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3882\n",
      "INFO:bedrock_predictor:Claude completion tokens: 128\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01UA6A7ByrbzN3Jk9rybKuY5', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A guillemot is a type of seabird in the auk family. Specifically, guillemots are part of the Uria and Cepphus genera. In British use, the term \"guillemot\" refers to both Uria and Cepphus species, while in North America, the Uria species are called \"murres\" and only the Cepphus species are called \"guillemots\". The guillemot is known for its distinctive white belly, thicker and longer bill compared to the Cepphus species, and its tendency to form very dense colonies on cliffs during the breeding season.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3590, 'output_tokens': 141}, 'generated_text': 'A guillemot is a type of seabird in the auk family. Specifically, guillemots are part of the Uria and Cepphus genera. In British use, the term \"guillemot\" refers to both Uria and Cepphus species, while in North America, the Uria species are called \"murres\" and only the Cepphus species are called \"guillemots\". The guillemot is known for its distinctive white belly, thicker and longer bill compared to the Cepphus species, and its tendency to form very dense colonies on cliffs during the breeding season.'}, 'latency': 2.987478708004346, 'prompt_tokens': 3882, 'completion_tokens': 128}\n",
      "INFO:__main__:response_json={'id': 'msg_01UA6A7ByrbzN3Jk9rybKuY5', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A guillemot is a type of seabird in the auk family. Specifically, guillemots are part of the Uria and Cepphus genera. In British use, the term \"guillemot\" refers to both Uria and Cepphus species, while in North America, the Uria species are called \"murres\" and only the Cepphus species are called \"guillemots\". The guillemot is known for its distinctive white belly, thicker and longer bill compared to the Cepphus species, and its tendency to form very dense colonies on cliffs during the breeding season.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3590, 'output_tokens': 141}, 'generated_text': 'A guillemot is a type of seabird in the auk family. Specifically, guillemots are part of the Uria and Cepphus genera. In British use, the term \"guillemot\" refers to both Uria and Cepphus species, while in North America, the Uria species are called \"murres\" and only the Cepphus species are called \"guillemots\". The guillemot is known for its distinctive white belly, thicker and longer bill compared to the Cepphus species, and its tendency to form very dense colonies on cliffs during the breeding season.'}\n",
      "INFO:__main__:latency=2.987478708004346\n",
      "INFO:__main__:prompt_tokens=3882\n",
      "INFO:__main__:completion_tokens=128\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3882, completion_tokens=128, latency=2.9875\n",
      "INFO:__main__:e_idx=1/2, chunk_index=50/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3616\n",
      "INFO:bedrock_predictor:Claude completion tokens: 56\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01MWa6yb3xePjmziVP7Y3HLZ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the song \"Dakota\" by the Welsh band Stereophonics was their first single to reach #1 on the UK Singles Chart. It was released on February 28, 2005 and spent a total of 20 weeks on the UK singles chart.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3343, 'output_tokens': 64}, 'generated_text': 'According to the passage, the song \"Dakota\" by the Welsh band Stereophonics was their first single to reach #1 on the UK Singles Chart. It was released on February 28, 2005 and spent a total of 20 weeks on the UK singles chart.'}, 'latency': 1.3318093749985565, 'prompt_tokens': 3616, 'completion_tokens': 56}\n",
      "INFO:__main__:response_json={'id': 'msg_01MWa6yb3xePjmziVP7Y3HLZ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the song \"Dakota\" by the Welsh band Stereophonics was their first single to reach #1 on the UK Singles Chart. It was released on February 28, 2005 and spent a total of 20 weeks on the UK singles chart.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3343, 'output_tokens': 64}, 'generated_text': 'According to the passage, the song \"Dakota\" by the Welsh band Stereophonics was their first single to reach #1 on the UK Singles Chart. It was released on February 28, 2005 and spent a total of 20 weeks on the UK singles chart.'}\n",
      "INFO:__main__:latency=1.3318093749985565\n",
      "INFO:__main__:prompt_tokens=3616\n",
      "INFO:__main__:completion_tokens=56\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3616, completion_tokens=56, latency=1.3318\n",
      "INFO:__main__:e_idx=1/2, chunk_index=51/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3567\n",
      "INFO:bedrock_predictor:Claude completion tokens: 54\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_017uppu3zC4LDb424bTUotVo', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the passage, the counter-intelligence agency whose name meant \"Death to Spies\" in English was SMERSH. The passage states that the player controls Semion Strogov, a captain in the Soviet counterintelligence agency named SMERSH.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3356, 'output_tokens': 63}, 'generated_text': 'Based on the passage, the counter-intelligence agency whose name meant \"Death to Spies\" in English was SMERSH. The passage states that the player controls Semion Strogov, a captain in the Soviet counterintelligence agency named SMERSH.'}, 'latency': 1.8361036669957684, 'prompt_tokens': 3567, 'completion_tokens': 54}\n",
      "INFO:__main__:response_json={'id': 'msg_017uppu3zC4LDb424bTUotVo', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the passage, the counter-intelligence agency whose name meant \"Death to Spies\" in English was SMERSH. The passage states that the player controls Semion Strogov, a captain in the Soviet counterintelligence agency named SMERSH.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3356, 'output_tokens': 63}, 'generated_text': 'Based on the passage, the counter-intelligence agency whose name meant \"Death to Spies\" in English was SMERSH. The passage states that the player controls Semion Strogov, a captain in the Soviet counterintelligence agency named SMERSH.'}\n",
      "INFO:__main__:latency=1.8361036669957684\n",
      "INFO:__main__:prompt_tokens=3567\n",
      "INFO:__main__:completion_tokens=54\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3567, completion_tokens=54, latency=1.8361\n",
      "INFO:__main__:e_idx=1/2, chunk_index=52/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3330\n",
      "INFO:bedrock_predictor:Claude completion tokens: 19\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01RCvSwAZpGRkzNTQ3pZt33t', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3071, 'output_tokens': 23}, 'generated_text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}, 'latency': 1.078618125000503, 'prompt_tokens': 3330, 'completion_tokens': 19}\n",
      "INFO:__main__:response_json={'id': 'msg_01RCvSwAZpGRkzNTQ3pZt33t', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3071, 'output_tokens': 23}, 'generated_text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}\n",
      "INFO:__main__:latency=1.078618125000503\n",
      "INFO:__main__:prompt_tokens=3330\n",
      "INFO:__main__:completion_tokens=19\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3330, completion_tokens=19, latency=1.0786\n",
      "INFO:__main__:e_idx=1/2, chunk_index=53/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3566\n",
      "INFO:bedrock_predictor:Claude completion tokens: 23\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01UHFafC5sWGtE6DbpyRA5S2', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3393, 'output_tokens': 29}, 'generated_text': 'The main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick.'}, 'latency': 1.0354307500092546, 'prompt_tokens': 3566, 'completion_tokens': 23}\n",
      "INFO:__main__:response_json={'id': 'msg_01UHFafC5sWGtE6DbpyRA5S2', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3393, 'output_tokens': 29}, 'generated_text': 'The main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick.'}\n",
      "INFO:__main__:latency=1.0354307500092546\n",
      "INFO:__main__:prompt_tokens=3566\n",
      "INFO:__main__:completion_tokens=23\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3566, completion_tokens=23, latency=1.0354\n",
      "INFO:__main__:e_idx=1/2, chunk_index=54/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3497\n",
      "INFO:bedrock_predictor:Claude completion tokens: 17\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01WpatNkWo2sfuPczESCrS72', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The English cities of Gloucester and Worcester are located on the River Severn.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3276, 'output_tokens': 20}, 'generated_text': 'The English cities of Gloucester and Worcester are located on the River Severn.'}, 'latency': 0.908573584005353, 'prompt_tokens': 3497, 'completion_tokens': 17}\n",
      "INFO:__main__:response_json={'id': 'msg_01WpatNkWo2sfuPczESCrS72', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The English cities of Gloucester and Worcester are located on the River Severn.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3276, 'output_tokens': 20}, 'generated_text': 'The English cities of Gloucester and Worcester are located on the River Severn.'}\n",
      "INFO:__main__:latency=0.908573584005353\n",
      "INFO:__main__:prompt_tokens=3497\n",
      "INFO:__main__:completion_tokens=17\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3497, completion_tokens=17, latency=0.9086\n",
      "INFO:__main__:e_idx=1/2, chunk_index=55/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3003\n",
      "INFO:bedrock_predictor:Claude completion tokens: 24\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_012bFC1kLiJqWKR7d29ZxS8v', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"The musical instrument with the Italian name fagotto, which means 'bundle of sticks', is the bassoon.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2815, 'output_tokens': 27}, 'generated_text': \"The musical instrument with the Italian name fagotto, which means 'bundle of sticks', is the bassoon.\"}, 'latency': 0.9905333329952555, 'prompt_tokens': 3003, 'completion_tokens': 24}\n",
      "INFO:__main__:response_json={'id': 'msg_012bFC1kLiJqWKR7d29ZxS8v', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"The musical instrument with the Italian name fagotto, which means 'bundle of sticks', is the bassoon.\"}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2815, 'output_tokens': 27}, 'generated_text': \"The musical instrument with the Italian name fagotto, which means 'bundle of sticks', is the bassoon.\"}\n",
      "INFO:__main__:latency=0.9905333329952555\n",
      "INFO:__main__:prompt_tokens=3003\n",
      "INFO:__main__:completion_tokens=24\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3003, completion_tokens=24, latency=0.9905\n",
      "INFO:__main__:e_idx=1/2, chunk_index=56/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3783\n",
      "INFO:bedrock_predictor:Claude completion tokens: 29\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_012ffpV5YuphVpk8NQDh1G9K', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\".'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3447, 'output_tokens': 33}, 'generated_text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\".'}, 'latency': 0.930397374992026, 'prompt_tokens': 3783, 'completion_tokens': 29}\n",
      "INFO:__main__:response_json={'id': 'msg_012ffpV5YuphVpk8NQDh1G9K', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\".'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3447, 'output_tokens': 33}, 'generated_text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\".'}\n",
      "INFO:__main__:latency=0.930397374992026\n",
      "INFO:__main__:prompt_tokens=3783\n",
      "INFO:__main__:completion_tokens=29\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3783, completion_tokens=29, latency=0.9304\n",
      "INFO:__main__:e_idx=1/2, chunk_index=57/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-haiku-20240307-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-haiku-20240307-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3271\n",
      "INFO:bedrock_predictor:Claude completion tokens: 33\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01AkXFhZVBkqUSsKuncVbGXf', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3118, 'output_tokens': 37}, 'generated_text': 'According to the passage, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}, 'latency': 0.9273305420065299, 'prompt_tokens': 3271, 'completion_tokens': 33}\n",
      "INFO:__main__:response_json={'id': 'msg_01AkXFhZVBkqUSsKuncVbGXf', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}], 'model': 'claude-3-haiku-48k-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3118, 'output_tokens': 37}, 'generated_text': 'According to the passage, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}\n",
      "INFO:__main__:latency=0.9273305420065299\n",
      "INFO:__main__:prompt_tokens=3271\n",
      "INFO:__main__:completion_tokens=33\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-haiku-20240307-v1:0, prompt_tokens = 3271, completion_tokens=33, latency=0.9273\n",
      "INFO:__main__:the haiku-bedrock-trial ran for 126.60784579100437 seconds......\n",
      "INFO:__main__:metrics json is: {'experiment_name': 'haiku-bedrock-trial', 'concurrency': 1, 'payload_file': 'payload_en_3000-4000.jsonl', 'errors': [], 'successes': 1, 'error_rate': 0.0, 'all_prompts_token_count': 3271, 'prompt_token_count_mean': 3271.0, 'prompt_token_throughput': 3216.76, 'all_completions_token_count': 33, 'completion_token_count_mean': 33.0, 'completion_token_throughput': 32.45, 'transactions': 1, 'transactions_per_second': 0.98, 'transactions_per_minute': 58, 'latency_mean': 0.9273305420065299}\n",
      "INFO:bedrock_predictor:pricing dict: {'input-per-1k-tokens': 0.00025}\n",
      "INFO:bedrock_predictor:input per 1k token pricing: 0.00025\n",
      "INFO:bedrock_predictor:pricing dict: {'output-per-1k-tokens': 0.00125}\n",
      "INFO:bedrock_predictor:output per 1k token pricing: 0.00125\n",
      "INFO:__main__:the rate for running haiku-bedrock-trial running on Claudev3-Haiku-ODT for 126.60784579100437 is $0.000859....\n",
      "INFO:__main__:experiment=1/2, name=haiku-bedrock-trial, duration=126.61 seconds, done\n",
      "INFO:__main__:endpoint info found is: []\n",
      "INFO:__main__:experiment name=claude-3-sonnet, custom bring your own ep_name=anthropic.claude-3-sonnet-20240229-v1:0\n",
      "INFO:__main__:Using fmbench.scripts directory: /Users/madhurpt/Desktop/foundation-model-benchmarking-tool-5/src/fmbench/scripts\n",
      "INFO:__main__:script provided for inference from this model is --> bedrock_predictor\n",
      "INFO:__main__:script path is --> /Users/madhurpt/Desktop/foundation-model-benchmarking-tool-5/src/fmbench/scripts/bedrock_predictor.py\n",
      "INFO:__main__:Deploying using local code: /Users/madhurpt/Desktop/foundation-model-benchmarking-tool-5/src/fmbench/scripts/bedrock_predictor.py\n",
      "INFO:bedrock_predictor:__init__ self._predictor=<botocore.client.BedrockRuntime object at 0x281839a10>\n",
      "INFO:__main__:there are 1 combinations of [(1, 'payload_en_3000-4000.jsonl')] to run\n",
      "INFO:__main__:s3 path where the payload files are being read from -> fmbench-claude-ab3/data/prompts/payload_en_3000-4000.jsonl\n",
      "INFO:__main__:read from s3://sagemaker-fmbench-write-121797993273/fmbench-claude-ab3/data/prompts/payload_en_3000-4000.jsonl, contains 57 lines\n",
      "INFO:__main__:creating combinations for concurrency=1, payload_file=payload_en_3000-4000.jsonl, payload_list length=57\n",
      "INFO:__main__:after only retaining chunks of length 1, we have 57 chunks, previously we had 57 chunks\n",
      "INFO:__main__:there are 1 for {'name': 'claude-3-sonnet', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0', 'model_version': '*', 'model_name': 'claude-3-sonnet', 'ep_name': 'anthropic.claude-3-sonnet-20240229-v1:0', 'instance_type': 'Claudev3-Sonnet-ODT', 'image_uri': None, 'deploy': False, 'instance_count': 1, 'deployment_script': None, 'inference_script': 'bedrock_predictor.py', 'payload_files': ['payload_en_3000-4000.jsonl'], 'concurrency_levels': [1], 'env': None}\n",
      "INFO:__main__:e_idx=2/2, chunk_index=1/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3000\n",
      "INFO:bedrock_predictor:Claude completion tokens: 25\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_013WZCZwaD7wDnJSuSHjSK2F', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Indradhanura Chhai came out earlier in 1993, while The Death of Black King is a 1971 Czechoslovak film.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2923, 'output_tokens': 36}, 'generated_text': 'Indradhanura Chhai came out earlier in 1993, while The Death of Black King is a 1971 Czechoslovak film.'}, 'latency': 3.3010361670021666, 'prompt_tokens': 3000, 'completion_tokens': 25}\n",
      "INFO:__main__:response_json={'id': 'msg_013WZCZwaD7wDnJSuSHjSK2F', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Indradhanura Chhai came out earlier in 1993, while The Death of Black King is a 1971 Czechoslovak film.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2923, 'output_tokens': 36}, 'generated_text': 'Indradhanura Chhai came out earlier in 1993, while The Death of Black King is a 1971 Czechoslovak film.'}\n",
      "INFO:__main__:latency=3.3010361670021666\n",
      "INFO:__main__:prompt_tokens=3000\n",
      "INFO:__main__:completion_tokens=25\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3000, completion_tokens=25, latency=3.3010\n",
      "INFO:__main__:e_idx=2/2, chunk_index=2/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3896\n",
      "INFO:bedrock_predictor:Claude completion tokens: 58\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_018eHZCGLZnFQir1BQka4Fyq', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Peter Rosegger (born 1843) was younger than Ruel \"Pete\" Redinger (born 1896). The passages state that Rosegger was an Austrian writer and poet from the 19th century, while Redinger was an American football player in the early 20th century.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3765, 'output_tokens': 70}, 'generated_text': 'Peter Rosegger (born 1843) was younger than Ruel \"Pete\" Redinger (born 1896). The passages state that Rosegger was an Austrian writer and poet from the 19th century, while Redinger was an American football player in the early 20th century.'}, 'latency': 5.483078375007608, 'prompt_tokens': 3896, 'completion_tokens': 58}\n",
      "INFO:__main__:response_json={'id': 'msg_018eHZCGLZnFQir1BQka4Fyq', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Peter Rosegger (born 1843) was younger than Ruel \"Pete\" Redinger (born 1896). The passages state that Rosegger was an Austrian writer and poet from the 19th century, while Redinger was an American football player in the early 20th century.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3765, 'output_tokens': 70}, 'generated_text': 'Peter Rosegger (born 1843) was younger than Ruel \"Pete\" Redinger (born 1896). The passages state that Rosegger was an Austrian writer and poet from the 19th century, while Redinger was an American football player in the early 20th century.'}\n",
      "INFO:__main__:latency=5.483078375007608\n",
      "INFO:__main__:prompt_tokens=3896\n",
      "INFO:__main__:completion_tokens=58\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3896, completion_tokens=58, latency=5.4831\n",
      "INFO:__main__:e_idx=2/2, chunk_index=3/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3789\n",
      "INFO:bedrock_predictor:Claude completion tokens: 58\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_016d7wCdCMwPuD9NLtsVg2KK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Erich Haenisch died in 1966, while William Pooley died in 1629. Therefore, William Pooley died first, several centuries before Erich Haenisch. Erich Haenisch was a German sinologist who lived from 1880 to 1966.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3533, 'output_tokens': 77}, 'generated_text': 'Based on the information provided, Erich Haenisch died in 1966, while William Pooley died in 1629. Therefore, William Pooley died first, several centuries before Erich Haenisch. Erich Haenisch was a German sinologist who lived from 1880 to 1966.'}, 'latency': 4.4306421669898555, 'prompt_tokens': 3789, 'completion_tokens': 58}\n",
      "INFO:__main__:response_json={'id': 'msg_016d7wCdCMwPuD9NLtsVg2KK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Erich Haenisch died in 1966, while William Pooley died in 1629. Therefore, William Pooley died first, several centuries before Erich Haenisch. Erich Haenisch was a German sinologist who lived from 1880 to 1966.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3533, 'output_tokens': 77}, 'generated_text': 'Based on the information provided, Erich Haenisch died in 1966, while William Pooley died in 1629. Therefore, William Pooley died first, several centuries before Erich Haenisch. Erich Haenisch was a German sinologist who lived from 1880 to 1966.'}\n",
      "INFO:__main__:latency=4.4306421669898555\n",
      "INFO:__main__:prompt_tokens=3789\n",
      "INFO:__main__:completion_tokens=58\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3789, completion_tokens=58, latency=4.4306\n",
      "INFO:__main__:e_idx=2/2, chunk_index=4/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3450\n",
      "INFO:bedrock_predictor:Claude completion tokens: 71\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_0114vwjAweUCo1njYocqnfcK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passages, John William Noell, the father of Thomas E. Noell, died in Washington, D.C. The relevant excerpt states: \"He served from March 4, 1859, until his death on March 14, 1863, in Washington, D.C. He was interred in St. Mary\\'s Cemetery, in Perryville.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3249, 'output_tokens': 85}, 'generated_text': 'According to the passages, John William Noell, the father of Thomas E. Noell, died in Washington, D.C. The relevant excerpt states: \"He served from March 4, 1859, until his death on March 14, 1863, in Washington, D.C. He was interred in St. Mary\\'s Cemetery, in Perryville.\"'}, 'latency': 4.799612500006333, 'prompt_tokens': 3450, 'completion_tokens': 71}\n",
      "INFO:__main__:response_json={'id': 'msg_0114vwjAweUCo1njYocqnfcK', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passages, John William Noell, the father of Thomas E. Noell, died in Washington, D.C. The relevant excerpt states: \"He served from March 4, 1859, until his death on March 14, 1863, in Washington, D.C. He was interred in St. Mary\\'s Cemetery, in Perryville.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3249, 'output_tokens': 85}, 'generated_text': 'According to the passages, John William Noell, the father of Thomas E. Noell, died in Washington, D.C. The relevant excerpt states: \"He served from March 4, 1859, until his death on March 14, 1863, in Washington, D.C. He was interred in St. Mary\\'s Cemetery, in Perryville.\"'}\n",
      "INFO:__main__:latency=4.799612500006333\n",
      "INFO:__main__:prompt_tokens=3450\n",
      "INFO:__main__:completion_tokens=71\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3450, completion_tokens=71, latency=4.7996\n",
      "INFO:__main__:e_idx=2/2, chunk_index=5/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3482\n",
      "INFO:bedrock_predictor:Claude completion tokens: 53\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01C3GuU3AbGUBoCMTb9QtnKV', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a former Chinese and German table tennis player, while Johann Christian Gustav Lucae was a German anatomist from Frankfurt am Main.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3345, 'output_tokens': 58}, 'generated_text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a former Chinese and German table tennis player, while Johann Christian Gustav Lucae was a German anatomist from Frankfurt am Main.'}, 'latency': 5.928255458013155, 'prompt_tokens': 3482, 'completion_tokens': 53}\n",
      "INFO:__main__:response_json={'id': 'msg_01C3GuU3AbGUBoCMTb9QtnKV', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a former Chinese and German table tennis player, while Johann Christian Gustav Lucae was a German anatomist from Frankfurt am Main.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3345, 'output_tokens': 58}, 'generated_text': 'No, Ding Yaping and Johann Christian Gustav Lucae are not of the same nationality. Ding Yaping is a former Chinese and German table tennis player, while Johann Christian Gustav Lucae was a German anatomist from Frankfurt am Main.'}\n",
      "INFO:__main__:latency=5.928255458013155\n",
      "INFO:__main__:prompt_tokens=3482\n",
      "INFO:__main__:completion_tokens=53\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3482, completion_tokens=53, latency=5.9283\n",
      "INFO:__main__:e_idx=2/2, chunk_index=6/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3144\n",
      "INFO:bedrock_predictor:Claude completion tokens: 72\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01BfRBGAsk7cPbw1c5JFGZ6K', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Unfortunately, I could not find the date of death for P. Neelakantan, the director of the 1961 Tamil film Nallavan Vazhvan, in the given passages. The biographical details provided only mention his birth year of 1916 and that he was an active film director for nearly four decades, but do not specify his date of death.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2990, 'output_tokens': 83}, 'generated_text': 'Unfortunately, I could not find the date of death for P. Neelakantan, the director of the 1961 Tamil film Nallavan Vazhvan, in the given passages. The biographical details provided only mention his birth year of 1916 and that he was an active film director for nearly four decades, but do not specify his date of death.'}, 'latency': 4.89268108298711, 'prompt_tokens': 3144, 'completion_tokens': 72}\n",
      "INFO:__main__:response_json={'id': 'msg_01BfRBGAsk7cPbw1c5JFGZ6K', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Unfortunately, I could not find the date of death for P. Neelakantan, the director of the 1961 Tamil film Nallavan Vazhvan, in the given passages. The biographical details provided only mention his birth year of 1916 and that he was an active film director for nearly four decades, but do not specify his date of death.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2990, 'output_tokens': 83}, 'generated_text': 'Unfortunately, I could not find the date of death for P. Neelakantan, the director of the 1961 Tamil film Nallavan Vazhvan, in the given passages. The biographical details provided only mention his birth year of 1916 and that he was an active film director for nearly four decades, but do not specify his date of death.'}\n",
      "INFO:__main__:latency=4.89268108298711\n",
      "INFO:__main__:prompt_tokens=3144\n",
      "INFO:__main__:completion_tokens=72\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3144, completion_tokens=72, latency=4.8927\n",
      "INFO:__main__:e_idx=2/2, chunk_index=7/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3639\n",
      "INFO:bedrock_predictor:Claude completion tokens: 75\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_018XyoPr9TnrkRGzuQJU2XEE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Sandflow (1937) was directed by Lesley Selander, while Folgore Division (1955) was directed by Duilio Coletti. Lesley Selander lived from 1900 to 1979, while Duilio Coletti lived from 1906 to 1999. Therefore, the director who died first was Lesley Selander, the director of Sandflow.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 103}, 'generated_text': 'Based on the information provided, Sandflow (1937) was directed by Lesley Selander, while Folgore Division (1955) was directed by Duilio Coletti. Lesley Selander lived from 1900 to 1979, while Duilio Coletti lived from 1906 to 1999. Therefore, the director who died first was Lesley Selander, the director of Sandflow.'}, 'latency': 4.755831499991473, 'prompt_tokens': 3639, 'completion_tokens': 75}\n",
      "INFO:__main__:response_json={'id': 'msg_018XyoPr9TnrkRGzuQJU2XEE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Sandflow (1937) was directed by Lesley Selander, while Folgore Division (1955) was directed by Duilio Coletti. Lesley Selander lived from 1900 to 1979, while Duilio Coletti lived from 1906 to 1999. Therefore, the director who died first was Lesley Selander, the director of Sandflow.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 103}, 'generated_text': 'Based on the information provided, Sandflow (1937) was directed by Lesley Selander, while Folgore Division (1955) was directed by Duilio Coletti. Lesley Selander lived from 1900 to 1979, while Duilio Coletti lived from 1906 to 1999. Therefore, the director who died first was Lesley Selander, the director of Sandflow.'}\n",
      "INFO:__main__:latency=4.755831499991473\n",
      "INFO:__main__:prompt_tokens=3639\n",
      "INFO:__main__:completion_tokens=75\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3639, completion_tokens=75, latency=4.7558\n",
      "INFO:__main__:e_idx=2/2, chunk_index=8/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3014\n",
      "INFO:bedrock_predictor:Claude completion tokens: 23\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01LoHDSquf8sMqM2xDKf2c55', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Alberta, Canada.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2816, 'output_tokens': 27}, 'generated_text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Alberta, Canada.'}, 'latency': 2.213023125004838, 'prompt_tokens': 3014, 'completion_tokens': 23}\n",
      "INFO:__main__:response_json={'id': 'msg_01LoHDSquf8sMqM2xDKf2c55', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Alberta, Canada.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2816, 'output_tokens': 27}, 'generated_text': 'Yes, Edmonton/Twin Island Airpark and Mayerthorpe Airport are both located in Alberta, Canada.'}\n",
      "INFO:__main__:latency=2.213023125004838\n",
      "INFO:__main__:prompt_tokens=3014\n",
      "INFO:__main__:completion_tokens=23\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3014, completion_tokens=23, latency=2.2130\n",
      "INFO:__main__:e_idx=2/2, chunk_index=9/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3891\n",
      "INFO:bedrock_predictor:Claude completion tokens: 69\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01GRjhr6HU76HDbHpHwNttZX', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Full Length LP by Guttermouth was released more recently than Blow in the Wind by Me First and the Gimme Gimmes. Full Length LP is Guttermouth's debut album released in 1991, while Blow in the Wind is Me First and the Gimme Gimmes' third album released in 2001.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3662, 'output_tokens': 76}, 'generated_text': \"Full Length LP by Guttermouth was released more recently than Blow in the Wind by Me First and the Gimme Gimmes. Full Length LP is Guttermouth's debut album released in 1991, while Blow in the Wind is Me First and the Gimme Gimmes' third album released in 2001.\"}, 'latency': 3.8162164590030443, 'prompt_tokens': 3891, 'completion_tokens': 69}\n",
      "INFO:__main__:response_json={'id': 'msg_01GRjhr6HU76HDbHpHwNttZX', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Full Length LP by Guttermouth was released more recently than Blow in the Wind by Me First and the Gimme Gimmes. Full Length LP is Guttermouth's debut album released in 1991, while Blow in the Wind is Me First and the Gimme Gimmes' third album released in 2001.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3662, 'output_tokens': 76}, 'generated_text': \"Full Length LP by Guttermouth was released more recently than Blow in the Wind by Me First and the Gimme Gimmes. Full Length LP is Guttermouth's debut album released in 1991, while Blow in the Wind is Me First and the Gimme Gimmes' third album released in 2001.\"}\n",
      "INFO:__main__:latency=3.8162164590030443\n",
      "INFO:__main__:prompt_tokens=3891\n",
      "INFO:__main__:completion_tokens=69\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3891, completion_tokens=69, latency=3.8162\n",
      "INFO:__main__:e_idx=2/2, chunk_index=10/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3575\n",
      "INFO:bedrock_predictor:Claude completion tokens: 66\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01AEgVFDAHT5SBRoBgZTwAG3', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, Kakwa River and Bighead River are not located in the same country. Based on the given context, Kakwa River is located in western Alberta, Canada, while Bighead River is located in Grey County in southern Ontario, Canada. So while they are both rivers in Canada, they are in different provinces.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3419, 'output_tokens': 71}, 'generated_text': 'No, Kakwa River and Bighead River are not located in the same country. Based on the given context, Kakwa River is located in western Alberta, Canada, while Bighead River is located in Grey County in southern Ontario, Canada. So while they are both rivers in Canada, they are in different provinces.'}, 'latency': 4.405986042009317, 'prompt_tokens': 3575, 'completion_tokens': 66}\n",
      "INFO:__main__:response_json={'id': 'msg_01AEgVFDAHT5SBRoBgZTwAG3', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'No, Kakwa River and Bighead River are not located in the same country. Based on the given context, Kakwa River is located in western Alberta, Canada, while Bighead River is located in Grey County in southern Ontario, Canada. So while they are both rivers in Canada, they are in different provinces.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3419, 'output_tokens': 71}, 'generated_text': 'No, Kakwa River and Bighead River are not located in the same country. Based on the given context, Kakwa River is located in western Alberta, Canada, while Bighead River is located in Grey County in southern Ontario, Canada. So while they are both rivers in Canada, they are in different provinces.'}\n",
      "INFO:__main__:latency=4.405986042009317\n",
      "INFO:__main__:prompt_tokens=3575\n",
      "INFO:__main__:completion_tokens=66\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3575, completion_tokens=66, latency=4.4060\n",
      "INFO:__main__:e_idx=2/2, chunk_index=11/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3419\n",
      "INFO:bedrock_predictor:Claude completion tokens: 72\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01TnYA93kQSWHeG3DufkbbfH', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the given passages, Kerem nan (born March 25, 1980) is younger than Vrindavan Lal Verma (born January 9, 1889). Vrindavan Lal Verma was a Hindi novelist and playwright who was born in 1889, while Kerem nan is a Turkish professional football goalkeeper who was born in 1980.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 91}, 'generated_text': 'Based on the given passages, Kerem nan (born March 25, 1980) is younger than Vrindavan Lal Verma (born January 9, 1889). Vrindavan Lal Verma was a Hindi novelist and playwright who was born in 1889, while Kerem nan is a Turkish professional football goalkeeper who was born in 1980.'}, 'latency': 4.904388459006441, 'prompt_tokens': 3419, 'completion_tokens': 72}\n",
      "INFO:__main__:response_json={'id': 'msg_01TnYA93kQSWHeG3DufkbbfH', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the given passages, Kerem nan (born March 25, 1980) is younger than Vrindavan Lal Verma (born January 9, 1889). Vrindavan Lal Verma was a Hindi novelist and playwright who was born in 1889, while Kerem nan is a Turkish professional football goalkeeper who was born in 1980.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3291, 'output_tokens': 91}, 'generated_text': 'Based on the given passages, Kerem nan (born March 25, 1980) is younger than Vrindavan Lal Verma (born January 9, 1889). Vrindavan Lal Verma was a Hindi novelist and playwright who was born in 1889, while Kerem nan is a Turkish professional football goalkeeper who was born in 1980.'}\n",
      "INFO:__main__:latency=4.904388459006441\n",
      "INFO:__main__:prompt_tokens=3419\n",
      "INFO:__main__:completion_tokens=72\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3419, completion_tokens=72, latency=4.9044\n",
      "INFO:__main__:e_idx=2/2, chunk_index=12/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3458\n",
      "INFO:bedrock_predictor:Claude completion tokens: 91\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01WXiFFkkLkAu1h17CqhxA7B', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passages, the date of death of William Jolliffe, 4th Baron Hylton\\'s father, Hylton George Hylton Jolliffe, 3rd Baron Hylton, was 26 May 1945. This is stated in Passage 8: \"Hylton George Hylton Jolliffe, 3rd Baron Hylton (10 November 1862  26 May 1945) was a British peer and Conservative politician.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3289, 'output_tokens': 120}, 'generated_text': 'Based on the provided passages, the date of death of William Jolliffe, 4th Baron Hylton\\'s father, Hylton George Hylton Jolliffe, 3rd Baron Hylton, was 26 May 1945. This is stated in Passage 8: \"Hylton George Hylton Jolliffe, 3rd Baron Hylton (10 November 1862  26 May 1945) was a British peer and Conservative politician.\"'}, 'latency': 4.628281874989625, 'prompt_tokens': 3458, 'completion_tokens': 91}\n",
      "INFO:__main__:response_json={'id': 'msg_01WXiFFkkLkAu1h17CqhxA7B', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passages, the date of death of William Jolliffe, 4th Baron Hylton\\'s father, Hylton George Hylton Jolliffe, 3rd Baron Hylton, was 26 May 1945. This is stated in Passage 8: \"Hylton George Hylton Jolliffe, 3rd Baron Hylton (10 November 1862  26 May 1945) was a British peer and Conservative politician.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3289, 'output_tokens': 120}, 'generated_text': 'Based on the provided passages, the date of death of William Jolliffe, 4th Baron Hylton\\'s father, Hylton George Hylton Jolliffe, 3rd Baron Hylton, was 26 May 1945. This is stated in Passage 8: \"Hylton George Hylton Jolliffe, 3rd Baron Hylton (10 November 1862  26 May 1945) was a British peer and Conservative politician.\"'}\n",
      "INFO:__main__:latency=4.628281874989625\n",
      "INFO:__main__:prompt_tokens=3458\n",
      "INFO:__main__:completion_tokens=91\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3458, completion_tokens=91, latency=4.6283\n",
      "INFO:__main__:e_idx=2/2, chunk_index=13/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3508\n",
      "INFO:bedrock_predictor:Claude completion tokens: 50\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01VCvgE8MQAwN6TWhGFbgfkV', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passages, I could not find information about who the father of the director of the film \"Sources of Life\" is. The passages mention details about the film and its cast, but do not provide information about the director\\'s family.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3385, 'output_tokens': 53}, 'generated_text': 'Based on the provided passages, I could not find information about who the father of the director of the film \"Sources of Life\" is. The passages mention details about the film and its cast, but do not provide information about the director\\'s family.'}, 'latency': 4.4467558749893215, 'prompt_tokens': 3508, 'completion_tokens': 50}\n",
      "INFO:__main__:response_json={'id': 'msg_01VCvgE8MQAwN6TWhGFbgfkV', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passages, I could not find information about who the father of the director of the film \"Sources of Life\" is. The passages mention details about the film and its cast, but do not provide information about the director\\'s family.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3385, 'output_tokens': 53}, 'generated_text': 'Based on the provided passages, I could not find information about who the father of the director of the film \"Sources of Life\" is. The passages mention details about the film and its cast, but do not provide information about the director\\'s family.'}\n",
      "INFO:__main__:latency=4.4467558749893215\n",
      "INFO:__main__:prompt_tokens=3508\n",
      "INFO:__main__:completion_tokens=50\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3508, completion_tokens=50, latency=4.4468\n",
      "INFO:__main__:e_idx=2/2, chunk_index=14/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3436\n",
      "INFO:bedrock_predictor:Claude completion tokens: 104\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01HaXquLozWX5uGuFLXh1Aff', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, the film \"Where Are You? I\\'m Here\" (Italian: Dove siete? Io sono qui) came out in 1993, while \"Patnam Vachina Pativrathalu\" was released in 1982. So \"Patnam Vachina Pativrathalu\", which is a Telugu remake of the 1980 Kannada film \"Pattanakke Banda Pathniyaru\", came out earlier than \"Where Are You? I\\'m Here\".'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3427, 'output_tokens': 122}, 'generated_text': 'Based on the information provided, the film \"Where Are You? I\\'m Here\" (Italian: Dove siete? Io sono qui) came out in 1993, while \"Patnam Vachina Pativrathalu\" was released in 1982. So \"Patnam Vachina Pativrathalu\", which is a Telugu remake of the 1980 Kannada film \"Pattanakke Banda Pathniyaru\", came out earlier than \"Where Are You? I\\'m Here\".'}, 'latency': 5.390240458000335, 'prompt_tokens': 3436, 'completion_tokens': 104}\n",
      "INFO:__main__:response_json={'id': 'msg_01HaXquLozWX5uGuFLXh1Aff', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, the film \"Where Are You? I\\'m Here\" (Italian: Dove siete? Io sono qui) came out in 1993, while \"Patnam Vachina Pativrathalu\" was released in 1982. So \"Patnam Vachina Pativrathalu\", which is a Telugu remake of the 1980 Kannada film \"Pattanakke Banda Pathniyaru\", came out earlier than \"Where Are You? I\\'m Here\".'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3427, 'output_tokens': 122}, 'generated_text': 'Based on the information provided, the film \"Where Are You? I\\'m Here\" (Italian: Dove siete? Io sono qui) came out in 1993, while \"Patnam Vachina Pativrathalu\" was released in 1982. So \"Patnam Vachina Pativrathalu\", which is a Telugu remake of the 1980 Kannada film \"Pattanakke Banda Pathniyaru\", came out earlier than \"Where Are You? I\\'m Here\".'}\n",
      "INFO:__main__:latency=5.390240458000335\n",
      "INFO:__main__:prompt_tokens=3436\n",
      "INFO:__main__:completion_tokens=104\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3436, completion_tokens=104, latency=5.3902\n",
      "INFO:__main__:e_idx=2/2, chunk_index=15/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3249\n",
      "INFO:bedrock_predictor:Claude completion tokens: 70\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01DDXQ7bpDLhTMHaoP4wPaSv', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Unfortunately, the given passages do not appear to mention who Charles James Irwin Grant's paternal grandfather was. The passages provide details about Charles James Irwin Grant himself, his wife, children, and some other relatives like his father Charles William Grant, 5th Baron de Longueuil. However, there is no information given about his paternal grandfather specifically.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3065, 'output_tokens': 80}, 'generated_text': \"Unfortunately, the given passages do not appear to mention who Charles James Irwin Grant's paternal grandfather was. The passages provide details about Charles James Irwin Grant himself, his wife, children, and some other relatives like his father Charles William Grant, 5th Baron de Longueuil. However, there is no information given about his paternal grandfather specifically.\"}, 'latency': 5.906184292005491, 'prompt_tokens': 3249, 'completion_tokens': 70}\n",
      "INFO:__main__:response_json={'id': 'msg_01DDXQ7bpDLhTMHaoP4wPaSv', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Unfortunately, the given passages do not appear to mention who Charles James Irwin Grant's paternal grandfather was. The passages provide details about Charles James Irwin Grant himself, his wife, children, and some other relatives like his father Charles William Grant, 5th Baron de Longueuil. However, there is no information given about his paternal grandfather specifically.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3065, 'output_tokens': 80}, 'generated_text': \"Unfortunately, the given passages do not appear to mention who Charles James Irwin Grant's paternal grandfather was. The passages provide details about Charles James Irwin Grant himself, his wife, children, and some other relatives like his father Charles William Grant, 5th Baron de Longueuil. However, there is no information given about his paternal grandfather specifically.\"}\n",
      "INFO:__main__:latency=5.906184292005491\n",
      "INFO:__main__:prompt_tokens=3249\n",
      "INFO:__main__:completion_tokens=70\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3249, completion_tokens=70, latency=5.9062\n",
      "INFO:__main__:e_idx=2/2, chunk_index=16/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3087\n",
      "INFO:bedrock_predictor:Claude completion tokens: 58\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01Qh5GUmJdSLjvVRF8ktP3op', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the provided information, Steve Barancik was born earlier than Helen Clifton. Barancik's date of birth is given as September 23, 1961, while Clifton's date of birth is May 4, 1948. Therefore, Steve Barancik was born earlier.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2593, 'output_tokens': 70}, 'generated_text': \"Based on the provided information, Steve Barancik was born earlier than Helen Clifton. Barancik's date of birth is given as September 23, 1961, while Clifton's date of birth is May 4, 1948. Therefore, Steve Barancik was born earlier.\"}, 'latency': 4.740846040993347, 'prompt_tokens': 3087, 'completion_tokens': 58}\n",
      "INFO:__main__:response_json={'id': 'msg_01Qh5GUmJdSLjvVRF8ktP3op', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the provided information, Steve Barancik was born earlier than Helen Clifton. Barancik's date of birth is given as September 23, 1961, while Clifton's date of birth is May 4, 1948. Therefore, Steve Barancik was born earlier.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2593, 'output_tokens': 70}, 'generated_text': \"Based on the provided information, Steve Barancik was born earlier than Helen Clifton. Barancik's date of birth is given as September 23, 1961, while Clifton's date of birth is May 4, 1948. Therefore, Steve Barancik was born earlier.\"}\n",
      "INFO:__main__:latency=4.740846040993347\n",
      "INFO:__main__:prompt_tokens=3087\n",
      "INFO:__main__:completion_tokens=58\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3087, completion_tokens=58, latency=4.7408\n",
      "INFO:__main__:e_idx=2/2, chunk_index=17/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3680\n",
      "INFO:bedrock_predictor:Claude completion tokens: 52\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_015ceGgsTzCkDiB58RqSpPii', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Susan, Crown Princess of Albania (Susan Cullen-Ward), the mother of Leka, Crown Prince of Albania (born 1982), died of lung cancer on 17 July 2004 in Tirana, Albania.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3479, 'output_tokens': 59}, 'generated_text': 'According to the passage, Susan, Crown Princess of Albania (Susan Cullen-Ward), the mother of Leka, Crown Prince of Albania (born 1982), died of lung cancer on 17 July 2004 in Tirana, Albania.'}, 'latency': 3.5302339589979965, 'prompt_tokens': 3680, 'completion_tokens': 52}\n",
      "INFO:__main__:response_json={'id': 'msg_015ceGgsTzCkDiB58RqSpPii', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Susan, Crown Princess of Albania (Susan Cullen-Ward), the mother of Leka, Crown Prince of Albania (born 1982), died of lung cancer on 17 July 2004 in Tirana, Albania.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3479, 'output_tokens': 59}, 'generated_text': 'According to the passage, Susan, Crown Princess of Albania (Susan Cullen-Ward), the mother of Leka, Crown Prince of Albania (born 1982), died of lung cancer on 17 July 2004 in Tirana, Albania.'}\n",
      "INFO:__main__:latency=3.5302339589979965\n",
      "INFO:__main__:prompt_tokens=3680\n",
      "INFO:__main__:completion_tokens=52\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3680, completion_tokens=52, latency=3.5302\n",
      "INFO:__main__:e_idx=2/2, chunk_index=18/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3950\n",
      "INFO:bedrock_predictor:Claude completion tokens: 38\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01KtpQ8SRN2CrcooTbsx469q', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Band-e-Amir Dragons is named after the series of six deep blue lakes in Band-e Amir National Park, Afghanistan's first national park located in Bamyan Province.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3621, 'output_tokens': 43}, 'generated_text': \"Band-e-Amir Dragons is named after the series of six deep blue lakes in Band-e Amir National Park, Afghanistan's first national park located in Bamyan Province.\"}, 'latency': 3.184990749999997, 'prompt_tokens': 3950, 'completion_tokens': 38}\n",
      "INFO:__main__:response_json={'id': 'msg_01KtpQ8SRN2CrcooTbsx469q', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Band-e-Amir Dragons is named after the series of six deep blue lakes in Band-e Amir National Park, Afghanistan's first national park located in Bamyan Province.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3621, 'output_tokens': 43}, 'generated_text': \"Band-e-Amir Dragons is named after the series of six deep blue lakes in Band-e Amir National Park, Afghanistan's first national park located in Bamyan Province.\"}\n",
      "INFO:__main__:latency=3.184990749999997\n",
      "INFO:__main__:prompt_tokens=3950\n",
      "INFO:__main__:completion_tokens=38\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3950, completion_tokens=38, latency=3.1850\n",
      "INFO:__main__:e_idx=2/2, chunk_index=19/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3463\n",
      "INFO:bedrock_predictor:Claude completion tokens: 86\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01XS5ynyFGr8gXP8HveCBFpE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The radio station that serves the area comprising all of Belknap County, among others, is WVNH (91.1 FM). According to Passage 10, WVNH is a radio station broadcasting a Christian radio format and licensed to Concord, New Hampshire. It serves the Concord and Franklin areas as well as the Lakes Region, which is described in Passage 2 as comprising all of Belknap County.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3284, 'output_tokens': 99}, 'generated_text': 'The radio station that serves the area comprising all of Belknap County, among others, is WVNH (91.1 FM). According to Passage 10, WVNH is a radio station broadcasting a Christian radio format and licensed to Concord, New Hampshire. It serves the Concord and Franklin areas as well as the Lakes Region, which is described in Passage 2 as comprising all of Belknap County.'}, 'latency': 4.343781291987398, 'prompt_tokens': 3463, 'completion_tokens': 86}\n",
      "INFO:__main__:response_json={'id': 'msg_01XS5ynyFGr8gXP8HveCBFpE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The radio station that serves the area comprising all of Belknap County, among others, is WVNH (91.1 FM). According to Passage 10, WVNH is a radio station broadcasting a Christian radio format and licensed to Concord, New Hampshire. It serves the Concord and Franklin areas as well as the Lakes Region, which is described in Passage 2 as comprising all of Belknap County.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3284, 'output_tokens': 99}, 'generated_text': 'The radio station that serves the area comprising all of Belknap County, among others, is WVNH (91.1 FM). According to Passage 10, WVNH is a radio station broadcasting a Christian radio format and licensed to Concord, New Hampshire. It serves the Concord and Franklin areas as well as the Lakes Region, which is described in Passage 2 as comprising all of Belknap County.'}\n",
      "INFO:__main__:latency=4.343781291987398\n",
      "INFO:__main__:prompt_tokens=3463\n",
      "INFO:__main__:completion_tokens=86\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3463, completion_tokens=86, latency=4.3438\n",
      "INFO:__main__:e_idx=2/2, chunk_index=20/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3996\n",
      "INFO:bedrock_predictor:Claude completion tokens: 41\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01EGPYphZwKhhfMoGs13Jxau', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passages, the village of Shienga is located in the East Mamprusi District of Ghana. The capital town of the East Mamprusi Municipal District is Gambaga.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3684, 'output_tokens': 46}, 'generated_text': 'Based on the provided passages, the village of Shienga is located in the East Mamprusi District of Ghana. The capital town of the East Mamprusi Municipal District is Gambaga.'}, 'latency': 3.723303875012789, 'prompt_tokens': 3996, 'completion_tokens': 41}\n",
      "INFO:__main__:response_json={'id': 'msg_01EGPYphZwKhhfMoGs13Jxau', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passages, the village of Shienga is located in the East Mamprusi District of Ghana. The capital town of the East Mamprusi Municipal District is Gambaga.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3684, 'output_tokens': 46}, 'generated_text': 'Based on the provided passages, the village of Shienga is located in the East Mamprusi District of Ghana. The capital town of the East Mamprusi Municipal District is Gambaga.'}\n",
      "INFO:__main__:latency=3.723303875012789\n",
      "INFO:__main__:prompt_tokens=3996\n",
      "INFO:__main__:completion_tokens=41\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3996, completion_tokens=41, latency=3.7233\n",
      "INFO:__main__:e_idx=2/2, chunk_index=21/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3050\n",
      "INFO:bedrock_predictor:Claude completion tokens: 97\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_011Rv62T8D3aoC5bvsY5i1WH', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the provided context, Tim Cluess has been the head coach of the Iona Gaels men's basketball team for a longer period than Steve Prohm has been a head coach. The passages mention that Cluess was in his 6th or 7th season as Iona's head coach in 2015-16 and 2016-17, while Prohm was in his 1st season as head coach of Iowa State in 2015-16 after previously being the head coach at Murray State.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2903, 'output_tokens': 122}, 'generated_text': \"Based on the provided context, Tim Cluess has been the head coach of the Iona Gaels men's basketball team for a longer period than Steve Prohm has been a head coach. The passages mention that Cluess was in his 6th or 7th season as Iona's head coach in 2015-16 and 2016-17, while Prohm was in his 1st season as head coach of Iowa State in 2015-16 after previously being the head coach at Murray State.\"}, 'latency': 4.610216291999677, 'prompt_tokens': 3050, 'completion_tokens': 97}\n",
      "INFO:__main__:response_json={'id': 'msg_011Rv62T8D3aoC5bvsY5i1WH', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the provided context, Tim Cluess has been the head coach of the Iona Gaels men's basketball team for a longer period than Steve Prohm has been a head coach. The passages mention that Cluess was in his 6th or 7th season as Iona's head coach in 2015-16 and 2016-17, while Prohm was in his 1st season as head coach of Iowa State in 2015-16 after previously being the head coach at Murray State.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2903, 'output_tokens': 122}, 'generated_text': \"Based on the provided context, Tim Cluess has been the head coach of the Iona Gaels men's basketball team for a longer period than Steve Prohm has been a head coach. The passages mention that Cluess was in his 6th or 7th season as Iona's head coach in 2015-16 and 2016-17, while Prohm was in his 1st season as head coach of Iowa State in 2015-16 after previously being the head coach at Murray State.\"}\n",
      "INFO:__main__:latency=4.610216291999677\n",
      "INFO:__main__:prompt_tokens=3050\n",
      "INFO:__main__:completion_tokens=97\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3050, completion_tokens=97, latency=4.6102\n",
      "INFO:__main__:e_idx=2/2, chunk_index=22/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3737\n",
      "INFO:bedrock_predictor:Claude completion tokens: 38\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01B4MRVrEWcuPWx4st1sXEnM', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passages, Jim Rasenberger is a contributor to Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3488, 'output_tokens': 43}, 'generated_text': 'According to the passages, Jim Rasenberger is a contributor to Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}, 'latency': 3.694953500002157, 'prompt_tokens': 3737, 'completion_tokens': 38}\n",
      "INFO:__main__:response_json={'id': 'msg_01B4MRVrEWcuPWx4st1sXEnM', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passages, Jim Rasenberger is a contributor to Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3488, 'output_tokens': 43}, 'generated_text': 'According to the passages, Jim Rasenberger is a contributor to Smithsonian magazine, which is the official journal published by the Smithsonian Institution in Washington, D.C.'}\n",
      "INFO:__main__:latency=3.694953500002157\n",
      "INFO:__main__:prompt_tokens=3737\n",
      "INFO:__main__:completion_tokens=38\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3737, completion_tokens=38, latency=3.6950\n",
      "INFO:__main__:e_idx=2/2, chunk_index=23/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3410\n",
      "INFO:bedrock_predictor:Claude completion tokens: 38\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01EVyHPqr5XUkGbpVqPQdJme', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passages, the genus Deutzia has around 60 species, while the genus Cassiope has 9-12 species. Therefore, Deutzia has more species than Cassiope.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3314, 'output_tokens': 49}, 'generated_text': 'According to the passages, the genus Deutzia has around 60 species, while the genus Cassiope has 9-12 species. Therefore, Deutzia has more species than Cassiope.'}, 'latency': 3.5898669159942074, 'prompt_tokens': 3410, 'completion_tokens': 38}\n",
      "INFO:__main__:response_json={'id': 'msg_01EVyHPqr5XUkGbpVqPQdJme', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passages, the genus Deutzia has around 60 species, while the genus Cassiope has 9-12 species. Therefore, Deutzia has more species than Cassiope.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3314, 'output_tokens': 49}, 'generated_text': 'According to the passages, the genus Deutzia has around 60 species, while the genus Cassiope has 9-12 species. Therefore, Deutzia has more species than Cassiope.'}\n",
      "INFO:__main__:latency=3.5898669159942074\n",
      "INFO:__main__:prompt_tokens=3410\n",
      "INFO:__main__:completion_tokens=38\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3410, completion_tokens=38, latency=3.5899\n",
      "INFO:__main__:e_idx=2/2, chunk_index=24/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3979\n",
      "INFO:bedrock_predictor:Claude completion tokens: 71\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01VAbhKqjy8WB6DuUWazUbqs', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the provided context, Peter Curtis and Scott Draper were both professional tennis players. Peter Curtis is mentioned as a former British professional tennis player who won a Grand Slam mixed doubles title with his wife. Scott Draper is described as an Australian former tennis player who won titles like the Australian Open mixed doubles and the Queen's Club Championships singles event.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3720, 'output_tokens': 76}, 'generated_text': \"Based on the provided context, Peter Curtis and Scott Draper were both professional tennis players. Peter Curtis is mentioned as a former British professional tennis player who won a Grand Slam mixed doubles title with his wife. Scott Draper is described as an Australian former tennis player who won titles like the Australian Open mixed doubles and the Queen's Club Championships singles event.\"}, 'latency': 4.7581827500107465, 'prompt_tokens': 3979, 'completion_tokens': 71}\n",
      "INFO:__main__:response_json={'id': 'msg_01VAbhKqjy8WB6DuUWazUbqs', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Based on the provided context, Peter Curtis and Scott Draper were both professional tennis players. Peter Curtis is mentioned as a former British professional tennis player who won a Grand Slam mixed doubles title with his wife. Scott Draper is described as an Australian former tennis player who won titles like the Australian Open mixed doubles and the Queen's Club Championships singles event.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3720, 'output_tokens': 76}, 'generated_text': \"Based on the provided context, Peter Curtis and Scott Draper were both professional tennis players. Peter Curtis is mentioned as a former British professional tennis player who won a Grand Slam mixed doubles title with his wife. Scott Draper is described as an Australian former tennis player who won titles like the Australian Open mixed doubles and the Queen's Club Championships singles event.\"}\n",
      "INFO:__main__:latency=4.7581827500107465\n",
      "INFO:__main__:prompt_tokens=3979\n",
      "INFO:__main__:completion_tokens=71\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3979, completion_tokens=71, latency=4.7582\n",
      "INFO:__main__:e_idx=2/2, chunk_index=25/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3171\n",
      "INFO:bedrock_predictor:Claude completion tokens: 37\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01GqZLnjXmGLt1VC8wfAckQ8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Jacob Minah set his personal best of 8099 points in the decathlon event at the 2007 Summer Universiade in Bangkok, Thailand, where he won the gold medal.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2922, 'output_tokens': 44}, 'generated_text': 'Jacob Minah set his personal best of 8099 points in the decathlon event at the 2007 Summer Universiade in Bangkok, Thailand, where he won the gold medal.'}, 'latency': 3.5448587919963757, 'prompt_tokens': 3171, 'completion_tokens': 37}\n",
      "INFO:__main__:response_json={'id': 'msg_01GqZLnjXmGLt1VC8wfAckQ8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Jacob Minah set his personal best of 8099 points in the decathlon event at the 2007 Summer Universiade in Bangkok, Thailand, where he won the gold medal.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2922, 'output_tokens': 44}, 'generated_text': 'Jacob Minah set his personal best of 8099 points in the decathlon event at the 2007 Summer Universiade in Bangkok, Thailand, where he won the gold medal.'}\n",
      "INFO:__main__:latency=3.5448587919963757\n",
      "INFO:__main__:prompt_tokens=3171\n",
      "INFO:__main__:completion_tokens=37\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3171, completion_tokens=37, latency=3.5449\n",
      "INFO:__main__:e_idx=2/2, chunk_index=26/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3655\n",
      "INFO:bedrock_predictor:Claude completion tokens: 61\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01Hd4qK7KpbNukW3jvvccaKE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Euptelea and Muehlenbeckia are both genera. Euptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. Muehlenbeckia is a genus of flowering plants in the family Polygonaceae with around 24 species.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3505, 'output_tokens': 73}, 'generated_text': 'Yes, Euptelea and Muehlenbeckia are both genera. Euptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. Muehlenbeckia is a genus of flowering plants in the family Polygonaceae with around 24 species.'}, 'latency': 3.6434488749946468, 'prompt_tokens': 3655, 'completion_tokens': 61}\n",
      "INFO:__main__:response_json={'id': 'msg_01Hd4qK7KpbNukW3jvvccaKE', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Yes, Euptelea and Muehlenbeckia are both genera. Euptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. Muehlenbeckia is a genus of flowering plants in the family Polygonaceae with around 24 species.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3505, 'output_tokens': 73}, 'generated_text': 'Yes, Euptelea and Muehlenbeckia are both genera. Euptelea is a genus of two species of flowering plants in the monogeneric family Eupteleaceae. Muehlenbeckia is a genus of flowering plants in the family Polygonaceae with around 24 species.'}\n",
      "INFO:__main__:latency=3.6434488749946468\n",
      "INFO:__main__:prompt_tokens=3655\n",
      "INFO:__main__:completion_tokens=61\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3655, completion_tokens=61, latency=3.6434\n",
      "INFO:__main__:e_idx=2/2, chunk_index=27/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3662\n",
      "INFO:bedrock_predictor:Claude completion tokens: 39\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01URXT9SdKdQRCCkhiXfWmxC', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Bennett Hill Farm is located in New Scotland, Albany County, New York. The passage states that the 2010 census population of the town of New Scotland was 8,648.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3372, 'output_tokens': 46}, 'generated_text': 'According to the passage, Bennett Hill Farm is located in New Scotland, Albany County, New York. The passage states that the 2010 census population of the town of New Scotland was 8,648.'}, 'latency': 2.9507667910074815, 'prompt_tokens': 3662, 'completion_tokens': 39}\n",
      "INFO:__main__:response_json={'id': 'msg_01URXT9SdKdQRCCkhiXfWmxC', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Bennett Hill Farm is located in New Scotland, Albany County, New York. The passage states that the 2010 census population of the town of New Scotland was 8,648.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3372, 'output_tokens': 46}, 'generated_text': 'According to the passage, Bennett Hill Farm is located in New Scotland, Albany County, New York. The passage states that the 2010 census population of the town of New Scotland was 8,648.'}\n",
      "INFO:__main__:latency=2.9507667910074815\n",
      "INFO:__main__:prompt_tokens=3662\n",
      "INFO:__main__:completion_tokens=39\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3662, completion_tokens=39, latency=2.9508\n",
      "INFO:__main__:e_idx=2/2, chunk_index=28/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3098\n",
      "INFO:bedrock_predictor:Claude completion tokens: 62\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_013V6CMmDi1WWXTtEEZK6jTT', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Sergio Casal and Manuel Orantes were both professional tennis players from Spain. Casal won 3 Grand Slam doubles titles and the doubles silver medal at the 1988 Olympics. Orantes won the 1975 US Open singles title and reached a career-high ranking of World No. 2. They played tennis professionally.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2980, 'output_tokens': 78}, 'generated_text': 'Sergio Casal and Manuel Orantes were both professional tennis players from Spain. Casal won 3 Grand Slam doubles titles and the doubles silver medal at the 1988 Olympics. Orantes won the 1975 US Open singles title and reached a career-high ranking of World No. 2. They played tennis professionally.'}, 'latency': 3.8128965420037275, 'prompt_tokens': 3098, 'completion_tokens': 62}\n",
      "INFO:__main__:response_json={'id': 'msg_013V6CMmDi1WWXTtEEZK6jTT', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Sergio Casal and Manuel Orantes were both professional tennis players from Spain. Casal won 3 Grand Slam doubles titles and the doubles silver medal at the 1988 Olympics. Orantes won the 1975 US Open singles title and reached a career-high ranking of World No. 2. They played tennis professionally.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2980, 'output_tokens': 78}, 'generated_text': 'Sergio Casal and Manuel Orantes were both professional tennis players from Spain. Casal won 3 Grand Slam doubles titles and the doubles silver medal at the 1988 Olympics. Orantes won the 1975 US Open singles title and reached a career-high ranking of World No. 2. They played tennis professionally.'}\n",
      "INFO:__main__:latency=3.8128965420037275\n",
      "INFO:__main__:prompt_tokens=3098\n",
      "INFO:__main__:completion_tokens=62\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3098, completion_tokens=62, latency=3.8129\n",
      "INFO:__main__:e_idx=2/2, chunk_index=29/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3704\n",
      "INFO:bedrock_predictor:Claude completion tokens: 45\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01HdH7Mmjmvm2U7eZLXJmmHP', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Baghdad ER was released first in 2006, while The Ten-Year Lunch is a documentary film from 1987. So Baghdad ER was released before The Ten-Year Lunch.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3484, 'output_tokens': 50}, 'generated_text': 'Based on the information provided, Baghdad ER was released first in 2006, while The Ten-Year Lunch is a documentary film from 1987. So Baghdad ER was released before The Ten-Year Lunch.'}, 'latency': 3.555162625008961, 'prompt_tokens': 3704, 'completion_tokens': 45}\n",
      "INFO:__main__:response_json={'id': 'msg_01HdH7Mmjmvm2U7eZLXJmmHP', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Baghdad ER was released first in 2006, while The Ten-Year Lunch is a documentary film from 1987. So Baghdad ER was released before The Ten-Year Lunch.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3484, 'output_tokens': 50}, 'generated_text': 'Based on the information provided, Baghdad ER was released first in 2006, while The Ten-Year Lunch is a documentary film from 1987. So Baghdad ER was released before The Ten-Year Lunch.'}\n",
      "INFO:__main__:latency=3.555162625008961\n",
      "INFO:__main__:prompt_tokens=3704\n",
      "INFO:__main__:completion_tokens=45\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3704, completion_tokens=45, latency=3.5552\n",
      "INFO:__main__:e_idx=2/2, chunk_index=30/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3400\n",
      "INFO:bedrock_predictor:Claude completion tokens: 73\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01NhHrdsrjuV3zgJt5sbHEd8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the provided context, Lee Young-sun\\'s personal best throw of 58.87 metres was achieved at the 2002 Asian Games in Busan. The passage states that \"A total of 459 athletes from 39 nations took part in the competition\" at the 2002 Asian Games athletics events. However, it does not specify how many of those athletes were women.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3121, 'output_tokens': 87}, 'generated_text': 'According to the provided context, Lee Young-sun\\'s personal best throw of 58.87 metres was achieved at the 2002 Asian Games in Busan. The passage states that \"A total of 459 athletes from 39 nations took part in the competition\" at the 2002 Asian Games athletics events. However, it does not specify how many of those athletes were women.'}, 'latency': 5.138682167002116, 'prompt_tokens': 3400, 'completion_tokens': 73}\n",
      "INFO:__main__:response_json={'id': 'msg_01NhHrdsrjuV3zgJt5sbHEd8', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the provided context, Lee Young-sun\\'s personal best throw of 58.87 metres was achieved at the 2002 Asian Games in Busan. The passage states that \"A total of 459 athletes from 39 nations took part in the competition\" at the 2002 Asian Games athletics events. However, it does not specify how many of those athletes were women.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3121, 'output_tokens': 87}, 'generated_text': 'According to the provided context, Lee Young-sun\\'s personal best throw of 58.87 metres was achieved at the 2002 Asian Games in Busan. The passage states that \"A total of 459 athletes from 39 nations took part in the competition\" at the 2002 Asian Games athletics events. However, it does not specify how many of those athletes were women.'}\n",
      "INFO:__main__:latency=5.138682167002116\n",
      "INFO:__main__:prompt_tokens=3400\n",
      "INFO:__main__:completion_tokens=73\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3400, completion_tokens=73, latency=5.1387\n",
      "INFO:__main__:e_idx=2/2, chunk_index=31/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3098\n",
      "INFO:bedrock_predictor:Claude completion tokens: 17\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01QtjPGejYCAY1TawDiRGr4X', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2836, 'output_tokens': 24}, 'generated_text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}, 'latency': 2.8138343329919735, 'prompt_tokens': 3098, 'completion_tokens': 17}\n",
      "INFO:__main__:response_json={'id': 'msg_01QtjPGejYCAY1TawDiRGr4X', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2836, 'output_tokens': 24}, 'generated_text': \"'Back to Bedlam' was the debut album for British singer James Blunt.\"}\n",
      "INFO:__main__:latency=2.8138343329919735\n",
      "INFO:__main__:prompt_tokens=3098\n",
      "INFO:__main__:completion_tokens=17\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3098, completion_tokens=17, latency=2.8138\n",
      "INFO:__main__:e_idx=2/2, chunk_index=32/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3909\n",
      "INFO:bedrock_predictor:Claude completion tokens: 38\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01EbfRH6zEnSk4dCfhcf3r9V', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A saluki is a type of dog breed. The passage mentions that salukis are considered to be one of the oldest dog breeds in existence and describes them as a \"beautiful creature\".'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3669, 'output_tokens': 41}, 'generated_text': 'A saluki is a type of dog breed. The passage mentions that salukis are considered to be one of the oldest dog breeds in existence and describes them as a \"beautiful creature\".'}, 'latency': 4.002347875008127, 'prompt_tokens': 3909, 'completion_tokens': 38}\n",
      "INFO:__main__:response_json={'id': 'msg_01EbfRH6zEnSk4dCfhcf3r9V', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'A saluki is a type of dog breed. The passage mentions that salukis are considered to be one of the oldest dog breeds in existence and describes them as a \"beautiful creature\".'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3669, 'output_tokens': 41}, 'generated_text': 'A saluki is a type of dog breed. The passage mentions that salukis are considered to be one of the oldest dog breeds in existence and describes them as a \"beautiful creature\".'}\n",
      "INFO:__main__:latency=4.002347875008127\n",
      "INFO:__main__:prompt_tokens=3909\n",
      "INFO:__main__:completion_tokens=38\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3909, completion_tokens=38, latency=4.0023\n",
      "INFO:__main__:e_idx=2/2, chunk_index=33/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3971\n",
      "INFO:bedrock_predictor:Claude completion tokens: 87\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01RtXLsneuj5VbUbEhuPnqaC', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The Naismith Legacy Award is presented in basketball. The passage states that it honors individuals from the game of basketball who have furthered the values that Dr. James Naismith, the inventor of basketball, wrote into the \"Original Rules\" of the game such as honor, respect and integrity. Dr. Naismith invented basketball in 1891 at a YMCA gym, which is depicted in the sculpture featured on the award itself.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3757, 'output_tokens': 97}, 'generated_text': 'The Naismith Legacy Award is presented in basketball. The passage states that it honors individuals from the game of basketball who have furthered the values that Dr. James Naismith, the inventor of basketball, wrote into the \"Original Rules\" of the game such as honor, respect and integrity. Dr. Naismith invented basketball in 1891 at a YMCA gym, which is depicted in the sculpture featured on the award itself.'}, 'latency': 5.489050416988903, 'prompt_tokens': 3971, 'completion_tokens': 87}\n",
      "INFO:__main__:response_json={'id': 'msg_01RtXLsneuj5VbUbEhuPnqaC', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The Naismith Legacy Award is presented in basketball. The passage states that it honors individuals from the game of basketball who have furthered the values that Dr. James Naismith, the inventor of basketball, wrote into the \"Original Rules\" of the game such as honor, respect and integrity. Dr. Naismith invented basketball in 1891 at a YMCA gym, which is depicted in the sculpture featured on the award itself.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3757, 'output_tokens': 97}, 'generated_text': 'The Naismith Legacy Award is presented in basketball. The passage states that it honors individuals from the game of basketball who have furthered the values that Dr. James Naismith, the inventor of basketball, wrote into the \"Original Rules\" of the game such as honor, respect and integrity. Dr. Naismith invented basketball in 1891 at a YMCA gym, which is depicted in the sculpture featured on the award itself.'}\n",
      "INFO:__main__:latency=5.489050416988903\n",
      "INFO:__main__:prompt_tokens=3971\n",
      "INFO:__main__:completion_tokens=87\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3971, completion_tokens=87, latency=5.4891\n",
      "INFO:__main__:e_idx=2/2, chunk_index=34/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3132\n",
      "INFO:bedrock_predictor:Claude completion tokens: 21\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01PDZN1ozpNSTHAf5bFi56Ck', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, archery events were held at Lord's Cricket Ground during the London 2012 Olympics.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2930, 'output_tokens': 27}, 'generated_text': \"According to the passage, archery events were held at Lord's Cricket Ground during the London 2012 Olympics.\"}, 'latency': 3.1806122499983758, 'prompt_tokens': 3132, 'completion_tokens': 21}\n",
      "INFO:__main__:response_json={'id': 'msg_01PDZN1ozpNSTHAf5bFi56Ck', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, archery events were held at Lord's Cricket Ground during the London 2012 Olympics.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2930, 'output_tokens': 27}, 'generated_text': \"According to the passage, archery events were held at Lord's Cricket Ground during the London 2012 Olympics.\"}\n",
      "INFO:__main__:latency=3.1806122499983758\n",
      "INFO:__main__:prompt_tokens=3132\n",
      "INFO:__main__:completion_tokens=21\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3132, completion_tokens=21, latency=3.1806\n",
      "INFO:__main__:e_idx=2/2, chunk_index=35/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3135\n",
      "INFO:bedrock_predictor:Claude completion tokens: 60\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_017nBNSRr56tM5KZcNhpkNky', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Donald Duck\\'s three nephews are named Huey, Dewey, and Louie. The 1938 animated short film \"Donald\\'s Nephews\" marked their first appearance in animation, though they had been introduced a few months earlier in the Donald Duck comic strip by artist Al Taliaferro.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2914, 'output_tokens': 70}, 'generated_text': 'Donald Duck\\'s three nephews are named Huey, Dewey, and Louie. The 1938 animated short film \"Donald\\'s Nephews\" marked their first appearance in animation, though they had been introduced a few months earlier in the Donald Duck comic strip by artist Al Taliaferro.'}, 'latency': 9.270625500008464, 'prompt_tokens': 3135, 'completion_tokens': 60}\n",
      "INFO:__main__:response_json={'id': 'msg_017nBNSRr56tM5KZcNhpkNky', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Donald Duck\\'s three nephews are named Huey, Dewey, and Louie. The 1938 animated short film \"Donald\\'s Nephews\" marked their first appearance in animation, though they had been introduced a few months earlier in the Donald Duck comic strip by artist Al Taliaferro.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2914, 'output_tokens': 70}, 'generated_text': 'Donald Duck\\'s three nephews are named Huey, Dewey, and Louie. The 1938 animated short film \"Donald\\'s Nephews\" marked their first appearance in animation, though they had been introduced a few months earlier in the Donald Duck comic strip by artist Al Taliaferro.'}\n",
      "INFO:__main__:latency=9.270625500008464\n",
      "INFO:__main__:prompt_tokens=3135\n",
      "INFO:__main__:completion_tokens=60\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3135, completion_tokens=60, latency=9.2706\n",
      "INFO:__main__:e_idx=2/2, chunk_index=36/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3030\n",
      "INFO:bedrock_predictor:Claude completion tokens: 44\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01QfN6oAE7p3SgndBCiDwrgS', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the boxer who was stripped of his heavyweight boxing titles in April 1967 when he refused induction into the U.S. Army was Muhammad Ali (referred to as Cassius Clay in the passage).'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2896, 'output_tokens': 51}, 'generated_text': 'According to the passage, the boxer who was stripped of his heavyweight boxing titles in April 1967 when he refused induction into the U.S. Army was Muhammad Ali (referred to as Cassius Clay in the passage).'}, 'latency': 3.4854875409946544, 'prompt_tokens': 3030, 'completion_tokens': 44}\n",
      "INFO:__main__:response_json={'id': 'msg_01QfN6oAE7p3SgndBCiDwrgS', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the boxer who was stripped of his heavyweight boxing titles in April 1967 when he refused induction into the U.S. Army was Muhammad Ali (referred to as Cassius Clay in the passage).'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2896, 'output_tokens': 51}, 'generated_text': 'According to the passage, the boxer who was stripped of his heavyweight boxing titles in April 1967 when he refused induction into the U.S. Army was Muhammad Ali (referred to as Cassius Clay in the passage).'}\n",
      "INFO:__main__:latency=3.4854875409946544\n",
      "INFO:__main__:prompt_tokens=3030\n",
      "INFO:__main__:completion_tokens=44\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3030, completion_tokens=44, latency=3.4855\n",
      "INFO:__main__:e_idx=2/2, chunk_index=37/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3848\n",
      "INFO:bedrock_predictor:Claude completion tokens: 74\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01CeCZKfKxrNngJJe3wKWdHV', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, the former Italian Prime Minister Aldo Moro was kidnapped by the Red Brigades terrorist group on March 16, 1978. After 55 days in captivity and their demands being refused, Moro's body was found in the trunk of a red car in the middle of Rome on May 9, 1978. He had been shot 11 times in the chest.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3606, 'output_tokens': 93}, 'generated_text': \"According to the passage, the former Italian Prime Minister Aldo Moro was kidnapped by the Red Brigades terrorist group on March 16, 1978. After 55 days in captivity and their demands being refused, Moro's body was found in the trunk of a red car in the middle of Rome on May 9, 1978. He had been shot 11 times in the chest.\"}, 'latency': 4.6402227920043515, 'prompt_tokens': 3848, 'completion_tokens': 74}\n",
      "INFO:__main__:response_json={'id': 'msg_01CeCZKfKxrNngJJe3wKWdHV', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"According to the passage, the former Italian Prime Minister Aldo Moro was kidnapped by the Red Brigades terrorist group on March 16, 1978. After 55 days in captivity and their demands being refused, Moro's body was found in the trunk of a red car in the middle of Rome on May 9, 1978. He had been shot 11 times in the chest.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3606, 'output_tokens': 93}, 'generated_text': \"According to the passage, the former Italian Prime Minister Aldo Moro was kidnapped by the Red Brigades terrorist group on March 16, 1978. After 55 days in captivity and their demands being refused, Moro's body was found in the trunk of a red car in the middle of Rome on May 9, 1978. He had been shot 11 times in the chest.\"}\n",
      "INFO:__main__:latency=4.6402227920043515\n",
      "INFO:__main__:prompt_tokens=3848\n",
      "INFO:__main__:completion_tokens=74\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3848, completion_tokens=74, latency=4.6402\n",
      "INFO:__main__:e_idx=2/2, chunk_index=38/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3208\n",
      "INFO:bedrock_predictor:Claude completion tokens: 36\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_013b3v4d7LFYY9DHeb1fWsEj', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the biographical information provided in the passage, the stage name that British-born American film actor Archibald Alexander Leach was better known by is Cary Grant.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2972, 'output_tokens': 41}, 'generated_text': 'Based on the biographical information provided in the passage, the stage name that British-born American film actor Archibald Alexander Leach was better known by is Cary Grant.'}, 'latency': 2.793251708993921, 'prompt_tokens': 3208, 'completion_tokens': 36}\n",
      "INFO:__main__:response_json={'id': 'msg_013b3v4d7LFYY9DHeb1fWsEj', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the biographical information provided in the passage, the stage name that British-born American film actor Archibald Alexander Leach was better known by is Cary Grant.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2972, 'output_tokens': 41}, 'generated_text': 'Based on the biographical information provided in the passage, the stage name that British-born American film actor Archibald Alexander Leach was better known by is Cary Grant.'}\n",
      "INFO:__main__:latency=2.793251708993921\n",
      "INFO:__main__:prompt_tokens=3208\n",
      "INFO:__main__:completion_tokens=36\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3208, completion_tokens=36, latency=2.7933\n",
      "INFO:__main__:e_idx=2/2, chunk_index=39/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3475\n",
      "INFO:bedrock_predictor:Claude completion tokens: 55\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01SphUpdSDdh5EbRWnZXS1zj', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Unfortunately, the provided context does not contain enough information to determine what Blondie's last UK No. 1 single was in the 1980s. The passage discusses Blondie's musical style and impact, but does not mention specific chart positions or hit singles from that era.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3242, 'output_tokens': 64}, 'generated_text': \"Unfortunately, the provided context does not contain enough information to determine what Blondie's last UK No. 1 single was in the 1980s. The passage discusses Blondie's musical style and impact, but does not mention specific chart positions or hit singles from that era.\"}, 'latency': 4.786429125000723, 'prompt_tokens': 3475, 'completion_tokens': 55}\n",
      "INFO:__main__:response_json={'id': 'msg_01SphUpdSDdh5EbRWnZXS1zj', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': \"Unfortunately, the provided context does not contain enough information to determine what Blondie's last UK No. 1 single was in the 1980s. The passage discusses Blondie's musical style and impact, but does not mention specific chart positions or hit singles from that era.\"}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3242, 'output_tokens': 64}, 'generated_text': \"Unfortunately, the provided context does not contain enough information to determine what Blondie's last UK No. 1 single was in the 1980s. The passage discusses Blondie's musical style and impact, but does not mention specific chart positions or hit singles from that era.\"}\n",
      "INFO:__main__:latency=4.786429125000723\n",
      "INFO:__main__:prompt_tokens=3475\n",
      "INFO:__main__:completion_tokens=55\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3475, completion_tokens=55, latency=4.7864\n",
      "INFO:__main__:e_idx=2/2, chunk_index=40/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3681\n",
      "INFO:bedrock_predictor:Claude completion tokens: 95\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_015GkdqWfEK5KsmyaypshpcP', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, a hoy was a small sloop-rigged coasting ship used for freight that was powered by sails. The passage mentions that hoys evolved over time, but were principally sailing vessels used for carrying cargo or passengers along coasts and estuaries. They were able to skillfully utilize tides as well as wind propulsion before the development of steam engines. So a traditional hoy boat was powered by sails using the wind.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3517, 'output_tokens': 99}, 'generated_text': 'According to the passage, a hoy was a small sloop-rigged coasting ship used for freight that was powered by sails. The passage mentions that hoys evolved over time, but were principally sailing vessels used for carrying cargo or passengers along coasts and estuaries. They were able to skillfully utilize tides as well as wind propulsion before the development of steam engines. So a traditional hoy boat was powered by sails using the wind.'}, 'latency': 5.183992291000322, 'prompt_tokens': 3681, 'completion_tokens': 95}\n",
      "INFO:__main__:response_json={'id': 'msg_015GkdqWfEK5KsmyaypshpcP', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, a hoy was a small sloop-rigged coasting ship used for freight that was powered by sails. The passage mentions that hoys evolved over time, but were principally sailing vessels used for carrying cargo or passengers along coasts and estuaries. They were able to skillfully utilize tides as well as wind propulsion before the development of steam engines. So a traditional hoy boat was powered by sails using the wind.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3517, 'output_tokens': 99}, 'generated_text': 'According to the passage, a hoy was a small sloop-rigged coasting ship used for freight that was powered by sails. The passage mentions that hoys evolved over time, but were principally sailing vessels used for carrying cargo or passengers along coasts and estuaries. They were able to skillfully utilize tides as well as wind propulsion before the development of steam engines. So a traditional hoy boat was powered by sails using the wind.'}\n",
      "INFO:__main__:latency=5.183992291000322\n",
      "INFO:__main__:prompt_tokens=3681\n",
      "INFO:__main__:completion_tokens=95\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3681, completion_tokens=95, latency=5.1840\n",
      "INFO:__main__:e_idx=2/2, chunk_index=41/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3581\n",
      "INFO:bedrock_predictor:Claude completion tokens: 97\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01MhhreicnCz38ugj16c79zf', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Matthew Webb\\'s final stunt that led to his death was an attempt to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls. It states that on July 24, 1883, \"he jumped into the river from a small boat located near the Niagara Falls Suspension Bridge and began his swim\" through the dangerous rapids, where he likely drowned near the entrance to the whirlpool section of the river.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3334, 'output_tokens': 108}, 'generated_text': 'According to the passage, Matthew Webb\\'s final stunt that led to his death was an attempt to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls. It states that on July 24, 1883, \"he jumped into the river from a small boat located near the Niagara Falls Suspension Bridge and began his swim\" through the dangerous rapids, where he likely drowned near the entrance to the whirlpool section of the river.'}, 'latency': 5.415742457989836, 'prompt_tokens': 3581, 'completion_tokens': 97}\n",
      "INFO:__main__:response_json={'id': 'msg_01MhhreicnCz38ugj16c79zf', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Matthew Webb\\'s final stunt that led to his death was an attempt to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls. It states that on July 24, 1883, \"he jumped into the river from a small boat located near the Niagara Falls Suspension Bridge and began his swim\" through the dangerous rapids, where he likely drowned near the entrance to the whirlpool section of the river.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3334, 'output_tokens': 108}, 'generated_text': 'According to the passage, Matthew Webb\\'s final stunt that led to his death was an attempt to swim through the Whirlpool Rapids on the Niagara River below Niagara Falls. It states that on July 24, 1883, \"he jumped into the river from a small boat located near the Niagara Falls Suspension Bridge and began his swim\" through the dangerous rapids, where he likely drowned near the entrance to the whirlpool section of the river.'}\n",
      "INFO:__main__:latency=5.415742457989836\n",
      "INFO:__main__:prompt_tokens=3581\n",
      "INFO:__main__:completion_tokens=97\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3581, completion_tokens=97, latency=5.4157\n",
      "INFO:__main__:e_idx=2/2, chunk_index=42/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3302\n",
      "INFO:bedrock_predictor:Claude completion tokens: 28\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01Ey8qm9x2tgPEZHHaTXfcYx', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Alexander Graham Bell and his assistant first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3042, 'output_tokens': 33}, 'generated_text': 'According to the passage, Alexander Graham Bell and his assistant first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}, 'latency': 2.8606463330070255, 'prompt_tokens': 3302, 'completion_tokens': 28}\n",
      "INFO:__main__:response_json={'id': 'msg_01Ey8qm9x2tgPEZHHaTXfcYx', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Alexander Graham Bell and his assistant first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3042, 'output_tokens': 33}, 'generated_text': 'According to the passage, Alexander Graham Bell and his assistant first publicly demonstrated their telephone invention at the Centennial Exhibition in Philadelphia in 1876.'}\n",
      "INFO:__main__:latency=2.8606463330070255\n",
      "INFO:__main__:prompt_tokens=3302\n",
      "INFO:__main__:completion_tokens=28\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3302, completion_tokens=28, latency=2.8606\n",
      "INFO:__main__:e_idx=2/2, chunk_index=43/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3614\n",
      "INFO:bedrock_predictor:Claude completion tokens: 68\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_012FCBTURyx1EHzfcY2iX535', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Unfortunately, I do not have enough information from the given context to determine which city is known as the \"Pearl of the Danube\". The passage discusses details about a Danube river cruise itinerary that visits Austria, Germany, Hungary and Slovakia, but does not specifically mention any city nicknamed the \"Pearl of the Danube\".'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3365, 'output_tokens': 72}, 'generated_text': 'Unfortunately, I do not have enough information from the given context to determine which city is known as the \"Pearl of the Danube\". The passage discusses details about a Danube river cruise itinerary that visits Austria, Germany, Hungary and Slovakia, but does not specifically mention any city nicknamed the \"Pearl of the Danube\".'}, 'latency': 4.40427179200924, 'prompt_tokens': 3614, 'completion_tokens': 68}\n",
      "INFO:__main__:response_json={'id': 'msg_012FCBTURyx1EHzfcY2iX535', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Unfortunately, I do not have enough information from the given context to determine which city is known as the \"Pearl of the Danube\". The passage discusses details about a Danube river cruise itinerary that visits Austria, Germany, Hungary and Slovakia, but does not specifically mention any city nicknamed the \"Pearl of the Danube\".'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3365, 'output_tokens': 72}, 'generated_text': 'Unfortunately, I do not have enough information from the given context to determine which city is known as the \"Pearl of the Danube\". The passage discusses details about a Danube river cruise itinerary that visits Austria, Germany, Hungary and Slovakia, but does not specifically mention any city nicknamed the \"Pearl of the Danube\".'}\n",
      "INFO:__main__:latency=4.40427179200924\n",
      "INFO:__main__:prompt_tokens=3614\n",
      "INFO:__main__:completion_tokens=68\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3614, completion_tokens=68, latency=4.4043\n",
      "INFO:__main__:e_idx=2/2, chunk_index=44/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3537\n",
      "INFO:bedrock_predictor:Claude completion tokens: 36\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01R6YWSDbTxspaa5oJrjYJcz', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the plot summary provided, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3321, 'output_tokens': 44}, 'generated_text': 'Based on the plot summary provided, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}, 'latency': 3.429325457997038, 'prompt_tokens': 3537, 'completion_tokens': 36}\n",
      "INFO:__main__:response_json={'id': 'msg_01R6YWSDbTxspaa5oJrjYJcz', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the plot summary provided, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3321, 'output_tokens': 44}, 'generated_text': 'Based on the plot summary provided, Charlton Heston played the role of Moses in the 1956 film \"The Ten Commandments\" directed by Cecil B. DeMille.'}\n",
      "INFO:__main__:latency=3.429325457997038\n",
      "INFO:__main__:prompt_tokens=3537\n",
      "INFO:__main__:completion_tokens=36\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3537, completion_tokens=36, latency=3.4293\n",
      "INFO:__main__:e_idx=2/2, chunk_index=45/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3165\n",
      "INFO:bedrock_predictor:Claude completion tokens: 84\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01WRhQ2x6x3n61bL15G4P11i', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Gary Busey played Buddy Holly in the 1978 film The Buddy Holly Story. The passage mentions that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\" It also states that \"Busey was rightfully nominated for an Oscar for his effective portrayal.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2963, 'output_tokens': 95}, 'generated_text': 'According to the passage, Gary Busey played Buddy Holly in the 1978 film The Buddy Holly Story. The passage mentions that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\" It also states that \"Busey was rightfully nominated for an Oscar for his effective portrayal.\"'}, 'latency': 4.36099024998839, 'prompt_tokens': 3165, 'completion_tokens': 84}\n",
      "INFO:__main__:response_json={'id': 'msg_01WRhQ2x6x3n61bL15G4P11i', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, Gary Busey played Buddy Holly in the 1978 film The Buddy Holly Story. The passage mentions that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\" It also states that \"Busey was rightfully nominated for an Oscar for his effective portrayal.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2963, 'output_tokens': 95}, 'generated_text': 'According to the passage, Gary Busey played Buddy Holly in the 1978 film The Buddy Holly Story. The passage mentions that \"Gary Busey not only did his own singing, but even lost 32 lbs to play Buddy Holly in this sensational musical biography of the singer from Lubbock Texas.\" It also states that \"Busey was rightfully nominated for an Oscar for his effective portrayal.\"'}\n",
      "INFO:__main__:latency=4.36099024998839\n",
      "INFO:__main__:prompt_tokens=3165\n",
      "INFO:__main__:completion_tokens=84\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3165, completion_tokens=84, latency=4.3610\n",
      "INFO:__main__:e_idx=2/2, chunk_index=46/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3476\n",
      "INFO:bedrock_predictor:Claude completion tokens: 49\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01CtM4xThzWJJfekUkT46JvL', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Hattie Jacques played the role of Miss Pugh on the Hancock radio show. The passage mentions that the cast for Series 5 comprised \"Tony Hancock, Bill Kerr, Sidney James, Kenneth Williams and Hattie Jacques.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3244, 'output_tokens': 63}, 'generated_text': 'Based on the information provided, Hattie Jacques played the role of Miss Pugh on the Hancock radio show. The passage mentions that the cast for Series 5 comprised \"Tony Hancock, Bill Kerr, Sidney James, Kenneth Williams and Hattie Jacques.\"'}, 'latency': 4.2168919169926085, 'prompt_tokens': 3476, 'completion_tokens': 49}\n",
      "INFO:__main__:response_json={'id': 'msg_01CtM4xThzWJJfekUkT46JvL', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided, Hattie Jacques played the role of Miss Pugh on the Hancock radio show. The passage mentions that the cast for Series 5 comprised \"Tony Hancock, Bill Kerr, Sidney James, Kenneth Williams and Hattie Jacques.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3244, 'output_tokens': 63}, 'generated_text': 'Based on the information provided, Hattie Jacques played the role of Miss Pugh on the Hancock radio show. The passage mentions that the cast for Series 5 comprised \"Tony Hancock, Bill Kerr, Sidney James, Kenneth Williams and Hattie Jacques.\"'}\n",
      "INFO:__main__:latency=4.2168919169926085\n",
      "INFO:__main__:prompt_tokens=3476\n",
      "INFO:__main__:completion_tokens=49\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3476, completion_tokens=49, latency=4.2169\n",
      "INFO:__main__:e_idx=2/2, chunk_index=47/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3235\n",
      "INFO:bedrock_predictor:Claude completion tokens: 57\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_011u6wQ1AhYEtoDaesxmEuLt', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the biographical information provided, Nadine Coyle is the member of the British pop group Girls Aloud who was born in Northern Ireland. Specifically, the passage states that \"Nadine Coyle was born on June 15, 1985 in Derry, Northern Ireland.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2994, 'output_tokens': 68}, 'generated_text': 'Based on the biographical information provided, Nadine Coyle is the member of the British pop group Girls Aloud who was born in Northern Ireland. Specifically, the passage states that \"Nadine Coyle was born on June 15, 1985 in Derry, Northern Ireland.\"'}, 'latency': 5.227270540999598, 'prompt_tokens': 3235, 'completion_tokens': 57}\n",
      "INFO:__main__:response_json={'id': 'msg_011u6wQ1AhYEtoDaesxmEuLt', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the biographical information provided, Nadine Coyle is the member of the British pop group Girls Aloud who was born in Northern Ireland. Specifically, the passage states that \"Nadine Coyle was born on June 15, 1985 in Derry, Northern Ireland.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2994, 'output_tokens': 68}, 'generated_text': 'Based on the biographical information provided, Nadine Coyle is the member of the British pop group Girls Aloud who was born in Northern Ireland. Specifically, the passage states that \"Nadine Coyle was born on June 15, 1985 in Derry, Northern Ireland.\"'}\n",
      "INFO:__main__:latency=5.227270540999598\n",
      "INFO:__main__:prompt_tokens=3235\n",
      "INFO:__main__:completion_tokens=57\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3235, completion_tokens=57, latency=5.2273\n",
      "INFO:__main__:e_idx=2/2, chunk_index=48/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3363\n",
      "INFO:bedrock_predictor:Claude completion tokens: 157\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_016ieYRPjDKtcJTMjgHLZEwm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the context provided, the Bargello museum is located in Florence, Italy. The passage mentions that \"The Museum is housed in the medieval Palazzo del Capitano del Popolo (or Bargello Palace), built starting from 1255 and enlarged in the 14th century, ancient residence of the Captain of the People, then of the Podest and lastly of the Captain of Justice (called Bargello), that is the chief of the police (16th century), when the palace was transformed into a prison. The building was completely restored in order to house the Bargello National Museum, opened in 1865.\" Therefore, the Bargello and the Uffizi are among the art museums located in the city of Florence, Italy.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3218, 'output_tokens': 165}, 'generated_text': 'Based on the context provided, the Bargello museum is located in Florence, Italy. The passage mentions that \"The Museum is housed in the medieval Palazzo del Capitano del Popolo (or Bargello Palace), built starting from 1255 and enlarged in the 14th century, ancient residence of the Captain of the People, then of the Podest and lastly of the Captain of Justice (called Bargello), that is the chief of the police (16th century), when the palace was transformed into a prison. The building was completely restored in order to house the Bargello National Museum, opened in 1865.\" Therefore, the Bargello and the Uffizi are among the art museums located in the city of Florence, Italy.'}, 'latency': 5.167902209010208, 'prompt_tokens': 3363, 'completion_tokens': 157}\n",
      "INFO:__main__:response_json={'id': 'msg_016ieYRPjDKtcJTMjgHLZEwm', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the context provided, the Bargello museum is located in Florence, Italy. The passage mentions that \"The Museum is housed in the medieval Palazzo del Capitano del Popolo (or Bargello Palace), built starting from 1255 and enlarged in the 14th century, ancient residence of the Captain of the People, then of the Podest and lastly of the Captain of Justice (called Bargello), that is the chief of the police (16th century), when the palace was transformed into a prison. The building was completely restored in order to house the Bargello National Museum, opened in 1865.\" Therefore, the Bargello and the Uffizi are among the art museums located in the city of Florence, Italy.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3218, 'output_tokens': 165}, 'generated_text': 'Based on the context provided, the Bargello museum is located in Florence, Italy. The passage mentions that \"The Museum is housed in the medieval Palazzo del Capitano del Popolo (or Bargello Palace), built starting from 1255 and enlarged in the 14th century, ancient residence of the Captain of the People, then of the Podest and lastly of the Captain of Justice (called Bargello), that is the chief of the police (16th century), when the palace was transformed into a prison. The building was completely restored in order to house the Bargello National Museum, opened in 1865.\" Therefore, the Bargello and the Uffizi are among the art museums located in the city of Florence, Italy.'}\n",
      "INFO:__main__:latency=5.167902209010208\n",
      "INFO:__main__:prompt_tokens=3363\n",
      "INFO:__main__:completion_tokens=157\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3363, completion_tokens=157, latency=5.1679\n",
      "INFO:__main__:e_idx=2/2, chunk_index=49/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3882\n",
      "INFO:bedrock_predictor:Claude completion tokens: 260\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_012x5i634cQAmhymMSRGVotB', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, guillemots are seabirds in the auk family (part of the order Charadriiformes). It mentions two genera of guillemots:\\n\\n1) Uria - Referred to as \"murres\" in North America, these have white bellies, thicker and longer bills, and form dense colonies on cliffs during breeding season. The two living species are the common murre/guillemot (Uria aalge) and the thick-billed murre/Brnnich\\'s guillemot (Uria lomvia).\\n\\n2) Cepphus - Referred to as \"guillemots\" in North America, these are smaller than Uria species, have black bellies, rounder heads and bright red feet. The three living species are the black guillemot (Cepphus grylle), pigeon guillemot (Cepphus columba), and spectacled guillemot (Cepphus carbo).\\n\\nSo in summary, guillemots are auk seabirds, with the Uria genus called \"murres\" in North America, and the Cepphus genus called \"guillemots\" in North America.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3590, 'output_tokens': 272}, 'generated_text': 'According to the passage, guillemots are seabirds in the auk family (part of the order Charadriiformes). It mentions two genera of guillemots:\\n\\n1) Uria - Referred to as \"murres\" in North America, these have white bellies, thicker and longer bills, and form dense colonies on cliffs during breeding season. The two living species are the common murre/guillemot (Uria aalge) and the thick-billed murre/Brnnich\\'s guillemot (Uria lomvia).\\n\\n2) Cepphus - Referred to as \"guillemots\" in North America, these are smaller than Uria species, have black bellies, rounder heads and bright red feet. The three living species are the black guillemot (Cepphus grylle), pigeon guillemot (Cepphus columba), and spectacled guillemot (Cepphus carbo).\\n\\nSo in summary, guillemots are auk seabirds, with the Uria genus called \"murres\" in North America, and the Cepphus genus called \"guillemots\" in North America.'}, 'latency': 8.151820500002941, 'prompt_tokens': 3882, 'completion_tokens': 260}\n",
      "INFO:__main__:response_json={'id': 'msg_012x5i634cQAmhymMSRGVotB', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, guillemots are seabirds in the auk family (part of the order Charadriiformes). It mentions two genera of guillemots:\\n\\n1) Uria - Referred to as \"murres\" in North America, these have white bellies, thicker and longer bills, and form dense colonies on cliffs during breeding season. The two living species are the common murre/guillemot (Uria aalge) and the thick-billed murre/Brnnich\\'s guillemot (Uria lomvia).\\n\\n2) Cepphus - Referred to as \"guillemots\" in North America, these are smaller than Uria species, have black bellies, rounder heads and bright red feet. The three living species are the black guillemot (Cepphus grylle), pigeon guillemot (Cepphus columba), and spectacled guillemot (Cepphus carbo).\\n\\nSo in summary, guillemots are auk seabirds, with the Uria genus called \"murres\" in North America, and the Cepphus genus called \"guillemots\" in North America.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3590, 'output_tokens': 272}, 'generated_text': 'According to the passage, guillemots are seabirds in the auk family (part of the order Charadriiformes). It mentions two genera of guillemots:\\n\\n1) Uria - Referred to as \"murres\" in North America, these have white bellies, thicker and longer bills, and form dense colonies on cliffs during breeding season. The two living species are the common murre/guillemot (Uria aalge) and the thick-billed murre/Brnnich\\'s guillemot (Uria lomvia).\\n\\n2) Cepphus - Referred to as \"guillemots\" in North America, these are smaller than Uria species, have black bellies, rounder heads and bright red feet. The three living species are the black guillemot (Cepphus grylle), pigeon guillemot (Cepphus columba), and spectacled guillemot (Cepphus carbo).\\n\\nSo in summary, guillemots are auk seabirds, with the Uria genus called \"murres\" in North America, and the Cepphus genus called \"guillemots\" in North America.'}\n",
      "INFO:__main__:latency=8.151820500002941\n",
      "INFO:__main__:prompt_tokens=3882\n",
      "INFO:__main__:completion_tokens=260\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3882, completion_tokens=260, latency=8.1518\n",
      "INFO:__main__:e_idx=2/2, chunk_index=50/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3616\n",
      "INFO:bedrock_predictor:Claude completion tokens: 72\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01KaGRNoFBGM38fxhjjh6tov', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The UK #1 single released by the band Stereophonics in 2005 was \"Dakota\". According to the passage, \"Dakota\" was the first single from their fifth studio album \"Language. Sex. Violence. Other?\" and it became the first Stereophonics single to reach #1 on the UK Singles Chart.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3343, 'output_tokens': 75}, 'generated_text': 'The UK #1 single released by the band Stereophonics in 2005 was \"Dakota\". According to the passage, \"Dakota\" was the first single from their fifth studio album \"Language. Sex. Violence. Other?\" and it became the first Stereophonics single to reach #1 on the UK Singles Chart.'}, 'latency': 3.8899984169984236, 'prompt_tokens': 3616, 'completion_tokens': 72}\n",
      "INFO:__main__:response_json={'id': 'msg_01KaGRNoFBGM38fxhjjh6tov', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'The UK #1 single released by the band Stereophonics in 2005 was \"Dakota\". According to the passage, \"Dakota\" was the first single from their fifth studio album \"Language. Sex. Violence. Other?\" and it became the first Stereophonics single to reach #1 on the UK Singles Chart.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3343, 'output_tokens': 75}, 'generated_text': 'The UK #1 single released by the band Stereophonics in 2005 was \"Dakota\". According to the passage, \"Dakota\" was the first single from their fifth studio album \"Language. Sex. Violence. Other?\" and it became the first Stereophonics single to reach #1 on the UK Singles Chart.'}\n",
      "INFO:__main__:latency=3.8899984169984236\n",
      "INFO:__main__:prompt_tokens=3616\n",
      "INFO:__main__:completion_tokens=72\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3616, completion_tokens=72, latency=3.8900\n",
      "INFO:__main__:e_idx=2/2, chunk_index=51/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3567\n",
      "INFO:bedrock_predictor:Claude completion tokens: 46\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_014bWv9cFWwkf9s3dzkcxAFH', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Soviet counterintelligence agency that the protagonist Semion Strogov works for in the game \"Death to Spies\" is called SMERSH, which means \\'death to spies\\' in English.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3356, 'output_tokens': 57}, 'generated_text': 'According to the passage, the Soviet counterintelligence agency that the protagonist Semion Strogov works for in the game \"Death to Spies\" is called SMERSH, which means \\'death to spies\\' in English.'}, 'latency': 3.7196122909954283, 'prompt_tokens': 3567, 'completion_tokens': 46}\n",
      "INFO:__main__:response_json={'id': 'msg_014bWv9cFWwkf9s3dzkcxAFH', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Soviet counterintelligence agency that the protagonist Semion Strogov works for in the game \"Death to Spies\" is called SMERSH, which means \\'death to spies\\' in English.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3356, 'output_tokens': 57}, 'generated_text': 'According to the passage, the Soviet counterintelligence agency that the protagonist Semion Strogov works for in the game \"Death to Spies\" is called SMERSH, which means \\'death to spies\\' in English.'}\n",
      "INFO:__main__:latency=3.7196122909954283\n",
      "INFO:__main__:prompt_tokens=3567\n",
      "INFO:__main__:completion_tokens=46\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3567, completion_tokens=46, latency=3.7196\n",
      "INFO:__main__:e_idx=2/2, chunk_index=52/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3330\n",
      "INFO:bedrock_predictor:Claude completion tokens: 19\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_011t8P4G5pU66ZNzKXK8Yshh', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3071, 'output_tokens': 23}, 'generated_text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}, 'latency': 4.383056624996243, 'prompt_tokens': 3330, 'completion_tokens': 19}\n",
      "INFO:__main__:response_json={'id': 'msg_011t8P4G5pU66ZNzKXK8Yshh', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3071, 'output_tokens': 23}, 'generated_text': 'According to the passage, King George II was born in Herrenhausen, Hanover.'}\n",
      "INFO:__main__:latency=4.383056624996243\n",
      "INFO:__main__:prompt_tokens=3330\n",
      "INFO:__main__:completion_tokens=19\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3330, completion_tokens=19, latency=4.3831\n",
      "INFO:__main__:e_idx=2/2, chunk_index=53/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3566\n",
      "INFO:bedrock_predictor:Claude completion tokens: 148\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01Et9wT3Lgmxj3JkeQbXQYNy', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passage, the main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick. The key details:\\n\\n- Grace Slick was one of the lead singers of the rock groups Jefferson Airplane, Jefferson Starship, Starship for nearly three decades from the mid-1960s to the mid-1990s.\\n\\n- She is considered one of the most important musicians in bringing 1960s psychedelic rock to mainstream appeal.\\n\\n- She is known for her witty, influential, thought-provoking lyrics.\\n\\nSo Grace Slick was the prominent female vocalist who fronted those influential psychedelic/rock bands over a long career spanning several decades.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3393, 'output_tokens': 160}, 'generated_text': 'Based on the provided passage, the main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick. The key details:\\n\\n- Grace Slick was one of the lead singers of the rock groups Jefferson Airplane, Jefferson Starship, Starship for nearly three decades from the mid-1960s to the mid-1990s.\\n\\n- She is considered one of the most important musicians in bringing 1960s psychedelic rock to mainstream appeal.\\n\\n- She is known for her witty, influential, thought-provoking lyrics.\\n\\nSo Grace Slick was the prominent female vocalist who fronted those influential psychedelic/rock bands over a long career spanning several decades.'}, 'latency': 6.304375291001634, 'prompt_tokens': 3566, 'completion_tokens': 148}\n",
      "INFO:__main__:response_json={'id': 'msg_01Et9wT3Lgmxj3JkeQbXQYNy', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the provided passage, the main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick. The key details:\\n\\n- Grace Slick was one of the lead singers of the rock groups Jefferson Airplane, Jefferson Starship, Starship for nearly three decades from the mid-1960s to the mid-1990s.\\n\\n- She is considered one of the most important musicians in bringing 1960s psychedelic rock to mainstream appeal.\\n\\n- She is known for her witty, influential, thought-provoking lyrics.\\n\\nSo Grace Slick was the prominent female vocalist who fronted those influential psychedelic/rock bands over a long career spanning several decades.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3393, 'output_tokens': 160}, 'generated_text': 'Based on the provided passage, the main female singer with the groups Jefferson Airplane, Jefferson Starship, and Starship was Grace Slick. The key details:\\n\\n- Grace Slick was one of the lead singers of the rock groups Jefferson Airplane, Jefferson Starship, Starship for nearly three decades from the mid-1960s to the mid-1990s.\\n\\n- She is considered one of the most important musicians in bringing 1960s psychedelic rock to mainstream appeal.\\n\\n- She is known for her witty, influential, thought-provoking lyrics.\\n\\nSo Grace Slick was the prominent female vocalist who fronted those influential psychedelic/rock bands over a long career spanning several decades.'}\n",
      "INFO:__main__:latency=6.304375291001634\n",
      "INFO:__main__:prompt_tokens=3566\n",
      "INFO:__main__:completion_tokens=148\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3566, completion_tokens=148, latency=6.3044\n",
      "INFO:__main__:e_idx=2/2, chunk_index=54/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3497\n",
      "INFO:bedrock_predictor:Claude completion tokens: 123\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01VSdk55bM2uUBAdRNQbae2L', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passage, the cities of Gloucester and Worcester are located along the River Severn. The passage mentions \"Diglis Basins and two wide locks accessing the Severn\" near Worcester, indicating the Worcester & Birmingham Canal connects to the River Severn around Worcester. It also states that the Droitwich Barge Canal \"offers a route to the River Severn at Hawford\", suggesting the River Severn flows near Worcester. Additionally, it mentions the Gloucester & Berkeley Canal opened in 1827, likely connecting to the River Severn near Gloucester.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3276, 'output_tokens': 133}, 'generated_text': 'Based on the information provided in the passage, the cities of Gloucester and Worcester are located along the River Severn. The passage mentions \"Diglis Basins and two wide locks accessing the Severn\" near Worcester, indicating the Worcester & Birmingham Canal connects to the River Severn around Worcester. It also states that the Droitwich Barge Canal \"offers a route to the River Severn at Hawford\", suggesting the River Severn flows near Worcester. Additionally, it mentions the Gloucester & Berkeley Canal opened in 1827, likely connecting to the River Severn near Gloucester.'}, 'latency': 6.620314416999463, 'prompt_tokens': 3497, 'completion_tokens': 123}\n",
      "INFO:__main__:response_json={'id': 'msg_01VSdk55bM2uUBAdRNQbae2L', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Based on the information provided in the passage, the cities of Gloucester and Worcester are located along the River Severn. The passage mentions \"Diglis Basins and two wide locks accessing the Severn\" near Worcester, indicating the Worcester & Birmingham Canal connects to the River Severn around Worcester. It also states that the Droitwich Barge Canal \"offers a route to the River Severn at Hawford\", suggesting the River Severn flows near Worcester. Additionally, it mentions the Gloucester & Berkeley Canal opened in 1827, likely connecting to the River Severn near Gloucester.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3276, 'output_tokens': 133}, 'generated_text': 'Based on the information provided in the passage, the cities of Gloucester and Worcester are located along the River Severn. The passage mentions \"Diglis Basins and two wide locks accessing the Severn\" near Worcester, indicating the Worcester & Birmingham Canal connects to the River Severn around Worcester. It also states that the Droitwich Barge Canal \"offers a route to the River Severn at Hawford\", suggesting the River Severn flows near Worcester. Additionally, it mentions the Gloucester & Berkeley Canal opened in 1827, likely connecting to the River Severn near Gloucester.'}\n",
      "INFO:__main__:latency=6.620314416999463\n",
      "INFO:__main__:prompt_tokens=3497\n",
      "INFO:__main__:completion_tokens=123\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3497, completion_tokens=123, latency=6.6203\n",
      "INFO:__main__:e_idx=2/2, chunk_index=55/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3003\n",
      "INFO:bedrock_predictor:Claude completion tokens: 45\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_015tLQb9RkPrBbjHd5tAvQaJ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the bassoon is the musical instrument whose Italian name fagotto means \"a bundle of sticks\". The passage states: \"(music, obsolete) A fagotto, or bassoon.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2815, 'output_tokens': 46}, 'generated_text': 'According to the passage, the bassoon is the musical instrument whose Italian name fagotto means \"a bundle of sticks\". The passage states: \"(music, obsolete) A fagotto, or bassoon.\"'}, 'latency': 3.011883917002706, 'prompt_tokens': 3003, 'completion_tokens': 45}\n",
      "INFO:__main__:response_json={'id': 'msg_015tLQb9RkPrBbjHd5tAvQaJ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the bassoon is the musical instrument whose Italian name fagotto means \"a bundle of sticks\". The passage states: \"(music, obsolete) A fagotto, or bassoon.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 2815, 'output_tokens': 46}, 'generated_text': 'According to the passage, the bassoon is the musical instrument whose Italian name fagotto means \"a bundle of sticks\". The passage states: \"(music, obsolete) A fagotto, or bassoon.\"'}\n",
      "INFO:__main__:latency=3.011883917002706\n",
      "INFO:__main__:prompt_tokens=3003\n",
      "INFO:__main__:completion_tokens=45\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3003, completion_tokens=45, latency=3.0119\n",
      "INFO:__main__:e_idx=2/2, chunk_index=56/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3783\n",
      "INFO:bedrock_predictor:Claude completion tokens: 77\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01VZJNJKevb8AcFMMAn5rBYZ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\". The passage states that \"Gordon Jackson, known to television viewers around the world as the crotchety butler Hudson in the TV series \\'Upstairs, Downstairs,\\' died Sunday, his agent said yesterday. He was 66.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3447, 'output_tokens': 83}, 'generated_text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\". The passage states that \"Gordon Jackson, known to television viewers around the world as the crotchety butler Hudson in the TV series \\'Upstairs, Downstairs,\\' died Sunday, his agent said yesterday. He was 66.\"'}, 'latency': 4.481852084005368, 'prompt_tokens': 3783, 'completion_tokens': 77}\n",
      "INFO:__main__:response_json={'id': 'msg_01VZJNJKevb8AcFMMAn5rBYZ', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\". The passage states that \"Gordon Jackson, known to television viewers around the world as the crotchety butler Hudson in the TV series \\'Upstairs, Downstairs,\\' died Sunday, his agent said yesterday. He was 66.\"'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3447, 'output_tokens': 83}, 'generated_text': 'According to the passage, the Scottish actor Gordon Jackson played the role of the butler Hudson in the TV series \"Upstairs, Downstairs\". The passage states that \"Gordon Jackson, known to television viewers around the world as the crotchety butler Hudson in the TV series \\'Upstairs, Downstairs,\\' died Sunday, his agent said yesterday. He was 66.\"'}\n",
      "INFO:__main__:latency=4.481852084005368\n",
      "INFO:__main__:prompt_tokens=3783\n",
      "INFO:__main__:completion_tokens=77\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3783, completion_tokens=77, latency=4.4819\n",
      "INFO:__main__:e_idx=2/2, chunk_index=57/57\n",
      "INFO:__main__:processing chunk with concurrency=1\n",
      "INFO:bedrock_predictor:REST API URL created based on bedrock model id 'anthropic.claude-3-sonnet-20240229-v1:0' : https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-3-sonnet-20240229-v1:0/invoke\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_predictor:CLAUDE PROMPT TOKENS: 3271\n",
      "INFO:bedrock_predictor:Claude completion tokens: 33\n",
      "INFO:__main__:response={'response_json': {'id': 'msg_01SwsVHcrmZ8UMkeEEC8amF6', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the poem, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3118, 'output_tokens': 37}, 'generated_text': 'According to the poem, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}, 'latency': 2.8649290000030305, 'prompt_tokens': 3271, 'completion_tokens': 33}\n",
      "INFO:__main__:response_json={'id': 'msg_01SwsVHcrmZ8UMkeEEC8amF6', 'type': 'message', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'According to the poem, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}], 'model': 'claude-3-sonnet-28k-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 3118, 'output_tokens': 37}, 'generated_text': 'According to the poem, the Owl and the Pussy-Cat sailed away for a year and a day to the land where the Bong-tree grows.'}\n",
      "INFO:__main__:latency=2.8649290000030305\n",
      "INFO:__main__:prompt_tokens=3271\n",
      "INFO:__main__:completion_tokens=33\n",
      "INFO:__main__:get_inference, done, endpoint=anthropic.claude-3-sonnet-20240229-v1:0, prompt_tokens = 3271, completion_tokens=33, latency=2.8649\n",
      "INFO:__main__:the claude-3-sonnet ran for 289.48077712500526 seconds......\n",
      "INFO:__main__:metrics json is: {'experiment_name': 'claude-3-sonnet', 'concurrency': 1, 'payload_file': 'payload_en_3000-4000.jsonl', 'errors': [], 'successes': 1, 'error_rate': 0.0, 'all_prompts_token_count': 3271, 'prompt_token_count_mean': 3271.0, 'prompt_token_throughput': 1115.37, 'all_completions_token_count': 33, 'completion_token_count_mean': 33.0, 'completion_token_throughput': 11.25, 'transactions': 1, 'transactions_per_second': 0.34, 'transactions_per_minute': 20, 'latency_mean': 2.8649290000030305}\n",
      "INFO:bedrock_predictor:pricing dict: {'input-per-1k-tokens': 0.003}\n",
      "INFO:bedrock_predictor:input per 1k token pricing: 0.003\n",
      "INFO:bedrock_predictor:pricing dict: {'output-per-1k-tokens': 0.015}\n",
      "INFO:bedrock_predictor:output per 1k token pricing: 0.015\n",
      "INFO:__main__:the rate for running claude-3-sonnet running on Claudev3-Sonnet-ODT for 289.48077712500526 is $0.010308000000000001....\n",
      "INFO:__main__:experiment=2/2, name=claude-3-sonnet, duration=289.48 seconds, done\n",
      "INFO:__main__:experiment durations:        experiment_name        instance_type duration_in_seconds  cost\n",
      "0  haiku-bedrock-trial   Claudev3-Haiku-ODT              126.61  0.00\n",
      "1      claude-3-sonnet  Claudev3-Sonnet-ODT              289.48  0.01\n",
      "INFO:__main__:Summary for cost of instance per endpoint per run saved to s3://sagemaker-fmbench-write-121797993273/fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/endpoint_per_instance_per_run_costs.csv\n",
      "INFO:__main__:total cost of all experiments: $0.01\n"
     ]
    }
   ],
   "source": [
    "# for each experiment\n",
    "#   - for each endpoint and concurrency in an experiment\n",
    "\n",
    "\n",
    "def clear_dir(dir_path: str):\n",
    "    files = glob.glob(os.path.join(dir_path, \"*\"))\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "\n",
    "_ = list(map(clear_dir, [METRICS_PER_INFERENCE_DIR, METRICS_PER_CHUNK_DIR]))\n",
    "\n",
    "# Initializing the total model instance cost to 0\n",
    "total_model_instance_cost: int = 0\n",
    "\n",
    "## To keep track of the cost for all model endpoints\n",
    "cost_data = []\n",
    "\n",
    "## To keep track of the experiment durations and the time it takes for the model endpoint to be in service to calculate cost association\n",
    "experiment_durations = []  \n",
    "\n",
    "## start the timer before the start of inferences\n",
    "current_time = datetime.now(timezone.utc)\n",
    "logger.info(f\"Current time recorded while running this experiment is {current_time}..... deployed models are going to start inferences...\")\n",
    "\n",
    "num_experiments: int = len(config['experiments'])\n",
    "for e_idx, experiment in enumerate(config['experiments']):\n",
    "    e_idx += 1  # Increment experiment index\n",
    "    experiment_start_time = time.perf_counter()  # Start timer for the experiment\n",
    "\n",
    "    predictor = create_predictor_for_experiment(experiment, config, endpoint_info_list)\n",
    "    if predictor is None:\n",
    "        logger.error(f\"predictor could not be created for experiment={experiment}, moving to next...\")\n",
    "        continue\n",
    "\n",
    "    combination_data = create_combinations(experiment)\n",
    "\n",
    "    for concurrency, payload_file, split_payload in combination_data:\n",
    "        for chunk_index, chunk in enumerate(split_payload):\n",
    "            logger.info(f\"e_idx={e_idx}/{num_experiments}, chunk_index={chunk_index+1}/{len(split_payload)}\")\n",
    "\n",
    "            responses, metrics = await run_inferences(predictor, chunk, experiment, concurrency, payload_file)\n",
    "            if metrics:\n",
    "                metrics_json = json.dumps(metrics, indent=2)\n",
    "                metrics_file_name = f\"{time.time()}.json\"\n",
    "                metrics_s3_path = os.path.join(METRICS_PER_CHUNK_DIR, metrics_file_name)\n",
    "                write_to_s3(metrics_json, config['aws']['bucket'], \"\", METRICS_PER_CHUNK_DIR, metrics_file_name)\n",
    "\n",
    "            if responses:\n",
    "                for r in responses:\n",
    "                    response_json = json.dumps(r, indent=2)\n",
    "                    response_file_name = f\"{time.time()}.json\"\n",
    "                    response_s3_path = os.path.join(METRICS_PER_INFERENCE_DIR, response_file_name)\n",
    "                    write_to_s3(response_json, config['aws']['bucket'], \"\", METRICS_PER_INFERENCE_DIR, response_file_name)\n",
    "    \n",
    "    ## initializing the experiment cost\n",
    "    exp_cost = 0\n",
    "    \n",
    "    # Experiment done, stopping the timer for this given experiment\n",
    "    experiment_end_time = time.perf_counter()\n",
    "\n",
    "    # calculating the duration of this given endpoint inference time\n",
    "    experiment_duration = experiment_end_time - experiment_start_time\n",
    "    logger.info(f\"the {experiment['name']} ran for {experiment_duration} seconds......\")\n",
    "\n",
    "    # calculating the per second cost for this instance type\n",
    "    exp_instance_type: str = experiment['instance_type']\n",
    "\n",
    "    # ## add an if statement here for bedrock versus sagemaker [ if sagemaker call, then hourly, if bedrock, then through the number of tokens ]\n",
    "\n",
    "    # # price of the given instance for this experiment \n",
    "    # hourly_rate = config['pricing'].get(experiment['instance_type'], 0)\n",
    "    # logger.info(f\"the hourly rate for {experiment['name']} running on {exp_instance_type} is {hourly_rate}\")\n",
    "\n",
    "    # cost_per_second = hourly_rate / 3600\n",
    "    # logger.info(f\"the rate for {experiment['name']} running on {exp_instance_type} is {cost_per_second} per second\")\n",
    "    \n",
    "    #cost for this given exp\n",
    "    logger.info(f\"metrics json is: {metrics}\")\n",
    "    # exp_cost = experiment_duration * cost_per_second\n",
    "    exp_cost = predictor.calculate_cost(exp_instance_type, config, experiment_duration, metrics)\n",
    "    logger.info(f\"the rate for running {experiment['name']} running on {exp_instance_type} for {experiment_duration} is ${exp_cost}....\")\n",
    "\n",
    "    ## tracking the total cost\n",
    "    total_model_instance_cost += exp_cost\n",
    "\n",
    "    experiment_durations.append({\n",
    "        'experiment_name': experiment['name'],\n",
    "        'instance_type': exp_instance_type, \n",
    "        'duration_in_seconds': f\"{experiment_duration:.2f}\", \n",
    "        'cost': f\"{exp_cost:.2f}\", \n",
    "    })\n",
    "\n",
    "    logger.info(f\"experiment={e_idx}/{num_experiments}, name={experiment['name']}, duration={experiment_duration:.2f} seconds, done\")\n",
    "\n",
    "# experiment_durations.append({'total_cost': f\"${total_model_instance_cost:.2f}\"})\n",
    "\n",
    "# After all experiments are done, summarize and optionally save experiment durations along with costs\n",
    "df_durations = pd.DataFrame(experiment_durations)\n",
    "logger.info(f\"experiment durations: {df_durations}\")\n",
    "\n",
    "# Convert the DataFrame to CSV and write it to S3 or wherever you prefer\n",
    "csv_buffer_cost = io.StringIO()\n",
    "df_durations.to_csv(csv_buffer_cost, index=False)\n",
    "experiment_associated_cost = csv_buffer_cost.getvalue()\n",
    "\n",
    "# Assuming write_to_s3() is already defined and configured correctly\n",
    "write_to_s3(experiment_associated_cost, config['aws']['bucket'], \"\", METRICS_DIR, SUMMARY_MODEL_ENDPOINT_COST_PER_INSTANCE)\n",
    "logger.info(f\"Summary for cost of instance per endpoint per run saved to s3://{config['aws']['bucket']}/{METRICS_DIR}/{SUMMARY_MODEL_ENDPOINT_COST_PER_INSTANCE}\")\n",
    "\n",
    "logger.info(f\"total cost of all experiments: ${sum(df_durations.cost.astype(float))}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fmbench.utils:found 114 items in bucket=sagemaker-fmbench-write-121797993273, prefix=fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/per_inference, suffix=.json\n",
      "INFO:fmbench.utils:there are total of 114 items in bucket=sagemaker-fmbench-write-121797993273, prefix=fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/per_inference, suffix=.json\n",
      "INFO:__main__:created dataframe of shape (114, 10) from all responses\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>Accept</th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>latency</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>Based on the information provided in the passa...</td>\n",
       "      <td>3000</td>\n",
       "      <td>80</td>\n",
       "      <td>1.877980</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>Unfortunately, there is no information provide...</td>\n",
       "      <td>3896</td>\n",
       "      <td>63</td>\n",
       "      <td>2.190344</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>Based on the information provided, Erich Haeni...</td>\n",
       "      <td>3789</td>\n",
       "      <td>54</td>\n",
       "      <td>1.515067</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>According to the information provided, Thomas ...</td>\n",
       "      <td>3450</td>\n",
       "      <td>33</td>\n",
       "      <td>1.362943</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>No, Ding Yaping and Johann Christian Gustav Lu...</td>\n",
       "      <td>3482</td>\n",
       "      <td>50</td>\n",
       "      <td>1.171559</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            endpoint_name  \\\n",
       "0  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "1  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "2  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "3  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "4  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "\n",
       "                                              prompt       ContentType  \\\n",
       "0  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "1  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "2  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "3  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "4  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "\n",
       "             Accept                                         completion  \\\n",
       "0  application/json  Based on the information provided in the passa...   \n",
       "1  application/json  Unfortunately, there is no information provide...   \n",
       "2  application/json  Based on the information provided, Erich Haeni...   \n",
       "3  application/json  According to the information provided, Thomas ...   \n",
       "4  application/json  No, Ding Yaping and Johann Christian Gustav Lu...   \n",
       "\n",
       "   prompt_tokens  completion_tokens   latency      experiment_name  \\\n",
       "0           3000                 80  1.877980  haiku-bedrock-trial   \n",
       "1           3896                 63  2.190344  haiku-bedrock-trial   \n",
       "2           3789                 54  1.515067  haiku-bedrock-trial   \n",
       "3           3450                 33  1.362943  haiku-bedrock-trial   \n",
       "4           3482                 50  1.171559  haiku-bedrock-trial   \n",
       "\n",
       "   concurrency  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List .json files in the specified S3 directory\n",
    "s3_files = list_s3_files(config['aws']['bucket'], METRICS_PER_INFERENCE_DIR)\n",
    "\n",
    "# Read and parse each JSON file from S3\n",
    "json_list = list(map(lambda key: json.loads(get_s3_object(config['aws']['bucket'], key)), \\\n",
    "                     s3_files))\n",
    "\n",
    "# Create DataFrame\n",
    "df_responses = pd.DataFrame(json_list)\n",
    "logger.info(f\"created dataframe of shape {df_responses.shape} from all responses\")\n",
    "df_responses.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fmbench.utils:found 114 items in bucket=sagemaker-fmbench-write-121797993273, prefix=fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/per_chunk, suffix=.json\n",
      "INFO:fmbench.utils:there are total of 114 items in bucket=sagemaker-fmbench-write-121797993273, prefix=fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/per_chunk, suffix=.json\n",
      "INFO:__main__:created dataframe of shape (114, 16) from all responses\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>payload_file</th>\n",
       "      <th>errors</th>\n",
       "      <th>successes</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>all_prompts_token_count</th>\n",
       "      <th>prompt_token_count_mean</th>\n",
       "      <th>prompt_token_throughput</th>\n",
       "      <th>all_completions_token_count</th>\n",
       "      <th>completion_token_count_mean</th>\n",
       "      <th>completion_token_throughput</th>\n",
       "      <th>transactions</th>\n",
       "      <th>transactions_per_second</th>\n",
       "      <th>transactions_per_minute</th>\n",
       "      <th>latency_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_3000-4000.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1491.46</td>\n",
       "      <td>80</td>\n",
       "      <td>80.0</td>\n",
       "      <td>39.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30</td>\n",
       "      <td>1.877980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_3000-4000.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3896</td>\n",
       "      <td>3896.0</td>\n",
       "      <td>1724.32</td>\n",
       "      <td>63</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>26</td>\n",
       "      <td>2.190344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_3000-4000.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3789</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>2417.30</td>\n",
       "      <td>54</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>38</td>\n",
       "      <td>1.515067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_3000-4000.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3450</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>2456.55</td>\n",
       "      <td>33</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>42</td>\n",
       "      <td>1.362943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_3000-4000.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3482</td>\n",
       "      <td>3482.0</td>\n",
       "      <td>2862.10</td>\n",
       "      <td>50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>49</td>\n",
       "      <td>1.171559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       experiment_name  concurrency                payload_file errors  \\\n",
       "0  haiku-bedrock-trial            1  payload_en_3000-4000.jsonl     []   \n",
       "1  haiku-bedrock-trial            1  payload_en_3000-4000.jsonl     []   \n",
       "2  haiku-bedrock-trial            1  payload_en_3000-4000.jsonl     []   \n",
       "3  haiku-bedrock-trial            1  payload_en_3000-4000.jsonl     []   \n",
       "4  haiku-bedrock-trial            1  payload_en_3000-4000.jsonl     []   \n",
       "\n",
       "   successes  error_rate  all_prompts_token_count  prompt_token_count_mean  \\\n",
       "0          1         0.0                     3000                   3000.0   \n",
       "1          1         0.0                     3896                   3896.0   \n",
       "2          1         0.0                     3789                   3789.0   \n",
       "3          1         0.0                     3450                   3450.0   \n",
       "4          1         0.0                     3482                   3482.0   \n",
       "\n",
       "   prompt_token_throughput  all_completions_token_count  \\\n",
       "0                  1491.46                           80   \n",
       "1                  1724.32                           63   \n",
       "2                  2417.30                           54   \n",
       "3                  2456.55                           33   \n",
       "4                  2862.10                           50   \n",
       "\n",
       "   completion_token_count_mean  completion_token_throughput  transactions  \\\n",
       "0                         80.0                        39.77             1   \n",
       "1                         63.0                        27.88             1   \n",
       "2                         54.0                        34.45             1   \n",
       "3                         33.0                        23.50             1   \n",
       "4                         50.0                        41.10             1   \n",
       "\n",
       "   transactions_per_second  transactions_per_minute  latency_mean  \n",
       "0                     0.50                       30      1.877980  \n",
       "1                     0.44                       26      2.190344  \n",
       "2                     0.64                       38      1.515067  \n",
       "3                     0.71                       42      1.362943  \n",
       "4                     0.82                       49      1.171559  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List .json files in the specified S3 directory\n",
    "s3_files = list_s3_files(config['aws']['bucket'], METRICS_PER_CHUNK_DIR)\n",
    "\n",
    "# Read and parse each JSON file from S3\n",
    "json_list = list(map(lambda key: json.loads(get_s3_object(config['aws']['bucket'], key)), \\\n",
    "                     s3_files))\n",
    "\n",
    "# Create DataFrame\n",
    "df_metrics = pd.DataFrame(json_list)\n",
    "logger.info(f\"created dataframe of shape {df_metrics.shape} from all responses\")\n",
    "df_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:the instance type: Claudev3-Haiku-ODT\n",
      "INFO:__main__:the instance type: Claudev3-Sonnet-ODT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_responses: Index(['endpoint_name', 'prompt', 'ContentType', 'Accept', 'completion',\n",
      "       'prompt_tokens', 'completion_tokens', 'latency', 'experiment_name',\n",
      "       'concurrency'],\n",
      "      dtype='object')\n",
      "Columns in df_endpoints: Index(['experiment_name', 'instance_type', 'EndpointName', 'ModelName',\n",
      "       'Image', 'S3Uri'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>Accept</th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>latency</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>EndpointName</th>\n",
       "      <th>ModelName</th>\n",
       "      <th>Image</th>\n",
       "      <th>S3Uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>Based on the information provided in the passa...</td>\n",
       "      <td>3000</td>\n",
       "      <td>80</td>\n",
       "      <td>1.877980</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>Claudev3-Haiku-ODT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>Unfortunately, there is no information provide...</td>\n",
       "      <td>3896</td>\n",
       "      <td>63</td>\n",
       "      <td>2.190344</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>Claudev3-Haiku-ODT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>Based on the information provided, Erich Haeni...</td>\n",
       "      <td>3789</td>\n",
       "      <td>54</td>\n",
       "      <td>1.515067</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>Claudev3-Haiku-ODT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>According to the information provided, Thomas ...</td>\n",
       "      <td>3450</td>\n",
       "      <td>33</td>\n",
       "      <td>1.362943</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>Claudev3-Haiku-ODT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an assistant for qu...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>application/json</td>\n",
       "      <td>No, Ding Yaping and Johann Christian Gustav Lu...</td>\n",
       "      <td>3482</td>\n",
       "      <td>50</td>\n",
       "      <td>1.171559</td>\n",
       "      <td>haiku-bedrock-trial</td>\n",
       "      <td>1</td>\n",
       "      <td>Claudev3-Haiku-ODT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            endpoint_name  \\\n",
       "0  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "1  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "2  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "3  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "4  anthropic.claude-3-haiku-20240307-v1:0   \n",
       "\n",
       "                                              prompt       ContentType  \\\n",
       "0  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "1  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "2  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "3  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "4  <s>[INST] <<SYS>>\\nYou are an assistant for qu...  application/json   \n",
       "\n",
       "             Accept                                         completion  \\\n",
       "0  application/json  Based on the information provided in the passa...   \n",
       "1  application/json  Unfortunately, there is no information provide...   \n",
       "2  application/json  Based on the information provided, Erich Haeni...   \n",
       "3  application/json  According to the information provided, Thomas ...   \n",
       "4  application/json  No, Ding Yaping and Johann Christian Gustav Lu...   \n",
       "\n",
       "   prompt_tokens  completion_tokens   latency      experiment_name  \\\n",
       "0           3000                 80  1.877980  haiku-bedrock-trial   \n",
       "1           3896                 63  2.190344  haiku-bedrock-trial   \n",
       "2           3789                 54  1.515067  haiku-bedrock-trial   \n",
       "3           3450                 33  1.362943  haiku-bedrock-trial   \n",
       "4           3482                 50  1.171559  haiku-bedrock-trial   \n",
       "\n",
       "   concurrency       instance_type EndpointName ModelName Image S3Uri  \n",
       "0            1  Claudev3-Haiku-ODT          NaN       NaN   NaN   NaN  \n",
       "1            1  Claudev3-Haiku-ODT          NaN       NaN   NaN   NaN  \n",
       "2            1  Claudev3-Haiku-ODT          NaN       NaN   NaN   NaN  \n",
       "3            1  Claudev3-Haiku-ODT          NaN       NaN   NaN   NaN  \n",
       "4            1  Claudev3-Haiku-ODT          NaN       NaN   NaN   NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if endpoint_info_list:\n",
    "    df_endpoints = pd.json_normalize(endpoint_info_list)\n",
    "    df_endpoints['instance_type'] = df_endpoints['endpoint_config.ProductionVariants'].map(lambda x: x[0]['InstanceType'])\n",
    "    cols_for_env = [c for c in df_endpoints.columns if 'Environment' in c]\n",
    "    print(cols_for_env)\n",
    "    cols_of_interest = ['experiment_name',\n",
    "                        'instance_type',\n",
    "                        'endpoint.EndpointName',\n",
    "                        'model_config.ModelName',\n",
    "                        'model_config.PrimaryContainer.Image',\n",
    "                        'model_config.PrimaryContainer.ModelDataSource.S3DataSource.S3Uri']\n",
    "    cols_of_interest.extend(cols_for_env)\n",
    "\n",
    "    df_endpoints = df_endpoints[cols_of_interest]\n",
    "    cols_of_interest_renamed = [c.split('.')[-1] for c in cols_of_interest]\n",
    "    df_endpoints.columns = cols_of_interest_renamed\n",
    "else:\n",
    "    # Create an empty DataFrame with the desired columns\n",
    "    df_endpoints = pd.DataFrame(columns=['experiment_name',\n",
    "                                         'instance_type',\n",
    "                                         'EndpointName',\n",
    "                                         'ModelName',\n",
    "                                         'Image',\n",
    "                                         'S3Uri'])\n",
    "\n",
    "# Check if 'experiment_name' column exists in both DataFrames\n",
    "print(\"Columns in df_responses:\", df_responses.columns)\n",
    "print(\"Columns in df_endpoints:\", df_endpoints.columns)\n",
    "\n",
    "df_results = pd.merge(left=df_responses, right=df_endpoints, how='left', left_on='experiment_name', right_on='experiment_name')\n",
    "\n",
    "for e, experiment in enumerate(config['experiments']):\n",
    "    experiment_name = experiment['name']\n",
    "    instance_type = experiment['instance_type']\n",
    "    \n",
    "    logger.info(f\"the instance type: {instance_type}\")\n",
    "    # Update the instance_type column in df_results where the EndpointName matches\n",
    "    df_results.loc[df_results['experiment_name'] == experiment_name, 'instance_type'] = instance_type\n",
    "\n",
    "# Inspect the result\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:results s3 path for per inference csv --> fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/per_inference_request_results.csv\n",
      "INFO:__main__:saved results dataframe of shape=(114, 15) in s3://sagemaker-fmbench-write-121797993273/fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/per_inference_request_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert df_results to CSV and write to S3\n",
    "csv_buffer = io.StringIO()\n",
    "df_results.to_csv(csv_buffer, index=False)\n",
    "csv_data_results = csv_buffer.getvalue()\n",
    "results_file_name = config['report']['per_inference_request_file'].format(datetime=date_time)\n",
    "results_s3_path = os.path.join(METRICS_DIR, results_file_name)\n",
    "logger.info(f\"results s3 path for per inference csv --> {results_s3_path}\")\n",
    "write_to_s3(csv_data_results, config['aws']['bucket'], \"\", METRICS_DIR, results_file_name)\n",
    "logger.info(f\"saved results dataframe of shape={df_results.shape} in s3://{BUCKET_NAME}/{results_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:the metrics metadata path is saved here --> metadata/metrics_path.txt\n",
      "INFO:__main__:the information on the defined path for results on these metrics are given in this --> fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10\n"
     ]
    }
   ],
   "source": [
    "# Ensure the metadata directory exists\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)\n",
    "\n",
    "# Path for the metrics_path.txt file\n",
    "metrics_path_file = os.path.join(METADATA_DIR, 'metrics_path.txt')\n",
    "logger.info(f\"the metrics metadata path is saved here --> {metrics_path_file}\")\n",
    "\n",
    "# Write the METRICS_DIR to metrics_path.txt\n",
    "with open(metrics_path_file, 'w') as file:\n",
    "    file.write(METRICS_DIR)\n",
    "\n",
    "## Write this data to S3\n",
    "write_to_s3(METRICS_DIR, config['aws']['bucket'], \"\", DATA_DIR, 'metrics_path.txt')\n",
    "\n",
    "logger.info(f\"the information on the defined path for results on these metrics are given in this --> {METRICS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:df_metrics cols = Index(['experiment_name', 'concurrency', 'payload_file', 'errors', 'successes',\n",
      "       'error_rate', 'all_prompts_token_count', 'prompt_token_count_mean',\n",
      "       'prompt_token_throughput', 'all_completions_token_count',\n",
      "       'completion_token_count_mean', 'completion_token_throughput',\n",
      "       'transactions', 'transactions_per_second', 'transactions_per_minute',\n",
      "       'latency_mean'],\n",
      "      dtype='object')\n",
      "INFO:__main__:df_endpoints cols = Index(['experiment_name', 'instance_type', 'EndpointName', 'ModelName',\n",
      "       'Image', 'S3Uri'],\n",
      "      dtype='object')\n",
      "INFO:__main__:the instance type: Claudev3-Haiku-ODT\n",
      "INFO:__main__:the instance type: Claudev3-Sonnet-ODT\n",
      "INFO:__main__:results s3 path for metrics csv --> fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/all_metrics.csv\n",
      "INFO:__main__:saved metrics results dataframe of shape=(114, 21) in s3://sagemaker-fmbench-write-121797993273/fmbench-claude-ab3/data/metrics/yyyy=2024/mm=03/dd=22/hh=13/mm=10/all_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# logger.info(f\"df_metrics cols = {df_metrics.columns}\")\n",
    "# logger.info(f\"df_endpoints cols = {df_endpoints.columns}\")\n",
    "# df_metrics = pd.merge(left=df_metrics, right=df_endpoints, how='left', left_on='experiment_name', right_on='experiment_name')\n",
    "\n",
    "# for e, experiment in enumerate(config['experiments']):\n",
    "#     experiment_name = experiment['name']\n",
    "#     instance_type = experiment['instance_type']\n",
    "    \n",
    "#     logger.info(f\"the instance type: {instance_type}\")\n",
    "#     # Update the instance_type column in df_results where the EndpointName matches\n",
    "#     df_metrics.loc[df_results['experiment_name'] == experiment_name, 'instance_type'] = instance_type\n",
    "\n",
    "# df_metrics.head()\n",
    "\n",
    "# # Convert df_metrics to CSV and write to S3\n",
    "# csv_buffer = io.StringIO()\n",
    "# df_metrics.to_csv(csv_buffer, index=False)\n",
    "# csv_data_metrics = csv_buffer.getvalue()\n",
    "# metrics_file_name = config['report']['all_metrics_file'].format(datetime=date_time)\n",
    "# metrics_s3_path = os.path.join(METRICS_DIR, metrics_file_name)\n",
    "# logger.info(f\"results s3 path for metrics csv --> {metrics_s3_path}\")\n",
    "# write_to_s3(csv_data_metrics, config['aws']['bucket'], \"\", METRICS_DIR, metrics_file_name)\n",
    "# logger.info(f\"saved metrics results dataframe of shape={df_metrics.shape} in s3://{config['aws']['bucket']}/{metrics_s3_path}\")\n",
    "\n",
    "logger.info(f\"df_metrics cols = {df_metrics.columns}\")\n",
    "logger.info(f\"df_endpoints cols = {df_endpoints.columns}\")\n",
    "df_metrics = pd.merge(left=df_metrics, right=df_endpoints, how='left', left_on='experiment_name', right_on='experiment_name')\n",
    "for e, experiment in enumerate(config['experiments']):\n",
    "    experiment_name = experiment['name']\n",
    "    instance_type = experiment['instance_type']\n",
    "    \n",
    "    logger.info(f\"the instance type: {instance_type}\")\n",
    "    # Update the instance_type column in df_results where the EndpointName matches\n",
    "    df_metrics.loc[df_results['experiment_name'] == experiment_name, 'instance_type'] = instance_type\n",
    "df_metrics.head()\n",
    "\n",
    "# Convert df_metrics to CSV and write to S3\n",
    "csv_buffer = io.StringIO()\n",
    "df_metrics.to_csv(csv_buffer, index=False)\n",
    "csv_data_metrics = csv_buffer.getvalue()\n",
    "metrics_file_name = config['report']['all_metrics_file'].format(datetime=date_time)\n",
    "metrics_s3_path = os.path.join(METRICS_DIR, metrics_file_name)\n",
    "logger.info(f\"results s3 path for metrics csv --> {metrics_s3_path}\")\n",
    "write_to_s3(csv_data_metrics, config['aws']['bucket'], \"\", METRICS_DIR, metrics_file_name)\n",
    "logger.info(f\"saved metrics results dataframe of shape={df_metrics.shape} in s3://{config['aws']['bucket']}/{metrics_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
