general:
  name: "Llama3-1-8b-g5"
  model_name: "Llama3-1-8b"

s3_read_data:
  source_data_files:
  - 2wikimqa_e.jsonl
  - 2wikimqa.jsonl
  - hotpotqa_e.jsonl
  - hotpotqa.jsonl
  - narrativeqa.jsonl
  - triviaqa_e.jsonl
  - triviaqa.jsonl
  tokenizer_prefix: llama3_1_tokenizer
  prompt_template_file: prompt_template_llama3.txt

datasets:
  # dataset related configuration
  prompt_template_keys:
  - input
  - context
  ground_truth_col_key: answers
  question_col_key: input

run_steps:
  0_setup.ipynb: yes
  1_generate_data.ipynb: yes
  2_deploy_model.ipynb: yes
  3_run_inference.ipynb: yes
  4_get_evaluations.ipynb: no
  5_model_metric_analysis.ipynb: yes
  6_cleanup.ipynb: yes

inference_parameters:
  sagemaker:
    do_sample: yes
    temperature: 0.1
    top_p: 0.92
    top_k: 120  
    max_new_tokens: 100

experiment: &experiment_defaults
  model_version: "*"
  download_from_hf_place_in_s3: yes
  deploy: yes
  instance_count: 1
  deployment_script: deploy_w_djl_serving.py
  inference_script: sagemaker_predictor.py
  inference_spec:
    parameter_set: sagemaker
  accept_eula: true
  payload_files:
  - payload_en_1-500.jsonl
  - payload_en_500-1000.jsonl
  - payload_en_1000-2000.jsonl
  - payload_en_2000-3000.jsonl
  serving.properties: |
      engine=Python
      option.model_id=s3://{write_bucket}/meta-llama/Llama-3.1-8B-Instruct
      option.dtype=fp16
  concurrency_levels:
  - 1
  - 2

metrics:
  dataset_of_interest: en_2000-3000

experiments:
  - <<: *experiment_defaults
    name: Llama3-1-8b-g5.2xl-djl-inference:0.29.0-lmi11.0.0-cu124
    model_id: meta-llama/Llama-3.1-8B-Instruct
    model_name: Meta-Llama-3-1-8B-Instruct
    ep_name: Meta-Llama-3-1-8B-Instruct-g5-2xl
    model_s3_path: s3://{write_bucket}/meta-llama/Llama-3.1-8B-Instruct
    instance_type: "ml.g5.xlarge"
    image_uri: 763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124

  - <<: *experiment_defaults
    name: Llama3-1-8b-g5.4xl-djl-inference:0.29.0-lmi11.0.0-cu124
    model_id: meta-llama/Llama-3.1-8B-Instruct
    model_name: Meta-Llama-3-1-8B-Instruct
    ep_name: Meta-Llama-3-1-8B-Instruct-g5-4xl
    model_s3_path: s3://{write_bucket}/meta-llama/Llama-3.1-8B-Instruct
    instance_type: "ml.g5.2xlarge"
    image_uri: 763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124

report:
  latency_budget: 2
  cost_per_10k_txn_budget: 100

config_files:
  infrastructure: infrastructure.yml
  dataset: dataset_filter_preparation.yml
  metrics: metrics.yml