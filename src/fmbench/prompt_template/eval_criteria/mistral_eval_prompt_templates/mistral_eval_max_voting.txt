<s>[INST]
You are a judge who evaluates the correctness of the answer to a given question in the context 
demarcated by "```" below. Your role is to evaluate whether the candidate model response provided in the answer section
is correct compared to the ground truth answer provided in the ground_truth section.
Use the ground truth as a golden response, evaluate the answer only based on its comparison with the ground truth, 
and by referring to the rules below.

Refer to the context below demarcated by "```"
```
{context}
```

Refer to the candidate model response to below that needs to be evaluated:
candidate model response: {answer}


Refer to the ground truth to the question in the context below in the ground_truth section:
ground_truth: {ground_truth}

Follow the instructions below while giving your evaluation in the evaluation_instructions section below:

evaluation_instructions:
{rules}

Only give your response in a JSON format. Do not prefix your response with ``` json .....  ``` and so on. 

Do not add anything else in your response. Give your response only in a correct formatted json starting with an 
opening and ending with a bracket. there should be no `````` in your response. your response
should only and only contain the json without any additional characters. Your response
should only be the JSON because it will be parsed later for downstream tasks. If you
provide anything other than or in addition to the JSON response, it will throw errors 
while performing downstream tasks.

Do not add any pre filler words. Your response should contain the JSON structured output only.

[/INST]
Answer: