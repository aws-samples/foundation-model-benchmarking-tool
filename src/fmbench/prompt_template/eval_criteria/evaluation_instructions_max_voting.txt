1. Evaluation Basis: Evaluate whether the candidate model output answers the question correctly compared to the ground truth provided.

2. JSON Response Format: Your response should be a JSON containing two elements: "verdict" and "explanation". The "verdict" field should mention whether the candidate model output is "correct" or "incorrect". The "explanation" field should provide the reason for the verdict based on the evaluation of the candidate model output against the ground truth.

3. Content Matching: The candidate model output does not have to use the exact wording of the ground truth but should correctly answer the question in a semantically equivalent manner. If there is more content in the candidate model response but it answers the question correctly and aligns with the ground truth, the verdict is "correct". Otherwise, it is "incorrect".

4. Absence of Information: If the candidate model output says that the context does not contain the answer and it differs from what the ground truth says, the verdict is "incorrect".

5. Incomplete Answers: If the candidate model output answers the question incorrectly or is incomplete (lacking important elements present in the ground truth), the verdict is "incorrect".

6. Careful Reading: Before giving your verdict, carefully read the ground truth, then the question, and finally the candidate model response. Ensure the response aligns with the ground truth in providing the correct answer.

7. Correct Semantic Matching: If the candidate model output matches the ground truth, not necessarily in wordings, but in providing the correct answer, the verdict is "correct".

8. Proper JSON Format: Ensure your response is in a proper JSON format containing the "verdict" and "explanation" fields without any pre-filler words.

9. Multiple Correct Responses: If the ground truth is a comma-separated list with multiple correct responses, the verdict is correct if the candidate model response aligns with any of the options.

10. Last Question Consideration: If there are multiple questions within the context, refer to the last question for evaluation.

11. Synonym and Paraphrase Matching: If the candidate model output uses synonyms or paraphrases but still correctly answers the question in the same way as the ground truth, the verdict should be "correct". The explanation should mention the semantic equivalence.

12. Additional Context: If the candidate model output includes unnecessary context or information not given in the ground truth but successfully concludes the correct answer as the ground truth, the verdict is "correct".

13. Multiple Valid Responses: If the ground truth provides multiple correct responses, any candidate model output that aligns with any of the correct options should be considered "correct". The explanation should mention the specific ground truth option the candidate model output matches.

14. Redundancy in Context: If the candidate model output includes redundant information but still correctly answers the question according to the ground truth, the verdict should be "correct".

15. Careful Rechecking: Finally, read the question to yourself. After reading the question, read the candidate model response and ground truth at the same time. If they both answer the question correctly, then the verdict is "correct". If the ground truth answers the question but the candidate model response does not in any way, then the verdict is "incorrect".