{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d144a1ec-e66d-45b8-baf1-af4641ee23ce",
   "metadata": {},
   "source": [
    "# Bring your own dataset\n",
    "\n",
    "---------\n",
    "*This notebook works best with the conda_python3 kernel on a ml.t3.medium machine*.\n",
    "\n",
    "### This part of our solution design includes \n",
    "\n",
    "- Creating your own `fmbench` compatible dataset from a [HuggingFace dataset](https://huggingface.co/docs/datasets/en/index).\n",
    "\n",
    "- Creating a prompt payload template compatible with your dataset.\n",
    "\n",
    "- Upload the dataset and the prompt payload to Amazon S3 from where it can be used by `fmbench`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa135b-2dec-4e2c-9821-bd8268a21492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if interactive mode is set to no -> pickup fmbench from Python installation path\n",
    "# if interactive mode is set to yes -> pickup fmbench from the current path (one level above this notebook)\n",
    "# if interactive mode is not defined -> pickup fmbench from the current path (one level above this notebook)\n",
    "# the premise is that if run non-interactively then it can only be run through main.py which will set interactive mode to no\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "if os.environ.get(\"INTERACTIVE_MODE_SET\", \"yes\") == \"yes\":\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64051b6-faae-4d92-b753-e88ffc5b59e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343d0fb-89cc-48da-8c77-22b8024a7e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fmbench.utils import *\n",
    "from fmbench.globals import *\n",
    "from datasets import load_dataset\n",
    "config = load_config(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89998f93-e59a-4d47-9957-ad0b11a089f7",
   "metadata": {},
   "source": [
    "## Convert HuggingFace dataset to jsonl format\n",
    "\n",
    "`fmbench` works with datasets in the [`JSON Lines`](https://jsonlines.org/) format. So here we show how to convert a HuggingFace dataset into JSON lines format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d021d-ff1c-4275-85ae-128265b0d5fa",
   "metadata": {},
   "source": [
    "Set the `ds_name` to the HuggingFace dataset id, for example [`THUDM/LongBench`](https://huggingface.co/datasets/THUDM/LongBench), [`rajpurkar/squad_v2`](https://huggingface.co/datasets/rajpurkar/squad_v2), [`banking77`](https://huggingface.co/datasets/banking77) or other text datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f7a8a-7cb7-491a-a087-57b019fd4cfb",
   "metadata": {},
   "source": [
    "#### Standard Text Datasets\n",
    "---\n",
    " \n",
    "If you are using FMBench to benchmark models on standard text datasets, run the cells below to perform appropriate data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bad51-f5dd-45e0-a08c-cbfd33206301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_id: str = \"rajpurkar/squad\"\n",
    "ds_name: str = \"plain_text\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"THUDM/LongBench\"\n",
    "# ds_name: str = \"2wikimqa\"\n",
    "# ds_split: str = \"test\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 200\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"banking77\"\n",
    "# ds_name: str = \"default\"\n",
    "# ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 10000\n",
    "\n",
    "ds_id: str = \"Open-Orca/OpenOrca\"\n",
    "ds_name: str = \"default\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cdc0a-277c-4809-ab01-980fca362f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to load the dataset and return the list of the dataset to convert into a df and then into a jsonl file\n",
    "import logging\n",
    "import itertools\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "def load_hf_ds_subset(\n",
    "    ds_id: str,\n",
    "    ds_split: str = \"train\",\n",
    "    ds_N: int = 100\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    Loads a subset of the Dolly dataset in streaming mode, taking the first ds_N examples.\n",
    "    \n",
    "    Args:\n",
    "        ds_id (str): The dataset identifier (default: 'databricks/databricks-dolly-15k').\n",
    "        ds_split (str): The split of the dataset to load (default: 'train').\n",
    "        ds_N (int): Number of examples to take from the dataset (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        Dataset: A Hugging Face Dataset object containing ds_N examples.\n",
    "    \"\"\"\n",
    "    logger.info(\n",
    "        f\"Starting to load dataset with id='{ds_id}', split='{ds_split}', \"\n",
    "        f\"taking the first {ds_N} examples in streaming mode.\"\n",
    "    )\n",
    "    dataset_stream = load_dataset(\n",
    "        ds_id,\n",
    "        split=ds_split,\n",
    "        streaming=True\n",
    "    )\n",
    "    dataset_iter = itertools.islice(dataset_stream, ds_N)\n",
    "    # Convert to a list\n",
    "    dataset_list = list(dataset_iter)\n",
    "    # Convert the list to a regular (in-memory) Hugging Face Dataset\n",
    "    subset_dataset = Dataset.from_list(dataset_list)\n",
    "    logger.info(f\"Loaded {len(subset_dataset)} examples from the dataset.\")\n",
    "    return subset_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d398d-0dbc-49cc-a76e-93854cba04bb",
   "metadata": {},
   "source": [
    "### Preprocess the Dolly Dataset\n",
    "---\n",
    "\n",
    "In this section of the notebook, we will pre process the Dolly dataset. The `databricks/databricks-dolly-15k` is an open source dataset of instruction-following records generated by thousands of Databricks employees in several of the behavioral categories outlined in the InstructGPT paper, including brainstorming, classification, closed QA, generation, information extraction, open QA, and summarization. This dataset contains the `instruction` and the `context`. However, for some of the categories for example open QA, the context is not provided. To make this consistent, we will add the context in a new line within the instruction field so that we can have the Foundation Models (FMs) consistently evaluate all content without having empty contexts in some of the calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55211757-fc29-4292-bf08-170693c782f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_id: str = \"databricks/databricks-dolly-15k\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98d6b5-addb-4e60-ba2a-adb6978bb7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_hf_ds_subset(ds_id, ds_split, ds_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284d9ad-aac6-48e1-aafd-f385ccb5c3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dataset to a dataframe, for print it out and easy conversion to jsonl\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a3b7a-ba4a-4a7a-98fc-8f74223cf0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"dataset shape before random subset = {df.shape}\")\n",
    "df = df.sample(n=ds_N)\n",
    "print(f\"dataset shape before random subset = {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf17096a-dd85-4ea9-92e8-74cf20905238",
   "metadata": {},
   "source": [
    "#### Merge the instruction and context\n",
    "---\n",
    "\n",
    "Now, we will add the context as a new line to the instruction column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7bb07-e90d-4efe-a3cf-8ca8716f8afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Append context to instruction only if context is not empty\n",
    "df[\"instruction\"] = df.apply(\n",
    "    lambda row: row[\"instruction\"] + \"\\n\" + row[\"context\"] \n",
    "                if isinstance(row[\"context\"], str) and row[\"context\"].strip() != \"\" \n",
    "                else row[\"instruction\"],\n",
    "    axis=1\n",
    ")\n",
    "df.drop(columns=[\"context\"], inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02860d2c-d992-4f53-b78c-38b06da69d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Preprocessed and loaded the dolly dataset. Going to load the jsonl line in the s3 bucket\")\n",
    "jsonl_content = df.to_json(orient='records', lines=True)\n",
    "print(jsonl_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5137cef-b568-4fac-a183-22ebfbb02c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['source_data_prefix']\n",
    "file_name: str = f\"{ds_id}.jsonl\"\n",
    "write_to_s3(jsonl_content, bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed39e1-8e07-4eb8-bc40-2442912e84ed",
   "metadata": {},
   "source": [
    "### Preprocess the OpenOrca Dataset\n",
    "---\n",
    "\n",
    "In this section of the notebook, we will pre process the OpenOrca dataset. This dataset contains the `system prompt` and the `question`. However, for some of the questions, the system prompt is not provided. To make this consistent, we will add the system prompt as a prefix to the question field so that we can have the Foundation Models (FMs) consistently evaluate all content without having empty system prompts in some of the calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d9740-b62f-4654-af3a-9be9dd3f7adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_id: str = \"Open-Orca/OpenOrca\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03ae42-caa3-4c1e-8802-4d5ebdf72e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_hf_ds_subset(ds_id, ds_split, ds_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72323b3c-afab-46df-9890-2b2ab426a3ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dataset to a dataframe, for print it out and easy conversion to jsonl\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d08ed-b2fa-41a3-8511-2dbe06ec690f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"question\"] = df.apply(\n",
    "    lambda row: row[\"system_prompt\"] + \"\\n\" + row[\"question\"] \n",
    "                if isinstance(row[\"system_prompt\"], str) and row[\"system_prompt\"].strip() != \"\" \n",
    "                else row[\"question\"],\n",
    "    axis=1\n",
    ")\n",
    "df.drop(columns=[\"system_prompt\"], inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5842b6-de35-4e3a-8d89-2cf2920fb600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Preprocessed and loaded the open orca dataset. Going to load the jsonl line in the s3 bucket\")\n",
    "jsonl_content = df.to_json(orient='records', lines=True)\n",
    "print(jsonl_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187f3ec-087a-4d75-bd5b-ebdefd80ec96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['source_data_prefix']\n",
    "file_name: str = f\"{ds_id}.jsonl\"\n",
    "write_to_s3(jsonl_content, bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ac1e1-15dd-427b-83c7-10e858695c5e",
   "metadata": {},
   "source": [
    "#### Image Datasets\n",
    "---\n",
    "\n",
    "If you are using FMBench to benchmark models on an image dataset, run the cells below to load the image dataset and send the data to s3. This data will be used in the `1_generate_data.ipynb` notebook to convert the available image column (specified by the user) in the configuration file into `base64`. This will be used later in the benchmarking test while running inferences against the model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75f3c3-2cb8-4d9d-adf3-9bf676c30c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Marqo/marqo-GS-10M DATASET: This is an image dataset without any questions\n",
    "\n",
    "# import itertools\n",
    "# from datasets import load_dataset, Dataset\n",
    "\n",
    "# # ds_id: str = \"HuggingFaceM4/WebSight\"\n",
    "# ds_id: str = \"Marqo/marqo-GS-10M\"\n",
    "# ds_name: str = \"default\"\n",
    "# # ds_name: str = \"v0.2\"\n",
    "# ds_split: str = \"in_domain\"\n",
    "# ds_N: int = 100\n",
    "\n",
    "# # Load the dataset in streaming mode so you don't have to load the entire dataset\n",
    "# dataset = load_dataset(ds_id, name=ds_name, split=ds_split, streaming=True)\n",
    "\n",
    "# # Take only the first ds_N examples\n",
    "# dataset_iter = itertools.islice(dataset, ds_N)\n",
    "\n",
    "# # Convert to a list and then to a regular dataset\n",
    "# dataset_list = list(dataset_iter)\n",
    "# dataset = Dataset.from_list(dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d56a4-b3a2-44eb-8fc2-dfa0900c1abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "ds_id: str = \"derek-thomas/ScienceQA\"\n",
    "ds_name: str = \"default\"\n",
    "ds_split: str = \"test\"\n",
    "ds_N: int = 100\n",
    "\n",
    "# Load the dataset in streaming mode so you don't have to load the entire dataset\n",
    "dataset = load_dataset(ds_id, name=ds_name, split=ds_split, streaming=True)\n",
    "\n",
    "# Take only the first ds_N examples\n",
    "dataset_iter = itertools.islice(dataset, ds_N)\n",
    "\n",
    "# Convert to a list and then to a regular dataset\n",
    "dataset_list = list(dataset_iter)\n",
    "dataset = Dataset.from_list(dataset_list)\n",
    "\n",
    "logger.info(f\"Loaded {len(dataset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558518a-c24e-4f6d-becf-3fdbf6c10e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b537258-4b82-4fc3-9428-aed84dbe6f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dataset to a dataframe, for print it out and easy conversion to jsonl\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5211187-d4b4-4104-b289-e8cd98782387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view one of the images in the dataset\n",
    "df.image[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14963800-dd1d-4c75-81da-6cb84f816807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some datasets contain a field called column, we would like to call it\n",
    "# input to match it to the prompt template\n",
    "df.rename(columns={\"question\": \"input\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23587aed-6814-45ae-8a7d-d030457e83a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# This is a custom JSON encoder class called PILImageEncoder that extends the built-in json.JSONEncoder class. \n",
    "# The purpose of this class is to enable JSON serialization of PIL (Python Imaging Library) Image objects, which are \n",
    "# not natively JSON serializable.\n",
    "\n",
    "# It checks if the object ( obj) is an instance of Image.Image (a PIL Image object).\n",
    "\n",
    "# If it is an Image object:\n",
    "# a. It creates a BytesIO buffer.\n",
    "# b. Saves the image to this buffer in JPEG format.\n",
    "# c. Converts the binary data in the buffer to a hexadecimal string.\n",
    "# d. Returns a dictionary with two keys: the hexadecimal string and the JPEG format\n",
    "\n",
    "class PILImageEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, Image.Image):\n",
    "            buffered = io.BytesIO()\n",
    "            obj.save(buffered, format=\"JPEG\")\n",
    "            hex_data = buffered.getvalue().hex()\n",
    "            return {\n",
    "                'hex_data': hex_data,\n",
    "                'format': 'JPEG'\n",
    "            }\n",
    "        return super(PILImageEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cc0f9-a86b-42de-81b4-21a6a3048fe7",
   "metadata": {},
   "source": [
    "### Subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4e481-2cd4-4341-b910-c5172eafe400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"dataset shape before random subset = {df.shape}\")\n",
    "df = df.sample(n=ds_N)\n",
    "print(f\"dataset shape before random subset = {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fcadf-0ca7-4123-92d6-ed7b188cfd4b",
   "metadata": {},
   "source": [
    "Convert to json lines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb38f44-9788-4d26-b77e-2dde3feddfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if the image column is provided in the dataset, then use the PIL image encoder\n",
    "if config['datasets'].get('image_col') is not None:\n",
    "    logger.info(f\"The data is multimodal. Using the PILImageEncoder to encode the PIL image into jsonl files\")\n",
    "    jsonl_content = df.to_json(orient='records', lines=True, default_handler=PILImageEncoder().default)\n",
    "else:\n",
    "    logger.info(f\"The data is standard text data, will convert to jsonl files.\")\n",
    "    jsonl_content = df.to_json(orient='records', lines=True)\n",
    "print(jsonl_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c64b4-d0c8-41d5-80a2-86581d176a20",
   "metadata": {},
   "source": [
    "## Upload the dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfecbb1-6355-4f52-86a4-53579d867629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['source_data_prefix']\n",
    "file_name: str = f\"{ds_id}.jsonl\"\n",
    "write_to_s3(jsonl_content, bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6fd45-fc80-45f3-a184-9cad6a1cd706",
   "metadata": {},
   "source": [
    "## Create a prompt template and upload it to S3\n",
    "The prompt template is specific to the model under test and also the dataset being used. The variables used in the template, such as `context` and `input` must exist in the dataset being used so that this prompt template can be converted into an actual prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018df5ca-dd8a-4436-a1a6-c3204ac079d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary containing the prompt template, it has a key by the name\n",
    "# of the dataset id which forces you to explicitly add your dataset here\n",
    "# otherwise no new prompt template will be uploaded and it wont accidently\n",
    "# end up overwriting an existing prompt template\n",
    "prompt_template = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef34360-c855-49e6-a624-0209ba09939f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LongBench\n",
    "prompt_template['THUDM-LongBench-llama2-mistral'] = \"\"\"<s>[INST] <<SYS>>\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context in the section demarcated by \"```\" to answer the question. If you don't know the answer just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "<</SYS>>\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "[/INST]\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac185446-2338-47ec-8c78-30dea736aaec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open Orca\n",
    "prompt_template['Open-Orca-OpenOrca-llama2-mistral'] = \"\"\"<s>[INST] <<SYS>>\n",
    "\n",
    "{system_prompt}\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "Context and task: {input}\n",
    "\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0009c-79b8-4cf9-8450-824a03ae5996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template['Open-Orca-OpenOrca-llama3'] = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{system_prompt}\n",
    "\n",
    "Context and task: {input} \n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771c28e-07c6-4805-b33d-186895496aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['prompt_template_dir']\n",
    "for k in prompt_template.keys():\n",
    "    file_name: str = f\"prompt_template_{k}.txt\"\n",
    "    print(f\"writing {file_name} to s3://{bucket}/{prefix}/{file_name}\")\n",
    "    write_to_s3(prompt_template[k], bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25ebd9-782a-4765-b612-2731468c5d63",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d11fdc-ac92-42a7-b9de-8a5d36050532",
   "metadata": {},
   "source": [
    "### Utility function for converting a line from container log to JSON format\n",
    "\n",
    "The following is a line from CW log from a model container that provides all the information about the model that is not available anywhere else (not in Model or EndpointConfig or Endpoint description). This information is often necessary to know the low level settings about the model which may have been set while compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71becec-c2c7-4145-ad9d-84ab16e79aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "line=\"\"\"model_id_or_path='/tmp/.djl.ai/download/ae03dd100c208acd82b5dbed563c971de864c408' rolling_batch=<RollingBatchEnum.auto: 'auto'> tensor_parallel_degree=8 trust_remote_code=False enable_streaming=<StreamingEnum.false: 'false'> batch_size=4 max_rolling_batch_size=4 dtype=<Dtype.f16: 'fp16'> revision=None output_formatter=None waiting_steps=None is_mpi=False draft_model_id=None spec_length=0 neuron_optimize_level=None enable_mixed_precision_accumulation=False enable_saturate_infinity=False n_positions=4096 unroll=None load_in_8bit=False low_cpu_mem_usage=False load_split_model=True context_length_estimate=None amp='f16' quantize=None compiled_graph_path=None task=None save_mp_checkpoint_path=None group_query_attention=None model_loader=<TnXModelLoaders.tnx: 'tnx'> rolling_batch_strategy=<TnXGenerationStrategy.continuous_batching: 'continuous_batching'> fuse_qkv=False on_device_embedding=False attention_layout=None collectives_layout=None cache_layout=None partition_schema=None all_reduce_dtype=None cast_logits_dtype=None\"\"\"\n",
    "import re\n",
    "import json\n",
    "pattern = r' (?=[^\\'\"])'\n",
    "\n",
    "\n",
    "# Split the string using the pattern\n",
    "result = re.split(pattern, line)\n",
    "print(\"\\n\".join([r for r in result]))\n",
    "params= {}\n",
    "for kv in result:\n",
    "    #print(kv.split('='))\n",
    "    k,v = kv.split('=')\n",
    "    params[k] = v\n",
    "print(json.dumps(params, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c6e72-c7d7-46ae-aec9-67400130120e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fmbench_python311",
   "language": "python",
   "name": "conda_fmbench_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
